{
  "data": {
    "models": [
      {
        "slug": "mistralai/devstral-2512",
        "hf_slug": "mistralai/Devstral-2-123B-Instruct-2512",
        "updated_at": "2025-12-09T16:24:38.243423+00:00",
        "created_at": "2025-12-09T13:03:39+00:00",
        "hf_updated_at": null,
        "name": "Mistral: Devstral 2 2512 (free)",
        "short_name": "Devstral 2 2512 (free)",
        "author": "mistralai",
        "description": "Devstral 2 is a state-of-the-art open-source model by Mistral AI specializing in agentic coding. It is a 123B-parameter dense transformer model supporting a 256K context window.\n\nDevstral 2 supports exploring codebases and orchestrating changes across multiple files while maintaining architecture-level context. It tracks framework dependencies, detects failures, and retries with corrections—solving challenges like bug fixing and modernizing legacy systems. The model can be fine-tuned to prioritize specific languages or optimize for large enterprise codebases. It is available under a modified MIT license.",
        "model_version_group_id": null,
        "context_length": 262144,
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Mistral",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": "",
        "promotion_message": "",
        "routing_error_message": "",
        "permaslug": "mistralai/devstral-2512",
        "supports_reasoning": true,
        "reasoning_config": {
          "start_token": null,
          "end_token": null,
          "system_prompt": null
        },
        "features": {
          "reasoning_config": {
            "start_token": null,
            "end_token": null,
            "system_prompt": null
          },
          "chat_template_config": {}
        },
        "default_parameters": {
          "temperature": 0.3,
          "top_p": null,
          "frequency_penalty": null
        },
        "default_order": [],
        "quick_start_example_type": null,
        "is_trainable_text": true,
        "is_trainable_image": null,
        "endpoint": {
          "id": "051afd3d-0ef7-4e5d-a4c6-58152b120da0",
          "name": "Mistral | mistralai/devstral-2512:free",
          "context_length": 262144,
          "model": {
            "slug": "mistralai/devstral-2512",
            "hf_slug": "mistralai/Devstral-2-123B-Instruct-2512",
            "updated_at": "2025-12-09T16:24:38.243423+00:00",
            "created_at": "2025-12-09T13:03:39+00:00",
            "hf_updated_at": null,
            "name": "Mistral: Devstral 2 2512",
            "short_name": "Devstral 2 2512",
            "author": "mistralai",
            "description": "Devstral 2 is a state-of-the-art open-source model by Mistral AI specializing in agentic coding. It is a 123B-parameter dense transformer model supporting a 256K context window.\n\nDevstral 2 supports exploring codebases and orchestrating changes across multiple files while maintaining architecture-level context. It tracks framework dependencies, detects failures, and retries with corrections—solving challenges like bug fixing and modernizing legacy systems. The model can be fine-tuned to prioritize specific languages or optimize for large enterprise codebases. It is available under a modified MIT license.",
            "model_version_group_id": null,
            "context_length": 262144,
            "input_modalities": [
              "text"
            ],
            "output_modalities": [
              "text"
            ],
            "has_text_output": true,
            "group": "Mistral",
            "instruct_type": null,
            "default_system": null,
            "default_stops": [],
            "hidden": false,
            "router": null,
            "warning_message": "",
            "promotion_message": "",
            "routing_error_message": "",
            "permaslug": "mistralai/devstral-2512",
            "supports_reasoning": true,
            "reasoning_config": {
              "start_token": null,
              "end_token": null,
              "system_prompt": null
            },
            "features": {
              "reasoning_config": {
                "start_token": null,
                "end_token": null,
                "system_prompt": null
              },
              "chat_template_config": {}
            },
            "default_parameters": {
              "temperature": 0.3,
              "top_p": null,
              "frequency_penalty": null
            },
            "default_order": [],
            "quick_start_example_type": null,
            "is_trainable_text": true,
            "is_trainable_image": null
          },
          "model_variant_slug": "mistralai/devstral-2512:free",
          "model_variant_permaslug": "mistralai/devstral-2512:free",
          "adapter_name": "MistralAdapter",
          "provider_name": "Mistral",
          "provider_info": {
            "name": "Mistral",
            "displayName": "Mistral",
            "slug": "mistral",
            "baseUrl": "https://api.mistral.ai/v1",
            "dataPolicy": {
              "training": false,
              "trainingOpenRouter": false,
              "retainsPrompts": true,
              "retentionDays": 30,
              "canPublish": false,
              "termsOfServiceURL": "https://mistral.ai/terms/#terms-of-use",
              "privacyPolicyURL": "https://mistral.ai/terms/#privacy-policy"
            },
            "headquarters": "FR",
            "regionOverrides": {},
            "hasChatCompletions": true,
            "hasCompletions": false,
            "isAbortable": false,
            "moderationRequired": false,
            "editors": [
              "{}"
            ],
            "owners": [
              "{}"
            ],
            "adapterName": "MistralAdapter",
            "isMultipartSupported": true,
            "statusPageUrl": "https://status.mistral.ai/",
            "byokEnabled": true,
            "icon": {
              "url": "/images/icons/Mistral.png"
            },
            "ignoredProviderModels": [
              "mistral-moderation-2411-all",
              "voxtral-mini-2507",
              "voxtral-small-2507",
              "voxtral-mini-transcribe-2507",
              "mistral-medium",
              "mistral-tiny",
              "mistral-tiny-2312",
              "open-mistral-nemo",
              "mistral-tiny-2407",
              "open-mixtral-8x7b",
              "mistral-small",
              "mistral-small-2312",
              "open-mixtral-8x22b-2404",
              "mistral-large-pixtral-2411",
              "codestral-2412",
              "codestral-2411-rc5",
              "pixtral-12b",
              "mistral-moderation-2411",
              "mistral-ocr-2503",
              "mistral-ocr-2505",
              "mistral-saba-2502",
              "open-mixtral-8x22b",
              "mistral-large-2407",
              "magistral-medium-2507",
              "mistral-embed",
              "codestral-embed",
              "codestral-2501",
              "mistral-small-2501",
              "mistral-ocr-2512",
              "labs-devstral-small-2512"
            ],
            "sendClientIp": false,
            "pricingStrategy": "mistral"
          },
          "provider_display_name": "Mistral",
          "provider_slug": "mistral",
          "provider_model_id": "devstral-2512",
          "quantization": "unknown",
          "variant": "free",
          "is_free": true,
          "can_abort": false,
          "max_prompt_tokens": null,
          "max_completion_tokens": null,
          "max_tokens_per_image": null,
          "supported_parameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "response_format",
            "structured_outputs",
            "tools",
            "tool_choice"
          ],
          "is_byok": false,
          "moderation_required": false,
          "data_policy": {
            "training": false,
            "trainingOpenRouter": false,
            "retainsPrompts": true,
            "retentionDays": 30,
            "canPublish": false,
            "termsOfServiceURL": "https://mistral.ai/terms/#terms-of-use",
            "privacyPolicyURL": "https://mistral.ai/terms/#privacy-policy"
          },
          "pricing": {
            "prompt": "0",
            "completion": "0",
            "discount": 0
          },
          "variable_pricings": [],
          "pricing_json": {
            "mistral:prompt_tokens": 0,
            "mistral:completion_tokens": 0
          },
          "pricing_version_id": "839797cc-849b-40ea-ba3a-d94bc6169abf",
          "is_hidden": false,
          "is_deranked": false,
          "is_disabled": false,
          "supports_tool_parameters": true,
          "supports_reasoning": false,
          "supports_multipart": true,
          "limit_rpm": 600,
          "limit_rpd": null,
          "limit_rpm_cf": null,
          "has_completions": false,
          "has_chat_completions": true,
          "features": {
            "disable_free_endpoint_limits": true,
            "supports_tool_choice": {
              "literal_none": true,
              "literal_auto": true,
              "literal_required": true,
              "type_function": true
            },
            "supports_input_audio": false
          },
          "provider_region": null,
          "deprecation_date": null
        }
      },
      {
        "slug": "arcee-ai/trinity-mini",
        "hf_slug": "arcee-ai/Trinity-Mini",
        "updated_at": "2026-01-08T19:23:52.555156+00:00",
        "created_at": "2025-12-01T15:08:40+00:00",
        "hf_updated_at": null,
        "name": "Arcee AI: Trinity Mini (free)",
        "short_name": "Trinity Mini (free)",
        "author": "arcee-ai",
        "description": "Trinity Mini is a 26B-parameter (3B active) sparse mixture-of-experts language model featuring 128 experts with 8 active per token. Engineered for efficient reasoning over long contexts (131k) with robust function calling and multi-step agent workflows.",
        "model_version_group_id": null,
        "context_length": 131072,
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Other",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": "",
        "promotion_message": "",
        "routing_error_message": "",
        "permaslug": "arcee-ai/trinity-mini-20251201",
        "supports_reasoning": true,
        "reasoning_config": {
          "start_token": "<think>",
          "end_token": "</think>",
          "system_prompt": null,
          "is_mandatory_reasoning": true
        },
        "features": {
          "reasoning_config": {
            "start_token": "<think>",
            "end_token": "</think>",
            "system_prompt": null,
            "is_mandatory_reasoning": true
          },
          "chat_template_config": {}
        },
        "default_parameters": {
          "temperature": 0.15,
          "top_p": 0.75,
          "frequency_penalty": null
        },
        "default_order": [],
        "quick_start_example_type": "reasoning",
        "is_trainable_text": null,
        "is_trainable_image": null,
        "endpoint": {
          "id": "57299f47-f9cd-460d-b2fb-8480a99fe88e",
          "name": "Arcee AI | arcee-ai/trinity-mini-20251201:free",
          "context_length": 131072,
          "model": {
            "slug": "arcee-ai/trinity-mini",
            "hf_slug": "arcee-ai/Trinity-Mini",
            "updated_at": "2026-01-08T19:23:52.555156+00:00",
            "created_at": "2025-12-01T15:08:40+00:00",
            "hf_updated_at": null,
            "name": "Arcee AI: Trinity Mini",
            "short_name": "Trinity Mini",
            "author": "arcee-ai",
            "description": "Trinity Mini is a 26B-parameter (3B active) sparse mixture-of-experts language model featuring 128 experts with 8 active per token. Engineered for efficient reasoning over long contexts (131k) with robust function calling and multi-step agent workflows.",
            "model_version_group_id": null,
            "context_length": 131072,
            "input_modalities": [
              "text"
            ],
            "output_modalities": [
              "text"
            ],
            "has_text_output": true,
            "group": "Other",
            "instruct_type": null,
            "default_system": null,
            "default_stops": [],
            "hidden": false,
            "router": null,
            "warning_message": "",
            "promotion_message": "",
            "routing_error_message": "",
            "permaslug": "arcee-ai/trinity-mini-20251201",
            "supports_reasoning": true,
            "reasoning_config": {
              "start_token": "<think>",
              "end_token": "</think>",
              "system_prompt": null,
              "is_mandatory_reasoning": true
            },
            "features": {
              "reasoning_config": {
                "start_token": "<think>",
                "end_token": "</think>",
                "system_prompt": null,
                "is_mandatory_reasoning": true
              },
              "chat_template_config": {}
            },
            "default_parameters": {
              "temperature": 0.15,
              "top_p": 0.75,
              "frequency_penalty": null
            },
            "default_order": [],
            "quick_start_example_type": "reasoning",
            "is_trainable_text": null,
            "is_trainable_image": null
          },
          "model_variant_slug": "arcee-ai/trinity-mini:free",
          "model_variant_permaslug": "arcee-ai/trinity-mini-20251201:free",
          "adapter_name": "ClarifaiAdapter",
          "provider_name": "Arcee AI",
          "provider_info": {
            "name": "Arcee AI",
            "displayName": "Arcee AI",
            "slug": "arcee-ai",
            "baseUrl": "https://api.clarifai.com/v2/ext/openai/v1",
            "dataPolicy": {
              "training": false,
              "trainingOpenRouter": false,
              "retainsPrompts": false,
              "canPublish": false
            },
            "headquarters": "US",
            "datacenters": [
              "US"
            ],
            "regionOverrides": {},
            "hasChatCompletions": true,
            "hasCompletions": false,
            "isAbortable": false,
            "moderationRequired": false,
            "editors": [],
            "owners": [],
            "adapterName": "ClarifaiAdapter",
            "isMultipartSupported": true,
            "statusPageUrl": null,
            "byokEnabled": true,
            "icon": {
              "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.arcee.ai/&size=256"
            },
            "ignoredProviderModels": [],
            "sendClientIp": false,
            "pricingStrategy": null
          },
          "provider_display_name": "Arcee AI",
          "provider_slug": "arcee-ai/bf16",
          "provider_model_id": "arcee_ai/AFM/models/trinity-mini",
          "quantization": "bf16",
          "variant": "free",
          "is_free": true,
          "can_abort": false,
          "max_prompt_tokens": null,
          "max_completion_tokens": null,
          "max_tokens_per_image": null,
          "supported_parameters": [
            "reasoning",
            "include_reasoning",
            "max_tokens",
            "temperature",
            "top_k",
            "top_p",
            "tool_choice",
            "tools",
            "structured_outputs",
            "response_format"
          ],
          "is_byok": false,
          "moderation_required": false,
          "data_policy": {
            "training": false,
            "trainingOpenRouter": false,
            "retainsPrompts": false,
            "canPublish": false
          },
          "pricing": {
            "prompt": "0",
            "completion": "0",
            "image": "0",
            "request": "0",
            "web_search": "0",
            "internal_reasoning": "0",
            "image_output": "0",
            "discount": 0
          },
          "variable_pricings": [],
          "is_hidden": false,
          "is_deranked": false,
          "is_disabled": false,
          "supports_tool_parameters": true,
          "supports_reasoning": true,
          "supports_multipart": true,
          "limit_rpm": null,
          "limit_rpd": null,
          "limit_rpm_cf": null,
          "has_completions": false,
          "has_chat_completions": true,
          "features": {
            "supports_tool_choice": {
              "literal_none": false,
              "literal_auto": true,
              "literal_required": true,
              "type_function": true
            },
            "is_mandatory_reasoning": true,
            "supports_input_audio": false
          },
          "provider_region": null,
          "deprecation_date": null
        }
      },
      {
        "slug": "tngtech/tng-r1t-chimera",
        "hf_slug": null,
        "updated_at": "2026-01-08T19:23:52.555156+00:00",
        "created_at": "2025-11-26T19:09:21.439199+00:00",
        "hf_updated_at": null,
        "name": "TNG: R1T Chimera (free)",
        "short_name": "R1T Chimera (free)",
        "author": "tngtech",
        "description": "TNG-R1T-Chimera is an experimental LLM with a faible for creative storytelling and character interaction. It is a derivate of the original TNG/DeepSeek-R1T-Chimera released in April 2025 and is available exclusively via Chutes and OpenRouter.\n\nCharacteristics and improvements include:\n\nWe think that it has a creative and pleasant personality.\nIt has a preliminary EQ-Bench3 value of about 1305.\nIt is quite a bit more intelligent than the original, albeit a slightly slower.\nIt is much more think-token consistent, i.e. reasoning and answer blocks are properly delineated.\nTool calling is much improved.\n\nTNG Tech, the model authors, ask that users follow the careful guidelines that Microsoft has created for their \"MAI-DS-R1\" DeepSeek-based model. These guidelines are available on Hugging Face (https://huggingface.co/microsoft/MAI-DS-R1).",
        "model_version_group_id": null,
        "context_length": 163840,
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Other",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "promotion_message": null,
        "routing_error_message": null,
        "permaslug": "tngtech/tng-r1t-chimera",
        "supports_reasoning": true,
        "reasoning_config": {
          "start_token": null,
          "end_token": null,
          "system_prompt": null,
          "is_mandatory_reasoning": true
        },
        "features": {
          "reasoning_config": {
            "start_token": null,
            "end_token": null,
            "system_prompt": null,
            "is_mandatory_reasoning": true
          },
          "chat_template_config": {}
        },
        "default_parameters": {
          "temperature": null,
          "top_p": null,
          "frequency_penalty": null
        },
        "default_order": [],
        "quick_start_example_type": null,
        "is_trainable_text": null,
        "is_trainable_image": null,
        "endpoint": {
          "id": "b31307aa-c121-403c-a159-2e8f534f9836",
          "name": "Chutes | tngtech/tng-r1t-chimera:free",
          "context_length": 163840,
          "model": {
            "slug": "tngtech/tng-r1t-chimera",
            "hf_slug": null,
            "updated_at": "2026-01-08T19:23:52.555156+00:00",
            "created_at": "2025-11-26T19:09:21.439199+00:00",
            "hf_updated_at": null,
            "name": "TNG: R1T Chimera",
            "short_name": "R1T Chimera",
            "author": "tngtech",
            "description": "TNG-R1T-Chimera is an experimental LLM with a faible for creative storytelling and character interaction. It is a derivate of the original TNG/DeepSeek-R1T-Chimera released in April 2025 and is available exclusively via Chutes and OpenRouter.\n\nCharacteristics and improvements include:\n\nWe think that it has a creative and pleasant personality.\nIt has a preliminary EQ-Bench3 value of about 1305.\nIt is quite a bit more intelligent than the original, albeit a slightly slower.\nIt is much more think-token consistent, i.e. reasoning and answer blocks are properly delineated.\nTool calling is much improved.\n\nTNG Tech, the model authors, ask that users follow the careful guidelines that Microsoft has created for their \"MAI-DS-R1\" DeepSeek-based model. These guidelines are available on Hugging Face (https://huggingface.co/microsoft/MAI-DS-R1).",
            "model_version_group_id": null,
            "context_length": 163840,
            "input_modalities": [
              "text"
            ],
            "output_modalities": [
              "text"
            ],
            "has_text_output": true,
            "group": "Other",
            "instruct_type": null,
            "default_system": null,
            "default_stops": [],
            "hidden": false,
            "router": null,
            "warning_message": null,
            "promotion_message": null,
            "routing_error_message": null,
            "permaslug": "tngtech/tng-r1t-chimera",
            "supports_reasoning": true,
            "reasoning_config": {
              "start_token": null,
              "end_token": null,
              "system_prompt": null,
              "is_mandatory_reasoning": true
            },
            "features": {
              "reasoning_config": {
                "start_token": null,
                "end_token": null,
                "system_prompt": null,
                "is_mandatory_reasoning": true
              },
              "chat_template_config": {}
            },
            "default_parameters": {
              "temperature": null,
              "top_p": null,
              "frequency_penalty": null
            },
            "default_order": [],
            "quick_start_example_type": null,
            "is_trainable_text": null,
            "is_trainable_image": null
          },
          "model_variant_slug": "tngtech/tng-r1t-chimera:free",
          "model_variant_permaslug": "tngtech/tng-r1t-chimera:free",
          "adapter_name": "ChutesAdapter",
          "provider_name": "Chutes",
          "provider_info": {
            "name": "Chutes",
            "displayName": "Chutes",
            "slug": "chutes",
            "baseUrl": "https://llm.chutes.ai/v1",
            "dataPolicy": {
              "training": true,
              "trainingOpenRouter": false,
              "retainsPrompts": true,
              "canPublish": false,
              "termsOfServiceURL": "https://chutes.ai/tos"
            },
            "headquarters": "US",
            "regionOverrides": {},
            "hasChatCompletions": true,
            "hasCompletions": true,
            "isAbortable": true,
            "moderationRequired": false,
            "editors": [
              "{}"
            ],
            "owners": [
              "{}"
            ],
            "adapterName": "ChutesAdapter",
            "isMultipartSupported": true,
            "statusPageUrl": null,
            "byokEnabled": true,
            "icon": {
              "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
            },
            "ignoredProviderModels": [
              "openbmb/MiniCPM4-8B",
              "agentica-org/DeepSWE-Preview",
              "moonshotai/Kimi-K2-Instruct-tools",
              "internlm/Intern-S1",
              "TheDrummer/Gemmasutra-Pro-27B-v1.1",
              "all-hands/openhands-lm-32b-v0.1-ep3",
              "TheDrummer/Tunguska-39B-v1",
              "Meridian",
              "Zenith",
              "Proxima",
              "agentica-org/DeepCoder-14B-Preview",
              "TheDrummer/Cydonia-24B-v2.1",
              "Tesslate/UIGEN-X-32B-0727",
              "NousResearch/Hermes-4-14B",
              "unsloth/gemma-3-4b-it",
              "tencent/Hunyuan-A13B-Instruct",
              "unsloth/Llama-3.2-3B-Instruct",
              "unsloth/Llama-3.2-1B-Instruct",
              "zai-org/GLM-4.5-turbo",
              "zai-org/GLM-4.6-turbo",
              "rednote-hilab/dots.ocr",
              "deepseek-ai/DeepSeek-V3-0324-turbo",
              "deepseek-ai/DeepSeek-V3.1-turbo",
              "moonshotai/Kimi-K2-Thinking",
              "zai-org/GLM-4.5",
              "deepseek-ai/DeepSeek-V3.1"
            ],
            "sendClientIp": false,
            "pricingStrategy": null
          },
          "provider_display_name": "Chutes",
          "provider_slug": "chutes/fp8",
          "provider_model_id": "tngtech/TNG-R1T-Chimera-TEE",
          "quantization": "fp8",
          "variant": "free",
          "is_free": true,
          "can_abort": true,
          "max_prompt_tokens": null,
          "max_completion_tokens": 65536,
          "max_tokens_per_image": null,
          "supported_parameters": [
            "reasoning",
            "include_reasoning",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "seed",
            "top_k",
            "repetition_penalty",
            "tools",
            "tool_choice",
            "response_format",
            "structured_outputs"
          ],
          "is_byok": false,
          "moderation_required": false,
          "data_policy": {
            "training": true,
            "trainingOpenRouter": false,
            "retainsPrompts": true,
            "canPublish": false,
            "termsOfServiceURL": "https://chutes.ai/tos"
          },
          "pricing": {
            "prompt": "0",
            "completion": "0",
            "image": "0",
            "request": "0",
            "web_search": "0",
            "internal_reasoning": "0",
            "image_output": "0",
            "discount": 0
          },
          "variable_pricings": [],
          "is_hidden": false,
          "is_deranked": false,
          "is_disabled": false,
          "supports_tool_parameters": true,
          "supports_reasoning": true,
          "supports_multipart": true,
          "limit_rpm": null,
          "limit_rpd": null,
          "limit_rpm_cf": null,
          "has_completions": true,
          "has_chat_completions": true,
          "features": {
            "supports_tool_choice": {
              "literal_none": false,
              "literal_auto": true,
              "literal_required": true,
              "type_function": false
            },
            "is_mandatory_reasoning": true
          },
          "provider_region": null,
          "deprecation_date": null
        }
      },
      {
        "slug": "qwen/qwen3-next-80b-a3b-instruct",
        "hf_slug": "Qwen/Qwen3-Next-80B-A3B-Instruct",
        "updated_at": "2025-11-10T16:00:38.246665+00:00",
        "created_at": "2025-09-11T17:36:53.6379+00:00",
        "hf_updated_at": null,
        "name": "Qwen: Qwen3 Next 80B A3B Instruct (free)",
        "short_name": "Qwen3 Next 80B A3B Instruct (free)",
        "author": "qwen",
        "description": "Qwen3-Next-80B-A3B-Instruct is an instruction-tuned chat model in the Qwen3-Next series optimized for fast, stable responses without “thinking” traces. It targets complex tasks across reasoning, code generation, knowledge QA, and multilingual use, while remaining robust on alignment and formatting. Compared with prior Qwen3 instruct variants, it focuses on higher throughput and stability on ultra-long inputs and multi-turn dialogues, making it well-suited for RAG, tool use, and agentic workflows that require consistent final answers rather than visible chain-of-thought.\n\nThe model employs scaling-efficient training and decoding to improve parameter efficiency and inference speed, and has been validated on a broad set of public benchmarks where it reaches or approaches larger Qwen3 systems in several categories while outperforming earlier mid-sized baselines. It is best used as a general assistant, code helper, and long-context task solver in production settings where deterministic, instruction-following outputs are preferred.",
        "model_version_group_id": null,
        "context_length": 262144,
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Qwen3",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": "",
        "promotion_message": null,
        "routing_error_message": null,
        "permaslug": "qwen/qwen3-next-80b-a3b-instruct-2509",
        "supports_reasoning": true,
        "reasoning_config": {
          "start_token": null,
          "end_token": null,
          "system_prompt": null
        },
        "features": {
          "reasoning_config": {
            "start_token": null,
            "end_token": null,
            "system_prompt": null
          }
        },
        "default_parameters": {},
        "default_order": [],
        "quick_start_example_type": null,
        "is_trainable_text": true,
        "is_trainable_image": null,
        "endpoint": {
          "id": "94248808-ba97-4e3c-be60-1cb0928db51d",
          "name": "Venice | qwen/qwen3-next-80b-a3b-instruct-2509:free",
          "context_length": 262144,
          "model": {
            "slug": "qwen/qwen3-next-80b-a3b-instruct",
            "hf_slug": "Qwen/Qwen3-Next-80B-A3B-Instruct",
            "updated_at": "2025-11-10T16:00:38.246665+00:00",
            "created_at": "2025-09-11T17:36:53.6379+00:00",
            "hf_updated_at": null,
            "name": "Qwen: Qwen3 Next 80B A3B Instruct",
            "short_name": "Qwen3 Next 80B A3B Instruct",
            "author": "qwen",
            "description": "Qwen3-Next-80B-A3B-Instruct is an instruction-tuned chat model in the Qwen3-Next series optimized for fast, stable responses without “thinking” traces. It targets complex tasks across reasoning, code generation, knowledge QA, and multilingual use, while remaining robust on alignment and formatting. Compared with prior Qwen3 instruct variants, it focuses on higher throughput and stability on ultra-long inputs and multi-turn dialogues, making it well-suited for RAG, tool use, and agentic workflows that require consistent final answers rather than visible chain-of-thought.\n\nThe model employs scaling-efficient training and decoding to improve parameter efficiency and inference speed, and has been validated on a broad set of public benchmarks where it reaches or approaches larger Qwen3 systems in several categories while outperforming earlier mid-sized baselines. It is best used as a general assistant, code helper, and long-context task solver in production settings where deterministic, instruction-following outputs are preferred.",
            "model_version_group_id": null,
            "context_length": 262144,
            "input_modalities": [
              "text"
            ],
            "output_modalities": [
              "text"
            ],
            "has_text_output": true,
            "group": "Qwen3",
            "instruct_type": null,
            "default_system": null,
            "default_stops": [],
            "hidden": false,
            "router": null,
            "warning_message": "",
            "promotion_message": null,
            "routing_error_message": null,
            "permaslug": "qwen/qwen3-next-80b-a3b-instruct-2509",
            "supports_reasoning": true,
            "reasoning_config": {
              "start_token": null,
              "end_token": null,
              "system_prompt": null
            },
            "features": {
              "reasoning_config": {
                "start_token": null,
                "end_token": null,
                "system_prompt": null
              }
            },
            "default_parameters": {},
            "default_order": [],
            "quick_start_example_type": null,
            "is_trainable_text": true,
            "is_trainable_image": null
          },
          "model_variant_slug": "qwen/qwen3-next-80b-a3b-instruct:free",
          "model_variant_permaslug": "qwen/qwen3-next-80b-a3b-instruct-2509:free",
          "adapter_name": "VeniceAdapter",
          "provider_name": "Venice",
          "provider_info": {
            "name": "Venice",
            "displayName": "Venice (Beta)",
            "slug": "venice/beta",
            "baseUrl": "https://api.venice.ai/api/v1",
            "dataPolicy": {
              "training": false,
              "trainingOpenRouter": false,
              "retainsPrompts": false,
              "canPublish": false,
              "termsOfServiceURL": "https://venice.ai/legal/tos",
              "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
            },
            "regionOverrides": {},
            "hasChatCompletions": true,
            "hasCompletions": false,
            "isAbortable": true,
            "moderationRequired": false,
            "editors": [
              "{}"
            ],
            "owners": [
              "{}"
            ],
            "adapterName": "VeniceAdapter",
            "isMultipartSupported": false,
            "statusPageUrl": null,
            "byokEnabled": true,
            "icon": {
              "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://venice.ai/&size=256"
            },
            "ignoredProviderModels": [
              "llama-3.2-3b",
              "deepseek-coder-v2-lite",
              "dolphin-2.9.2-qwen2-72b",
              "mistral-32-24b",
              "zai-org-glm-4.6",
              "qwen3-235b-a22b-thinking-2507",
              "qwen3-235b-a22b-instruct-2507",
              "google-gemma-3-27b-it",
              "openai-gpt-oss-120b",
              "deepseek-ai-DeepSeek-R1",
              "grok-41-fast",
              "gemini-3-pro-preview",
              "claude-opus-45",
              "kimi-k2-thinking",
              "deepseek-v3.2",
              "openai-gpt-52",
              "gemini-3-flash-preview",
              "grok-code-fast-1"
            ],
            "sendClientIp": false,
            "pricingStrategy": null
          },
          "provider_display_name": "Venice (Beta)",
          "provider_slug": "venice/beta",
          "provider_model_id": "qwen3-next-80b",
          "quantization": "fp16",
          "variant": "free",
          "is_free": true,
          "can_abort": true,
          "max_prompt_tokens": null,
          "max_completion_tokens": null,
          "max_tokens_per_image": null,
          "supported_parameters": [
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "tools",
            "tool_choice",
            "structured_outputs",
            "response_format"
          ],
          "is_byok": false,
          "moderation_required": false,
          "data_policy": {
            "training": false,
            "trainingOpenRouter": false,
            "retainsPrompts": false,
            "canPublish": false,
            "termsOfServiceURL": "https://venice.ai/legal/tos",
            "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
          },
          "pricing": {
            "prompt": "0",
            "completion": "0",
            "image": "0",
            "request": "0",
            "web_search": "0",
            "internal_reasoning": "0",
            "image_output": "0",
            "discount": 0
          },
          "variable_pricings": [],
          "is_hidden": false,
          "is_deranked": false,
          "is_disabled": false,
          "supports_tool_parameters": true,
          "supports_reasoning": false,
          "supports_multipart": false,
          "limit_rpm": null,
          "limit_rpd": null,
          "limit_rpm_cf": null,
          "has_completions": false,
          "has_chat_completions": true,
          "features": {
            "supports_tool_choice": {
              "literal_none": true,
              "literal_auto": true,
              "literal_required": true,
              "type_function": true
            }
          },
          "provider_region": null,
          "deprecation_date": null
        }
      },
      {
        "slug": "nvidia/nemotron-nano-9b-v2",
        "hf_slug": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
        "updated_at": "2025-11-10T16:00:38.246665+00:00",
        "created_at": "2025-09-05T21:13:27.486887+00:00",
        "hf_updated_at": null,
        "name": "NVIDIA: Nemotron Nano 9B V2 (free)",
        "short_name": "Nemotron Nano 9B V2 (free)",
        "author": "nvidia",
        "description": "NVIDIA-Nemotron-Nano-9B-v2 is a large language model (LLM) trained from scratch by NVIDIA, and designed as a unified model for both reasoning and non-reasoning tasks. It responds to user queries and tasks by first generating a reasoning trace and then concluding with a final response. \n\nThe model's reasoning capabilities can be controlled via a system prompt. If the user prefers the model to provide its final answer without intermediate reasoning traces, it can be configured to do so.",
        "model_version_group_id": null,
        "context_length": 128000,
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Other",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": "",
        "promotion_message": null,
        "routing_error_message": null,
        "permaslug": "nvidia/nemotron-nano-9b-v2",
        "supports_reasoning": true,
        "reasoning_config": {
          "start_token": "<think>",
          "end_token": "</think>",
          "system_prompt": null
        },
        "features": {
          "reasoning_config": {
            "start_token": "<think>",
            "end_token": "</think>",
            "system_prompt": null
          }
        },
        "default_parameters": {},
        "default_order": [],
        "quick_start_example_type": null,
        "is_trainable_text": true,
        "is_trainable_image": null,
        "endpoint": {
          "id": "71549a70-5ef5-406b-ae54-fab8adfb6dae",
          "name": "Nvidia | nvidia/nemotron-nano-9b-v2:free",
          "context_length": 128000,
          "model": {
            "slug": "nvidia/nemotron-nano-9b-v2",
            "hf_slug": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
            "updated_at": "2025-11-10T16:00:38.246665+00:00",
            "created_at": "2025-09-05T21:13:27.486887+00:00",
            "hf_updated_at": null,
            "name": "NVIDIA: Nemotron Nano 9B V2",
            "short_name": "Nemotron Nano 9B V2",
            "author": "nvidia",
            "description": "NVIDIA-Nemotron-Nano-9B-v2 is a large language model (LLM) trained from scratch by NVIDIA, and designed as a unified model for both reasoning and non-reasoning tasks. It responds to user queries and tasks by first generating a reasoning trace and then concluding with a final response. \n\nThe model's reasoning capabilities can be controlled via a system prompt. If the user prefers the model to provide its final answer without intermediate reasoning traces, it can be configured to do so.",
            "model_version_group_id": null,
            "context_length": 32000,
            "input_modalities": [
              "text"
            ],
            "output_modalities": [
              "text"
            ],
            "has_text_output": true,
            "group": "Other",
            "instruct_type": null,
            "default_system": null,
            "default_stops": [],
            "hidden": false,
            "router": null,
            "warning_message": "",
            "promotion_message": null,
            "routing_error_message": null,
            "permaslug": "nvidia/nemotron-nano-9b-v2",
            "supports_reasoning": true,
            "reasoning_config": {
              "start_token": "<think>",
              "end_token": "</think>",
              "system_prompt": null
            },
            "features": {
              "reasoning_config": {
                "start_token": "<think>",
                "end_token": "</think>",
                "system_prompt": null
              }
            },
            "default_parameters": {},
            "default_order": [],
            "quick_start_example_type": null,
            "is_trainable_text": true,
            "is_trainable_image": null
          },
          "model_variant_slug": "nvidia/nemotron-nano-9b-v2:free",
          "model_variant_permaslug": "nvidia/nemotron-nano-9b-v2:free",
          "adapter_name": "OpenAIAdapter",
          "provider_name": "Nvidia",
          "provider_info": {
            "name": "Nvidia",
            "displayName": "NVIDIA",
            "slug": "nvidia",
            "baseUrl": "https://74819e7c-e3e6-4497-8fdb-5f5fdc17dc85.invocation.api.nvcf.nvidia.com/v1",
            "dataPolicy": {
              "training": false,
              "trainingOpenRouter": false,
              "retainsPrompts": false,
              "canPublish": false,
              "termsOfServiceURL": "https://assets.ngc.nvidia.com/products/api-catalog/legal/NVIDIA%20API%20Trial%20Terms%20of%20Service.pdf",
              "privacyPolicyURL": "https://www.nvidia.com/en-us/about-nvidia/privacy-policy/"
            },
            "headquarters": "US",
            "datacenters": [
              "US"
            ],
            "regionOverrides": {},
            "hasChatCompletions": true,
            "hasCompletions": false,
            "isAbortable": true,
            "moderationRequired": false,
            "editors": [],
            "owners": [],
            "adapterName": "OpenAIAdapter",
            "isMultipartSupported": true,
            "statusPageUrl": null,
            "byokEnabled": false,
            "icon": {
              "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.nvidia.com/en-us/&size=256"
            },
            "ignoredProviderModels": [],
            "sendClientIp": false,
            "pricingStrategy": null
          },
          "provider_display_name": "NVIDIA",
          "provider_slug": "nvidia/bf16",
          "provider_model_id": "nvidia/nvidia-nemotron-nano-9b-v2",
          "quantization": "bf16",
          "variant": "free",
          "is_free": true,
          "can_abort": true,
          "max_prompt_tokens": null,
          "max_completion_tokens": null,
          "max_tokens_per_image": null,
          "supported_parameters": [
            "reasoning",
            "include_reasoning",
            "structured_outputs",
            "response_format",
            "temperature",
            "max_tokens",
            "seed",
            "top_p",
            "tools",
            "tool_choice"
          ],
          "is_byok": false,
          "moderation_required": false,
          "data_policy": {
            "training": false,
            "trainingOpenRouter": false,
            "retainsPrompts": false,
            "canPublish": false,
            "termsOfServiceURL": "https://assets.ngc.nvidia.com/products/api-catalog/legal/NVIDIA%20API%20Trial%20Terms%20of%20Service.pdf",
            "privacyPolicyURL": "https://www.nvidia.com/en-us/about-nvidia/privacy-policy/"
          },
          "pricing": {
            "prompt": "0",
            "completion": "0",
            "image": "0",
            "request": "0",
            "web_search": "0",
            "internal_reasoning": "0",
            "image_output": "0",
            "discount": 0
          },
          "variable_pricings": [],
          "is_hidden": false,
          "is_deranked": false,
          "is_disabled": false,
          "supports_tool_parameters": true,
          "supports_reasoning": true,
          "supports_multipart": true,
          "limit_rpm": 50,
          "limit_rpd": null,
          "limit_rpm_cf": null,
          "has_completions": false,
          "has_chat_completions": true,
          "features": {
            "supports_multipart": true,
            "supports_tool_choice": {
              "literal_none": true,
              "literal_auto": true,
              "literal_required": true,
              "type_function": true
            },
            "supported_parameters": {
              "response_format": true,
              "structured_outputs": true
            },
            "supports_input_audio": false
          },
          "provider_region": null,
          "deprecation_date": null
        }
      },
      {
        "slug": "cognitivecomputations/dolphin-mistral-24b-venice-edition",
        "hf_slug": "cognitivecomputations/Dolphin-Mistral-24B-Venice-Edition",
        "updated_at": "2025-11-10T16:00:38.246665+00:00",
        "created_at": "2025-07-09T21:02:46.328189+00:00",
        "hf_updated_at": null,
        "name": "Venice: Uncensored (free)",
        "short_name": "Uncensored (free)",
        "author": "venice",
        "description": "Venice Uncensored Dolphin Mistral 24B Venice Edition is a fine-tuned variant of Mistral-Small-24B-Instruct-2501, developed by dphn.ai in collaboration with Venice.ai. This model is designed as an “uncensored” instruct-tuned LLM, preserving user control over alignment, system prompts, and behavior. Intended for advanced and unrestricted use cases, Venice Uncensored emphasizes steerability and transparent behavior, removing default safety and alignment layers typically found in mainstream assistant models.",
        "model_version_group_id": null,
        "context_length": 32768,
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Other",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": "",
        "promotion_message": null,
        "routing_error_message": null,
        "permaslug": "venice/uncensored",
        "supports_reasoning": true,
        "reasoning_config": {
          "start_token": null,
          "end_token": null,
          "system_prompt": null
        },
        "features": {
          "reasoning_config": {
            "start_token": null,
            "end_token": null,
            "system_prompt": null
          }
        },
        "default_parameters": {},
        "default_order": [],
        "quick_start_example_type": null,
        "is_trainable_text": null,
        "is_trainable_image": null,
        "endpoint": {
          "id": "2d9e49f9-2147-4259-9871-4f6b6f181976",
          "name": "Venice | venice/uncensored:free",
          "context_length": 32768,
          "model": {
            "slug": "cognitivecomputations/dolphin-mistral-24b-venice-edition",
            "hf_slug": "cognitivecomputations/Dolphin-Mistral-24B-Venice-Edition",
            "updated_at": "2025-11-10T16:00:38.246665+00:00",
            "created_at": "2025-07-09T21:02:46.328189+00:00",
            "hf_updated_at": null,
            "name": "Venice: Uncensored",
            "short_name": "Uncensored",
            "author": "venice",
            "description": "Venice Uncensored Dolphin Mistral 24B Venice Edition is a fine-tuned variant of Mistral-Small-24B-Instruct-2501, developed by dphn.ai in collaboration with Venice.ai. This model is designed as an “uncensored” instruct-tuned LLM, preserving user control over alignment, system prompts, and behavior. Intended for advanced and unrestricted use cases, Venice Uncensored emphasizes steerability and transparent behavior, removing default safety and alignment layers typically found in mainstream assistant models.",
            "model_version_group_id": null,
            "context_length": 32768,
            "input_modalities": [
              "text"
            ],
            "output_modalities": [
              "text"
            ],
            "has_text_output": true,
            "group": "Other",
            "instruct_type": null,
            "default_system": null,
            "default_stops": [],
            "hidden": false,
            "router": null,
            "warning_message": "",
            "promotion_message": null,
            "routing_error_message": null,
            "permaslug": "venice/uncensored",
            "supports_reasoning": true,
            "reasoning_config": {
              "start_token": null,
              "end_token": null,
              "system_prompt": null
            },
            "features": {
              "reasoning_config": {
                "start_token": null,
                "end_token": null,
                "system_prompt": null
              }
            },
            "default_parameters": {},
            "default_order": [],
            "quick_start_example_type": null,
            "is_trainable_text": null,
            "is_trainable_image": null
          },
          "model_variant_slug": "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
          "model_variant_permaslug": "venice/uncensored:free",
          "adapter_name": "VeniceAdapter",
          "provider_name": "Venice",
          "provider_info": {
            "name": "Venice",
            "displayName": "Venice",
            "slug": "venice",
            "baseUrl": "https://api.venice.ai/api/v1",
            "dataPolicy": {
              "training": false,
              "trainingOpenRouter": false,
              "retainsPrompts": false,
              "canPublish": false,
              "termsOfServiceURL": "https://venice.ai/legal/tos",
              "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
            },
            "regionOverrides": {},
            "hasChatCompletions": true,
            "hasCompletions": false,
            "isAbortable": true,
            "moderationRequired": false,
            "editors": [
              "{}"
            ],
            "owners": [
              "{}"
            ],
            "adapterName": "VeniceAdapter",
            "isMultipartSupported": false,
            "statusPageUrl": null,
            "byokEnabled": true,
            "icon": {
              "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://venice.ai/&size=256"
            },
            "ignoredProviderModels": [
              "llama-3.2-3b",
              "deepseek-coder-v2-lite",
              "dolphin-2.9.2-qwen2-72b",
              "mistral-32-24b",
              "zai-org-glm-4.6",
              "qwen3-235b-a22b-thinking-2507",
              "qwen3-235b-a22b-instruct-2507",
              "google-gemma-3-27b-it",
              "openai-gpt-oss-120b",
              "deepseek-ai-DeepSeek-R1",
              "grok-41-fast",
              "gemini-3-pro-preview",
              "claude-opus-45",
              "kimi-k2-thinking",
              "deepseek-v3.2",
              "openai-gpt-52",
              "gemini-3-flash-preview",
              "grok-code-fast-1"
            ],
            "sendClientIp": false,
            "pricingStrategy": null
          },
          "provider_display_name": "Venice",
          "provider_slug": "venice/fp16",
          "provider_model_id": "venice-uncensored",
          "quantization": "fp16",
          "variant": "free",
          "is_free": true,
          "can_abort": true,
          "max_prompt_tokens": null,
          "max_completion_tokens": null,
          "max_tokens_per_image": null,
          "supported_parameters": [
            "structured_outputs",
            "response_format",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k"
          ],
          "is_byok": false,
          "moderation_required": false,
          "data_policy": {
            "training": false,
            "trainingOpenRouter": false,
            "retainsPrompts": false,
            "canPublish": false,
            "termsOfServiceURL": "https://venice.ai/legal/tos",
            "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
          },
          "pricing": {
            "prompt": "0",
            "completion": "0",
            "image": "0",
            "request": "0",
            "web_search": "0",
            "internal_reasoning": "0",
            "image_output": "0",
            "discount": 0
          },
          "variable_pricings": [],
          "is_hidden": false,
          "is_deranked": false,
          "is_disabled": false,
          "supports_tool_parameters": false,
          "supports_reasoning": false,
          "supports_multipart": false,
          "limit_rpm": null,
          "limit_rpd": null,
          "limit_rpm_cf": null,
          "has_completions": false,
          "has_chat_completions": true,
          "features": {
            "supports_tool_choice": {
              "literal_none": true,
              "literal_auto": true,
              "literal_required": true,
              "type_function": true
            },
            "supported_parameters": {
              "response_format": true,
              "structured_outputs": true
            }
          },
          "provider_region": null,
          "deprecation_date": null
        }
      },
      {
        "slug": "qwen/qwen3-4b",
        "hf_slug": "Qwen/Qwen3-4B",
        "updated_at": "2025-11-10T16:00:38.246665+00:00",
        "created_at": "2025-04-30T16:38:24.032465+00:00",
        "hf_updated_at": null,
        "name": "Qwen: Qwen3 4B (free)",
        "short_name": "Qwen3 4B (free)",
        "author": "qwen",
        "description": "Qwen3-4B is a 4 billion parameter dense language model from the Qwen3 series, designed to support both general-purpose and reasoning-intensive tasks. It introduces a dual-mode architecture—thinking and non-thinking—allowing dynamic switching between high-precision logical reasoning and efficient dialogue generation. This makes it well-suited for multi-turn chat, instruction following, and complex agent workflows.",
        "model_version_group_id": null,
        "context_length": 40960,
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Qwen3",
        "instruct_type": "qwen3",
        "default_system": null,
        "default_stops": [
          "<|im_start|>",
          "<|im_end|>"
        ],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "promotion_message": null,
        "routing_error_message": null,
        "permaslug": "qwen/qwen3-4b-04-28",
        "supports_reasoning": true,
        "reasoning_config": {
          "start_token": "<think>",
          "end_token": "</think>"
        },
        "features": {
          "reasoning_config": {
            "start_token": "<think>",
            "end_token": "</think>"
          }
        },
        "default_parameters": {},
        "default_order": [],
        "quick_start_example_type": null,
        "is_trainable_text": true,
        "is_trainable_image": null,
        "endpoint": {
          "id": "2e98edb5-b21b-455b-afb4-d5c01aad515d",
          "name": "Venice | qwen/qwen3-4b-04-28:free",
          "context_length": 40960,
          "model": {
            "slug": "qwen/qwen3-4b",
            "hf_slug": "Qwen/Qwen3-4B",
            "updated_at": "2025-11-10T16:00:38.246665+00:00",
            "created_at": "2025-04-30T16:38:24.032465+00:00",
            "hf_updated_at": null,
            "name": "Qwen: Qwen3 4B",
            "short_name": "Qwen3 4B",
            "author": "qwen",
            "description": "Qwen3-4B is a 4 billion parameter dense language model from the Qwen3 series, designed to support both general-purpose and reasoning-intensive tasks. It introduces a dual-mode architecture—thinking and non-thinking—allowing dynamic switching between high-precision logical reasoning and efficient dialogue generation. This makes it well-suited for multi-turn chat, instruction following, and complex agent workflows.",
            "model_version_group_id": null,
            "context_length": 128000,
            "input_modalities": [
              "text"
            ],
            "output_modalities": [
              "text"
            ],
            "has_text_output": true,
            "group": "Qwen3",
            "instruct_type": "qwen3",
            "default_system": null,
            "default_stops": [
              "<|im_start|>",
              "<|im_end|>"
            ],
            "hidden": false,
            "router": null,
            "warning_message": null,
            "promotion_message": null,
            "routing_error_message": null,
            "permaslug": "qwen/qwen3-4b-04-28",
            "supports_reasoning": true,
            "reasoning_config": {
              "start_token": "<think>",
              "end_token": "</think>"
            },
            "features": {
              "reasoning_config": {
                "start_token": "<think>",
                "end_token": "</think>"
              }
            },
            "default_parameters": {},
            "default_order": [],
            "quick_start_example_type": null,
            "is_trainable_text": true,
            "is_trainable_image": null
          },
          "model_variant_slug": "qwen/qwen3-4b:free",
          "model_variant_permaslug": "qwen/qwen3-4b-04-28:free",
          "adapter_name": "VeniceAdapter",
          "provider_name": "Venice",
          "provider_info": {
            "name": "Venice",
            "displayName": "Venice",
            "slug": "venice",
            "baseUrl": "https://api.venice.ai/api/v1",
            "dataPolicy": {
              "training": false,
              "trainingOpenRouter": false,
              "retainsPrompts": false,
              "canPublish": false,
              "termsOfServiceURL": "https://venice.ai/legal/tos",
              "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
            },
            "regionOverrides": {},
            "hasChatCompletions": true,
            "hasCompletions": false,
            "isAbortable": true,
            "moderationRequired": false,
            "editors": [
              "{}"
            ],
            "owners": [
              "{}"
            ],
            "adapterName": "VeniceAdapter",
            "isMultipartSupported": false,
            "statusPageUrl": null,
            "byokEnabled": true,
            "icon": {
              "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://venice.ai/&size=256"
            },
            "ignoredProviderModels": [
              "llama-3.2-3b",
              "deepseek-coder-v2-lite",
              "dolphin-2.9.2-qwen2-72b",
              "mistral-32-24b",
              "zai-org-glm-4.6",
              "qwen3-235b-a22b-thinking-2507",
              "qwen3-235b-a22b-instruct-2507",
              "google-gemma-3-27b-it",
              "openai-gpt-oss-120b",
              "deepseek-ai-DeepSeek-R1",
              "grok-41-fast",
              "gemini-3-pro-preview",
              "claude-opus-45",
              "kimi-k2-thinking",
              "deepseek-v3.2",
              "openai-gpt-52",
              "gemini-3-flash-preview",
              "grok-code-fast-1"
            ],
            "sendClientIp": false,
            "pricingStrategy": null
          },
          "provider_display_name": "Venice",
          "provider_slug": "venice/fp8",
          "provider_model_id": "qwen3-4b",
          "quantization": "fp8",
          "variant": "free",
          "is_free": true,
          "can_abort": true,
          "max_prompt_tokens": null,
          "max_completion_tokens": null,
          "max_tokens_per_image": null,
          "supported_parameters": [
            "reasoning",
            "include_reasoning",
            "structured_outputs",
            "response_format",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "tools",
            "tool_choice"
          ],
          "is_byok": false,
          "moderation_required": false,
          "data_policy": {
            "training": false,
            "trainingOpenRouter": false,
            "retainsPrompts": false,
            "canPublish": false,
            "termsOfServiceURL": "https://venice.ai/legal/tos",
            "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
          },
          "pricing": {
            "prompt": "0",
            "completion": "0",
            "image": "0",
            "request": "0",
            "web_search": "0",
            "internal_reasoning": "0",
            "image_output": "0",
            "discount": 0
          },
          "variable_pricings": [],
          "is_hidden": false,
          "is_deranked": false,
          "is_disabled": false,
          "supports_tool_parameters": true,
          "supports_reasoning": true,
          "supports_multipart": false,
          "limit_rpm": 1,
          "limit_rpd": null,
          "limit_rpm_cf": null,
          "has_completions": false,
          "has_chat_completions": true,
          "features": {
            "supports_tool_choice": {
              "literal_none": true,
              "literal_auto": true,
              "literal_required": true,
              "type_function": true
            },
            "supported_parameters": {
              "response_format": true,
              "structured_outputs": true
            }
          },
          "provider_region": null,
          "deprecation_date": null
        }
      },
      {
        "slug": "mistralai/mistral-small-3.1-24b-instruct",
        "hf_slug": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
        "updated_at": "2025-11-10T16:00:38.246665+00:00",
        "created_at": "2025-03-17T19:15:37.00423+00:00",
        "hf_updated_at": null,
        "name": "Mistral: Mistral Small 3.1 24B (free)",
        "short_name": "Mistral Small 3.1 24B (free)",
        "author": "mistralai",
        "description": "Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small 3 (2501), featuring 24 billion parameters with advanced multimodal capabilities. It provides state-of-the-art performance in text-based reasoning and vision tasks, including image analysis, programming, mathematical reasoning, and multilingual support across dozens of languages. Equipped with an extensive 128k token context window and optimized for efficient local inference, it supports use cases such as conversational agents, function calling, long-document comprehension, and privacy-sensitive deployments. The updated version is [Mistral Small 3.2](mistralai/mistral-small-3.2-24b-instruct)",
        "model_version_group_id": null,
        "context_length": 128000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Mistral",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "promotion_message": null,
        "routing_error_message": null,
        "permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
        "supports_reasoning": true,
        "reasoning_config": {
          "start_token": null,
          "end_token": null,
          "system_prompt": null
        },
        "features": {
          "reasoning_config": {
            "start_token": null,
            "end_token": null,
            "system_prompt": null
          }
        },
        "default_parameters": {
          "temperature": 0.3
        },
        "default_order": [],
        "quick_start_example_type": null,
        "is_trainable_text": true,
        "is_trainable_image": null,
        "endpoint": {
          "id": "ecbdc9f1-ecca-4f91-83cf-b3495a60e874",
          "name": "Venice | mistralai/mistral-small-3.1-24b-instruct-2503:free",
          "context_length": 128000,
          "model": {
            "slug": "mistralai/mistral-small-3.1-24b-instruct",
            "hf_slug": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
            "updated_at": "2025-11-10T16:00:38.246665+00:00",
            "created_at": "2025-03-17T19:15:37.00423+00:00",
            "hf_updated_at": null,
            "name": "Mistral: Mistral Small 3.1 24B",
            "short_name": "Mistral Small 3.1 24B",
            "author": "mistralai",
            "description": "Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small 3 (2501), featuring 24 billion parameters with advanced multimodal capabilities. It provides state-of-the-art performance in text-based reasoning and vision tasks, including image analysis, programming, mathematical reasoning, and multilingual support across dozens of languages. Equipped with an extensive 128k token context window and optimized for efficient local inference, it supports use cases such as conversational agents, function calling, long-document comprehension, and privacy-sensitive deployments. The updated version is [Mistral Small 3.2](mistralai/mistral-small-3.2-24b-instruct)",
            "model_version_group_id": null,
            "context_length": 128000,
            "input_modalities": [
              "text",
              "image"
            ],
            "output_modalities": [
              "text"
            ],
            "has_text_output": true,
            "group": "Mistral",
            "instruct_type": null,
            "default_system": null,
            "default_stops": [],
            "hidden": false,
            "router": null,
            "warning_message": null,
            "promotion_message": null,
            "routing_error_message": null,
            "permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
            "supports_reasoning": true,
            "reasoning_config": {
              "start_token": null,
              "end_token": null,
              "system_prompt": null
            },
            "features": {
              "reasoning_config": {
                "start_token": null,
                "end_token": null,
                "system_prompt": null
              }
            },
            "default_parameters": {
              "temperature": 0.3
            },
            "default_order": [],
            "quick_start_example_type": null,
            "is_trainable_text": true,
            "is_trainable_image": null
          },
          "model_variant_slug": "mistralai/mistral-small-3.1-24b-instruct:free",
          "model_variant_permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503:free",
          "adapter_name": "VeniceAdapter",
          "provider_name": "Venice",
          "provider_info": {
            "name": "Venice",
            "displayName": "Venice",
            "slug": "venice",
            "baseUrl": "https://api.venice.ai/api/v1",
            "dataPolicy": {
              "training": false,
              "trainingOpenRouter": false,
              "retainsPrompts": false,
              "canPublish": false,
              "termsOfServiceURL": "https://venice.ai/legal/tos",
              "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
            },
            "regionOverrides": {},
            "hasChatCompletions": true,
            "hasCompletions": false,
            "isAbortable": true,
            "moderationRequired": false,
            "editors": [
              "{}"
            ],
            "owners": [
              "{}"
            ],
            "adapterName": "VeniceAdapter",
            "isMultipartSupported": false,
            "statusPageUrl": null,
            "byokEnabled": true,
            "icon": {
              "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://venice.ai/&size=256"
            },
            "ignoredProviderModels": [
              "llama-3.2-3b",
              "deepseek-coder-v2-lite",
              "dolphin-2.9.2-qwen2-72b",
              "mistral-32-24b",
              "zai-org-glm-4.6",
              "qwen3-235b-a22b-thinking-2507",
              "qwen3-235b-a22b-instruct-2507",
              "google-gemma-3-27b-it",
              "openai-gpt-oss-120b",
              "deepseek-ai-DeepSeek-R1",
              "grok-41-fast",
              "gemini-3-pro-preview",
              "claude-opus-45",
              "kimi-k2-thinking",
              "deepseek-v3.2",
              "openai-gpt-52",
              "gemini-3-flash-preview",
              "grok-code-fast-1"
            ],
            "sendClientIp": false,
            "pricingStrategy": null
          },
          "provider_display_name": "Venice",
          "provider_slug": "venice/fp8",
          "provider_model_id": "mistral-31-24b",
          "quantization": "fp8",
          "variant": "free",
          "is_free": true,
          "can_abort": true,
          "max_prompt_tokens": null,
          "max_completion_tokens": null,
          "max_tokens_per_image": null,
          "supported_parameters": [
            "structured_outputs",
            "response_format",
            "max_tokens",
            "temperature",
            "top_p",
            "stop",
            "frequency_penalty",
            "presence_penalty",
            "top_k",
            "tools",
            "tool_choice"
          ],
          "is_byok": false,
          "moderation_required": false,
          "data_policy": {
            "training": false,
            "trainingOpenRouter": false,
            "retainsPrompts": false,
            "canPublish": false,
            "termsOfServiceURL": "https://venice.ai/legal/tos",
            "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
          },
          "pricing": {
            "prompt": "0",
            "completion": "0",
            "image": "0",
            "request": "0",
            "web_search": "0",
            "internal_reasoning": "0",
            "image_output": "0",
            "discount": 0
          },
          "variable_pricings": [],
          "is_hidden": false,
          "is_deranked": false,
          "is_disabled": false,
          "supports_tool_parameters": true,
          "supports_reasoning": false,
          "supports_multipart": false,
          "limit_rpm": 1,
          "limit_rpd": null,
          "limit_rpm_cf": null,
          "has_completions": false,
          "has_chat_completions": true,
          "features": {
            "supports_tool_choice": {
              "literal_none": true,
              "literal_auto": true,
              "literal_required": true,
              "type_function": true
            },
            "supported_parameters": {
              "response_format": true,
              "structured_outputs": true
            }
          },
          "provider_region": null,
          "deprecation_date": null
        }
      }
    ],
    "analytics": {
      "bytedance-seed/seedream-4.5-20251203": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "bytedance-seed/seedream-4.5-20251203",
        "variant": "standard",
        "variant_permaslug": "bytedance-seed/seedream-4.5-20251203",
        "count": 75246,
        "total_completion_tokens": 314152050,
        "total_prompt_tokens": 428693516,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 114576,
        "num_media_completion": 75246,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "relace/relace-apply-3": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "relace/relace-apply-3",
        "variant": "standard",
        "variant_permaslug": "relace/relace-apply-3",
        "count": 13323,
        "total_completion_tokens": 22379940,
        "total_prompt_tokens": 29802775,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "z-ai/glm-4.5v": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "z-ai/glm-4.5v",
        "variant": "standard",
        "variant_permaslug": "z-ai/glm-4.5v",
        "count": 66940,
        "total_completion_tokens": 10134314,
        "total_prompt_tokens": 71660122,
        "total_native_tokens_reasoning": 5995695,
        "num_media_prompt": 15292,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 3767890,
        "total_tool_calls": 2300,
        "requests_with_tool_call_errors": 167
      },
      "thedrummer/unslopnemo-12b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "thedrummer/unslopnemo-12b",
        "variant": "standard",
        "variant_permaslug": "thedrummer/unslopnemo-12b",
        "count": 428221,
        "total_completion_tokens": 74103601,
        "total_prompt_tokens": 1398392748,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepseek/deepseek-chat-v3-0324": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-chat-v3-0324",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-chat-v3-0324",
        "count": 25129913,
        "total_completion_tokens": 5687028934,
        "total_prompt_tokens": 117114372323,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 699,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 4278220480,
        "total_tool_calls": 454864,
        "requests_with_tool_call_errors": 3613
      },
      "meta-llama/llama-3.2-11b-vision-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3.2-11b-vision-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-3.2-11b-vision-instruct",
        "count": 669472,
        "total_completion_tokens": 76149633,
        "total_prompt_tokens": 2854513799,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 637780,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "nousresearch/hermes-3-llama-3.1-405b:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nousresearch/hermes-3-llama-3.1-405b",
        "variant": "free",
        "variant_permaslug": "nousresearch/hermes-3-llama-3.1-405b:free",
        "count": 122309,
        "total_completion_tokens": 36460291,
        "total_prompt_tokens": 1091363808,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-5.1-codex-mini-20251113": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5.1-codex-mini-20251113",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5.1-codex-mini-20251113",
        "count": 203034,
        "total_completion_tokens": 169360581,
        "total_prompt_tokens": 3972102410,
        "total_native_tokens_reasoning": 137137629,
        "num_media_prompt": 6977,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 3235835776,
        "total_tool_calls": 81574,
        "requests_with_tool_call_errors": 451
      },
      "sentence-transformers/all-minilm-l6-v2-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sentence-transformers/all-minilm-l6-v2-20251117",
        "variant": "standard",
        "variant_permaslug": "sentence-transformers/all-minilm-l6-v2-20251117",
        "count": 202678,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 3299734751,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "thedrummer/skyfall-36b-v2": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "thedrummer/skyfall-36b-v2",
        "variant": "standard",
        "variant_permaslug": "thedrummer/skyfall-36b-v2",
        "count": 416210,
        "total_completion_tokens": 133707809,
        "total_prompt_tokens": 1280216037,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 742776336,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "x-ai/grok-3": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "x-ai/grok-3",
        "variant": "standard",
        "variant_permaslug": "x-ai/grok-3",
        "count": 476422,
        "total_completion_tokens": 115300132,
        "total_prompt_tokens": 1120575111,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 67,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 264177270,
        "total_tool_calls": 7970,
        "requests_with_tool_call_errors": 14
      },
      "baidu/ernie-4.5-21b-a3b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "baidu/ernie-4.5-21b-a3b",
        "variant": "standard",
        "variant_permaslug": "baidu/ernie-4.5-21b-a3b",
        "count": 65889,
        "total_completion_tokens": 1562112,
        "total_prompt_tokens": 19743672,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "alfredpros/codellama-7b-instruct-solidity": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "alfredpros/codellama-7b-instruct-solidity",
        "variant": "standard",
        "variant_permaslug": "alfredpros/codellama-7b-instruct-solidity",
        "count": 1519,
        "total_completion_tokens": 831158,
        "total_prompt_tokens": 775082,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepseek/deepseek-v3.2-speciale-20251201": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-v3.2-speciale-20251201",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-v3.2-speciale-20251201",
        "count": 177596,
        "total_completion_tokens": 1358657442,
        "total_prompt_tokens": 934169701,
        "total_native_tokens_reasoning": 1278127912,
        "num_media_prompt": 155,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 125180352,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-3.5-turbo-16k": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-3.5-turbo-16k",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-3.5-turbo-16k",
        "count": 35797,
        "total_completion_tokens": 5268989,
        "total_prompt_tokens": 37534101,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 29184,
        "total_tool_calls": 8468,
        "requests_with_tool_call_errors": 44
      },
      "mistralai/mistral-7b-instruct-v0.3": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-7b-instruct-v0.3",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-7b-instruct-v0.3",
        "count": 222927,
        "total_completion_tokens": 14628383,
        "total_prompt_tokens": 95797516,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "meta-llama/llama-3-70b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3-70b-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-3-70b-instruct",
        "count": 800087,
        "total_completion_tokens": 45423541,
        "total_prompt_tokens": 526319331,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 504,
        "requests_with_tool_call_errors": 165
      },
      "meta-llama/llama-3.1-70b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3.1-70b-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-3.1-70b-instruct",
        "count": 3470692,
        "total_completion_tokens": 391976554,
        "total_prompt_tokens": 3931846415,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 3528,
        "requests_with_tool_call_errors": 371
      },
      "google/gemini-2.5-flash": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-2.5-flash",
        "variant": "standard",
        "variant_permaslug": "google/gemini-2.5-flash",
        "count": 118792627,
        "total_completion_tokens": 32633634843,
        "total_prompt_tokens": 401065342390,
        "total_native_tokens_reasoning": 3968457979,
        "num_media_prompt": 25563226,
        "num_media_completion": 0,
        "num_audio_prompt": 84423,
        "total_native_tokens_cached": 111499973823,
        "total_tool_calls": 9824649,
        "requests_with_tool_call_errors": 223421
      },
      "perplexity/sonar-reasoning-pro": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "perplexity/sonar-reasoning-pro",
        "variant": "standard",
        "variant_permaslug": "perplexity/sonar-reasoning-pro",
        "count": 66275,
        "total_completion_tokens": 80042619,
        "total_prompt_tokens": 248523168,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 999,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "mistralai/mistral-tiny": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-tiny",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-tiny",
        "count": 3520358,
        "total_completion_tokens": 46946587,
        "total_prompt_tokens": 1749212745,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 8,
        "requests_with_tool_call_errors": 6
      },
      "openai/gpt-5-image": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5-image",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5-image",
        "count": 12048,
        "total_completion_tokens": 35550225,
        "total_prompt_tokens": 43659768,
        "total_native_tokens_reasoning": 17080712,
        "num_media_prompt": 12115,
        "num_media_completion": 8587,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 3937536,
        "total_tool_calls": 52,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-30b-a3b-thinking-2507": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-30b-a3b-thinking-2507",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-30b-a3b-thinking-2507",
        "count": 270089,
        "total_completion_tokens": 407521400,
        "total_prompt_tokens": 3199936946,
        "total_native_tokens_reasoning": 382628991,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 60412,
        "requests_with_tool_call_errors": 28114
      },
      "mistralai/mistral-small-24b-instruct-2501": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-small-24b-instruct-2501",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-small-24b-instruct-2501",
        "count": 4776359,
        "total_completion_tokens": 770249426,
        "total_prompt_tokens": 12070034270,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 542687182,
        "total_tool_calls": 1524,
        "requests_with_tool_call_errors": 194
      },
      "baai/bge-large-en-v1.5-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "baai/bge-large-en-v1.5-20251117",
        "variant": "standard",
        "variant_permaslug": "baai/bge-large-en-v1.5-20251117",
        "count": 30967,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 35063406,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "minimax/minimax-m2.1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "minimax/minimax-m2.1",
        "variant": "standard",
        "variant_permaslug": "minimax/minimax-m2.1",
        "count": 3867431,
        "total_completion_tokens": 2901301241,
        "total_prompt_tokens": 125423022704,
        "total_native_tokens_reasoning": 1276393993,
        "num_media_prompt": 909,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 86424779244,
        "total_tool_calls": 2277425,
        "requests_with_tool_call_errors": 76355
      },
      "minimax/minimax-01": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "minimax/minimax-01",
        "variant": "standard",
        "variant_permaslug": "minimax/minimax-01",
        "count": 342495,
        "total_completion_tokens": 47456887,
        "total_prompt_tokens": 804467251,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 14729,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "thedrummer/cydonia-24b-v4.1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "thedrummer/cydonia-24b-v4.1",
        "variant": "standard",
        "variant_permaslug": "thedrummer/cydonia-24b-v4.1",
        "count": 229983,
        "total_completion_tokens": 59751974,
        "total_prompt_tokens": 996184186,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 543782016,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "sentence-transformers/multi-qa-mpnet-base-dot-v1-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sentence-transformers/multi-qa-mpnet-base-dot-v1-20251117",
        "variant": "standard",
        "variant_permaslug": "sentence-transformers/multi-qa-mpnet-base-dot-v1-20251117",
        "count": 4562,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 5723308,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-5-codex": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5-codex",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5-codex",
        "count": 47405,
        "total_completion_tokens": 41413560,
        "total_prompt_tokens": 2221569378,
        "total_native_tokens_reasoning": 28600266,
        "num_media_prompt": 5949,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1795800320,
        "total_tool_calls": 31080,
        "requests_with_tool_call_errors": 613
      },
      "qwen/qwen3-vl-8b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-vl-8b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-vl-8b-instruct",
        "count": 1544955,
        "total_completion_tokens": 630363743,
        "total_prompt_tokens": 3872537475,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 1288165,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 96470736,
        "total_tool_calls": 210430,
        "requests_with_tool_call_errors": 6420
      },
      "deepseek/deepseek-r1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-r1",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-r1",
        "count": 878504,
        "total_completion_tokens": 1437105641,
        "total_prompt_tokens": 4061772110,
        "total_native_tokens_reasoning": 903804879,
        "num_media_prompt": 271,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 4134016,
        "total_tool_calls": 10353,
        "requests_with_tool_call_errors": 167
      },
      "qwen/qwen3-coder-plus": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-coder-plus",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-coder-plus",
        "count": 44027,
        "total_completion_tokens": 14760350,
        "total_prompt_tokens": 781060634,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 2,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 424448027,
        "total_tool_calls": 19087,
        "requests_with_tool_call_errors": 1926
      },
      "kwaipilot/kat-coder-pro-v1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "kwaipilot/kat-coder-pro-v1",
        "variant": "standard",
        "variant_permaslug": "kwaipilot/kat-coder-pro-v1",
        "count": 339738,
        "total_completion_tokens": 186890467,
        "total_prompt_tokens": 3410155373,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 42,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2466410287,
        "total_tool_calls": 34934,
        "requests_with_tool_call_errors": 12569
      },
      "allenai/olmo-2-0325-32b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "allenai/olmo-2-0325-32b-instruct",
        "variant": "standard",
        "variant_permaslug": "allenai/olmo-2-0325-32b-instruct",
        "count": 789,
        "total_completion_tokens": 157212,
        "total_prompt_tokens": 809039,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "bytedance-seed/seed-1.6-flash-20250625": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "bytedance-seed/seed-1.6-flash-20250625",
        "variant": "standard",
        "variant_permaslug": "bytedance-seed/seed-1.6-flash-20250625",
        "count": 270450,
        "total_completion_tokens": 266273807,
        "total_prompt_tokens": 752171534,
        "total_native_tokens_reasoning": 209679983,
        "num_media_prompt": 135217,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 5341,
        "requests_with_tool_call_errors": 721
      },
      "cohere/command-r-08-2024": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "cohere/command-r-08-2024",
        "variant": "standard",
        "variant_permaslug": "cohere/command-r-08-2024",
        "count": 119383,
        "total_completion_tokens": 9406384,
        "total_prompt_tokens": 86878031,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 270,
        "requests_with_tool_call_errors": 54
      },
      "mistralai/mistral-medium-3": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-medium-3",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-medium-3",
        "count": 3824585,
        "total_completion_tokens": 100351381,
        "total_prompt_tokens": 1683193893,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 3630256,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 912,
        "requests_with_tool_call_errors": 21
      },
      "nousresearch/hermes-3-llama-3.1-70b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nousresearch/hermes-3-llama-3.1-70b",
        "variant": "standard",
        "variant_permaslug": "nousresearch/hermes-3-llama-3.1-70b",
        "count": 318476,
        "total_completion_tokens": 75063934,
        "total_prompt_tokens": 635666720,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "baai/bge-base-en-v1.5-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "baai/bge-base-en-v1.5-20251117",
        "variant": "standard",
        "variant_permaslug": "baai/bge-base-en-v1.5-20251117",
        "count": 46594,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 204094803,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-oss-20b:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-oss-20b",
        "variant": "free",
        "variant_permaslug": "openai/gpt-oss-20b:free",
        "count": 165717,
        "total_completion_tokens": 184560552,
        "total_prompt_tokens": 613048019,
        "total_native_tokens_reasoning": 157393574,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 15727,
        "requests_with_tool_call_errors": 2873
      },
      "qwen/qwen3-235b-a22b-04-28": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-235b-a22b-04-28",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-235b-a22b-04-28",
        "count": 898752,
        "total_completion_tokens": 467952658,
        "total_prompt_tokens": 4917727848,
        "total_native_tokens_reasoning": 303988923,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 359924717,
        "total_tool_calls": 72793,
        "requests_with_tool_call_errors": 1895
      },
      "qwen/qwen-2-vl-7b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-2-vl-7b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen-2-vl-7b-instruct",
        "count": 454318,
        "total_completion_tokens": 22113132,
        "total_prompt_tokens": 125580239,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 443157,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "sourceful/riverflow-v2-fast-preview": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sourceful/riverflow-v2-fast-preview",
        "variant": "standard",
        "variant_permaslug": "sourceful/riverflow-v2-fast-preview",
        "count": 3220,
        "total_completion_tokens": 13443500,
        "total_prompt_tokens": 9159102,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 1106,
        "num_media_completion": 3220,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "allenai/olmo-3.1-32b-instruct-20251215": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "allenai/olmo-3.1-32b-instruct-20251215",
        "variant": "standard",
        "variant_permaslug": "allenai/olmo-3.1-32b-instruct-20251215",
        "count": 239373,
        "total_completion_tokens": 54725574,
        "total_prompt_tokens": 324656446,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 545,
        "requests_with_tool_call_errors": 71
      },
      "nvidia/nemotron-nano-9b-v2": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nvidia/nemotron-nano-9b-v2",
        "variant": "standard",
        "variant_permaslug": "nvidia/nemotron-nano-9b-v2",
        "count": 820574,
        "total_completion_tokens": 387875326,
        "total_prompt_tokens": 782384533,
        "total_native_tokens_reasoning": 96138203,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 5846,
        "requests_with_tool_call_errors": 18
      },
      "deepcogito/cogito-v2.1-671b-20251118": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepcogito/cogito-v2.1-671b-20251118",
        "variant": "standard",
        "variant_permaslug": "deepcogito/cogito-v2.1-671b-20251118",
        "count": 14993,
        "total_completion_tokens": 6859447,
        "total_prompt_tokens": 86245261,
        "total_native_tokens_reasoning": 2054131,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepseek/deepseek-r1-distill-llama-70b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-r1-distill-llama-70b",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-r1-distill-llama-70b",
        "count": 704815,
        "total_completion_tokens": 312054937,
        "total_prompt_tokens": 1262078726,
        "total_native_tokens_reasoning": 290059329,
        "num_media_prompt": 86,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 379631898,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-4o-audio-preview": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4o-audio-preview",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4o-audio-preview",
        "count": 3687,
        "total_completion_tokens": 1155720,
        "total_prompt_tokens": 3528865,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 3762,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-4-1106-preview": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4-1106-preview",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4-1106-preview",
        "count": 74715,
        "total_completion_tokens": 27808795,
        "total_prompt_tokens": 127341429,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 18,
        "requests_with_tool_call_errors": 0
      },
      "perplexity/sonar-deep-research": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "perplexity/sonar-deep-research",
        "variant": "standard",
        "variant_permaslug": "perplexity/sonar-deep-research",
        "count": 12217,
        "total_completion_tokens": 2504177538,
        "total_prompt_tokens": 63662729,
        "total_native_tokens_reasoning": 2442993161,
        "num_media_prompt": 167,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-vl-30b-a3b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-vl-30b-a3b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-vl-30b-a3b-instruct",
        "count": 1460843,
        "total_completion_tokens": 232330540,
        "total_prompt_tokens": 4944563347,
        "total_native_tokens_reasoning": 586,
        "num_media_prompt": 1704869,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2146753619,
        "total_tool_calls": 26140,
        "requests_with_tool_call_errors": 1497
      },
      "sao10k/l3-lunaris-8b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sao10k/l3-lunaris-8b",
        "variant": "standard",
        "variant_permaslug": "sao10k/l3-lunaris-8b",
        "count": 2040021,
        "total_completion_tokens": 426024756,
        "total_prompt_tokens": 5199132352,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "allenai/olmo-3.1-32b-think-20251215": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "allenai/olmo-3.1-32b-think-20251215",
        "variant": "standard",
        "variant_permaslug": "allenai/olmo-3.1-32b-think-20251215",
        "count": 66718,
        "total_completion_tokens": 180382065,
        "total_prompt_tokens": 145131698,
        "total_native_tokens_reasoning": 162193632,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 55794432,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen-plus-2025-07-28": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-plus-2025-07-28",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen-plus-2025-07-28",
        "count": 24952,
        "total_completion_tokens": 13337972,
        "total_prompt_tokens": 226323104,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 735,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 8051,
        "requests_with_tool_call_errors": 4657
      },
      "qwen/qwen-turbo-2024-11-01": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-turbo-2024-11-01",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen-turbo-2024-11-01",
        "count": 466173,
        "total_completion_tokens": 35865625,
        "total_prompt_tokens": 720730759,
        "total_native_tokens_reasoning": 1798,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 289980800,
        "total_tool_calls": 22387,
        "requests_with_tool_call_errors": 361
      },
      "openai/gpt-5.1-chat-20251113": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5.1-chat-20251113",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5.1-chat-20251113",
        "count": 473652,
        "total_completion_tokens": 89159000,
        "total_prompt_tokens": 2701746351,
        "total_native_tokens_reasoning": 11472768,
        "num_media_prompt": 166387,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 960408832,
        "total_tool_calls": 22170,
        "requests_with_tool_call_errors": 63
      },
      "sentence-transformers/all-mpnet-base-v2-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sentence-transformers/all-mpnet-base-v2-20251117",
        "variant": "standard",
        "variant_permaslug": "sentence-transformers/all-mpnet-base-v2-20251117",
        "count": 25831,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 90481104,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-5-nano-2025-08-07": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5-nano-2025-08-07",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5-nano-2025-08-07",
        "count": 8297390,
        "total_completion_tokens": 9746751507,
        "total_prompt_tokens": 30790423084,
        "total_native_tokens_reasoning": 8738479170,
        "num_media_prompt": 726700,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 6627920128,
        "total_tool_calls": 503418,
        "requests_with_tool_call_errors": 3167
      },
      "qwen/qwen3-next-80b-a3b-thinking-2509": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-next-80b-a3b-thinking-2509",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-next-80b-a3b-thinking-2509",
        "count": 235121,
        "total_completion_tokens": 1355958083,
        "total_prompt_tokens": 2085202997,
        "total_native_tokens_reasoning": 1293494029,
        "num_media_prompt": 1,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 18020,
        "requests_with_tool_call_errors": 1688
      },
      "mistralai/pixtral-large-2411": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/pixtral-large-2411",
        "variant": "standard",
        "variant_permaslug": "mistralai/pixtral-large-2411",
        "count": 8350,
        "total_completion_tokens": 2586036,
        "total_prompt_tokens": 24653181,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 5302,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 197,
        "requests_with_tool_call_errors": 19
      },
      "baai/bge-m3-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "baai/bge-m3-20251117",
        "variant": "standard",
        "variant_permaslug": "baai/bge-m3-20251117",
        "count": 1666662,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 1153816181,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "mistralai/ministral-8b-2512": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/ministral-8b-2512",
        "variant": "standard",
        "variant_permaslug": "mistralai/ministral-8b-2512",
        "count": 2600830,
        "total_completion_tokens": 67598782,
        "total_prompt_tokens": 1843994144,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 4934,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 12173,
        "requests_with_tool_call_errors": 350
      },
      "deepseek/deepseek-v3.2-exp": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-v3.2-exp",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-v3.2-exp",
        "count": 3725188,
        "total_completion_tokens": 1719237329,
        "total_prompt_tokens": 21280045519,
        "total_native_tokens_reasoning": 525104715,
        "num_media_prompt": 1028,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 334653696,
        "total_tool_calls": 406656,
        "requests_with_tool_call_errors": 7207
      },
      "qwen/qwen3-vl-32b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-vl-32b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-vl-32b-instruct",
        "count": 98969,
        "total_completion_tokens": 44886191,
        "total_prompt_tokens": 269667732,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 94947,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-max": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-max",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-max",
        "count": 261638,
        "total_completion_tokens": 106902304,
        "total_prompt_tokens": 1438216194,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 104,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 135429552,
        "total_tool_calls": 29005,
        "requests_with_tool_call_errors": 1578
      },
      "qwen/qwen3-14b-04-28": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-14b-04-28",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-14b-04-28",
        "count": 2013703,
        "total_completion_tokens": 1083991811,
        "total_prompt_tokens": 3193053562,
        "total_native_tokens_reasoning": 176972281,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1253558411,
        "total_tool_calls": 21904,
        "requests_with_tool_call_errors": 645
      },
      "gryphe/mythomax-l2-13b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "gryphe/mythomax-l2-13b",
        "variant": "standard",
        "variant_permaslug": "gryphe/mythomax-l2-13b",
        "count": 1336595,
        "total_completion_tokens": 172868745,
        "total_prompt_tokens": 1369804365,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-coder-480b-a35b-07-25": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-coder-480b-a35b-07-25",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-coder-480b-a35b-07-25",
        "count": 1183519,
        "total_completion_tokens": 350046130,
        "total_prompt_tokens": 20897032270,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 55,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2111225391,
        "total_tool_calls": 264493,
        "requests_with_tool_call_errors": 16502
      },
      "z-ai/glm-4.5-air": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "z-ai/glm-4.5-air",
        "variant": "standard",
        "variant_permaslug": "z-ai/glm-4.5-air",
        "count": 1580562,
        "total_completion_tokens": 365941272,
        "total_prompt_tokens": 5621219360,
        "total_native_tokens_reasoning": 163947073,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2789557373,
        "total_tool_calls": 156587,
        "requests_with_tool_call_errors": 2300
      },
      "google/gemini-2.0-flash-exp:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-2.0-flash-exp",
        "variant": "free",
        "variant_permaslug": "google/gemini-2.0-flash-exp:free",
        "count": 201469,
        "total_completion_tokens": 92027745,
        "total_prompt_tokens": 1262025491,
        "total_native_tokens_reasoning": 51,
        "num_media_prompt": 91813,
        "num_media_completion": 798,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 4343,
        "requests_with_tool_call_errors": 282
      },
      "mistralai/devstral-2512:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/devstral-2512",
        "variant": "free",
        "variant_permaslug": "mistralai/devstral-2512:free",
        "count": 11232826,
        "total_completion_tokens": 7271160649,
        "total_prompt_tokens": 136050128592,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 2368802,
        "requests_with_tool_call_errors": 93192
      },
      "google/gemini-3-flash-preview-20251217": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-3-flash-preview-20251217",
        "variant": "standard",
        "variant_permaslug": "google/gemini-3-flash-preview-20251217",
        "count": 57458732,
        "total_completion_tokens": 22106001164,
        "total_prompt_tokens": 459455540389,
        "total_native_tokens_reasoning": 4760691917,
        "num_media_prompt": 15751081,
        "num_media_completion": 0,
        "num_audio_prompt": 204830,
        "total_native_tokens_cached": 212410579570,
        "total_tool_calls": 10603056,
        "requests_with_tool_call_errors": 293287
      },
      "aion-labs/aion-1.0": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "aion-labs/aion-1.0",
        "variant": "standard",
        "variant_permaslug": "aion-labs/aion-1.0",
        "count": 29280,
        "total_completion_tokens": 57208467,
        "total_prompt_tokens": 322815467,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "meta-llama/llama-4-scout-17b-16e-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "count": 5324810,
        "total_completion_tokens": 588960516,
        "total_prompt_tokens": 10487165000,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 2087751,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 84259,
        "requests_with_tool_call_errors": 16180
      },
      "google/gemini-2.5-flash-preview-09-2025": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-2.5-flash-preview-09-2025",
        "variant": "standard",
        "variant_permaslug": "google/gemini-2.5-flash-preview-09-2025",
        "count": 4078726,
        "total_completion_tokens": 4069615704,
        "total_prompt_tokens": 22083323174,
        "total_native_tokens_reasoning": 1148685235,
        "num_media_prompt": 1204831,
        "num_media_completion": 0,
        "num_audio_prompt": 1216,
        "total_native_tokens_cached": 7153010595,
        "total_tool_calls": 350281,
        "requests_with_tool_call_errors": 5058
      },
      "x-ai/grok-4-07-09": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "x-ai/grok-4-07-09",
        "variant": "standard",
        "variant_permaslug": "x-ai/grok-4-07-09",
        "count": 674249,
        "total_completion_tokens": 970725138,
        "total_prompt_tokens": 4454055300,
        "total_native_tokens_reasoning": 682777153,
        "num_media_prompt": 244424,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1955563021,
        "total_tool_calls": 52815,
        "requests_with_tool_call_errors": 485
      },
      "google/gemma-3-4b-it:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemma-3-4b-it",
        "variant": "free",
        "variant_permaslug": "google/gemma-3-4b-it:free",
        "count": 62672,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 59826949,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 81187,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-4o-2024-11-20": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4o-2024-11-20",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4o-2024-11-20",
        "count": 759304,
        "total_completion_tokens": 114695200,
        "total_prompt_tokens": 1153645774,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 135938,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 289417984,
        "total_tool_calls": 14815,
        "requests_with_tool_call_errors": 215
      },
      "morph/morph-v3-large": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "morph/morph-v3-large",
        "variant": "standard",
        "variant_permaslug": "morph/morph-v3-large",
        "count": 107502,
        "total_completion_tokens": 494160207,
        "total_prompt_tokens": 557403318,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "raifle/sorcererlm-8x22b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "raifle/sorcererlm-8x22b",
        "variant": "standard",
        "variant_permaslug": "raifle/sorcererlm-8x22b",
        "count": 1868,
        "total_completion_tokens": 464895,
        "total_prompt_tokens": 2998219,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "google/gemma-3-12b-it:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemma-3-12b-it",
        "variant": "free",
        "variant_permaslug": "google/gemma-3-12b-it:free",
        "count": 59109,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 46358074,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 16463,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "google/gemini-2.5-flash-lite": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-2.5-flash-lite",
        "variant": "standard",
        "variant_permaslug": "google/gemini-2.5-flash-lite",
        "count": 100763704,
        "total_completion_tokens": 29509868403,
        "total_prompt_tokens": 279496778158,
        "total_native_tokens_reasoning": 1994474676,
        "num_media_prompt": 218112432,
        "num_media_completion": 0,
        "num_audio_prompt": 27578,
        "total_native_tokens_cached": 48436325479,
        "total_tool_calls": 1816572,
        "requests_with_tool_call_errors": 71516
      },
      "google/gemma-3n-e4b-it:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemma-3n-e4b-it",
        "variant": "free",
        "variant_permaslug": "google/gemma-3n-e4b-it:free",
        "count": 32232,
        "total_completion_tokens": 8736480,
        "total_prompt_tokens": 15051432,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "microsoft/wizardlm-2-8x22b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "microsoft/wizardlm-2-8x22b",
        "variant": "standard",
        "variant_permaslug": "microsoft/wizardlm-2-8x22b",
        "count": 1635281,
        "total_completion_tokens": 306566262,
        "total_prompt_tokens": 1856072539,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "tngtech/deepseek-r1t-chimera": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "tngtech/deepseek-r1t-chimera",
        "variant": "standard",
        "variant_permaslug": "tngtech/deepseek-r1t-chimera",
        "count": 249074,
        "total_completion_tokens": 36072104,
        "total_prompt_tokens": 1260765309,
        "total_native_tokens_reasoning": 63835,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 206058687,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepseek/deepseek-r1-0528": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-r1-0528",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-r1-0528",
        "count": 1588173,
        "total_completion_tokens": 1798290646,
        "total_prompt_tokens": 13218610295,
        "total_native_tokens_reasoning": 1173246838,
        "num_media_prompt": 99,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 3264724729,
        "total_tool_calls": 20190,
        "requests_with_tool_call_errors": 490
      },
      "mistralai/mistral-large-2512": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-large-2512",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-large-2512",
        "count": 820817,
        "total_completion_tokens": 222131677,
        "total_prompt_tokens": 2722466669,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 182827,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 14182,
        "requests_with_tool_call_errors": 535
      },
      "sourceful/riverflow-v2-standard-preview": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sourceful/riverflow-v2-standard-preview",
        "variant": "standard",
        "variant_permaslug": "sourceful/riverflow-v2-standard-preview",
        "count": 8301,
        "total_completion_tokens": 34656675,
        "total_prompt_tokens": 22818904,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 8549,
        "num_media_completion": 8301,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-235b-a22b-thinking-2507": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-235b-a22b-thinking-2507",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-235b-a22b-thinking-2507",
        "count": 567284,
        "total_completion_tokens": 884190129,
        "total_prompt_tokens": 2384465062,
        "total_native_tokens_reasoning": 752273239,
        "num_media_prompt": 98,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 480966989,
        "total_tool_calls": 61145,
        "requests_with_tool_call_errors": 13322
      },
      "amazon/nova-premier-v1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "amazon/nova-premier-v1",
        "variant": "standard",
        "variant_permaslug": "amazon/nova-premier-v1",
        "count": 37345,
        "total_completion_tokens": 2899757,
        "total_prompt_tokens": 73437400,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 33935,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 116,
        "requests_with_tool_call_errors": 24
      },
      "openai/gpt-5.1-codex-max-20251204": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5.1-codex-max-20251204",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5.1-codex-max-20251204",
        "count": 132068,
        "total_completion_tokens": 124570723,
        "total_prompt_tokens": 4257757274,
        "total_native_tokens_reasoning": 74258542,
        "num_media_prompt": 12158,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 3348955776,
        "total_tool_calls": 70117,
        "requests_with_tool_call_errors": 608
      },
      "nvidia/llama-3.1-nemotron-ultra-253b-v1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
        "variant": "standard",
        "variant_permaslug": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
        "count": 4538676,
        "total_completion_tokens": 27559716,
        "total_prompt_tokens": 2696526467,
        "total_native_tokens_reasoning": 41270,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-235b-a22b-07-25": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-235b-a22b-07-25",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-235b-a22b-07-25",
        "count": 21188941,
        "total_completion_tokens": 4908370608,
        "total_prompt_tokens": 63037945463,
        "total_native_tokens_reasoning": 13581,
        "num_media_prompt": 88,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 13749945388,
        "total_tool_calls": 383443,
        "requests_with_tool_call_errors": 11054
      },
      "nousresearch/hermes-4-405b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nousresearch/hermes-4-405b",
        "variant": "standard",
        "variant_permaslug": "nousresearch/hermes-4-405b",
        "count": 102505,
        "total_completion_tokens": 67651287,
        "total_prompt_tokens": 411423476,
        "total_native_tokens_reasoning": 39370857,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwq-32b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwq-32b",
        "variant": "standard",
        "variant_permaslug": "qwen/qwq-32b",
        "count": 328775,
        "total_completion_tokens": 326717740,
        "total_prompt_tokens": 596507128,
        "total_native_tokens_reasoning": 264485560,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 5269,
        "requests_with_tool_call_errors": 8
      },
      "z-ai/glm-4.6-20251208": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "z-ai/glm-4.6-20251208",
        "variant": "standard",
        "variant_permaslug": "z-ai/glm-4.6-20251208",
        "count": 246100,
        "total_completion_tokens": 742226509,
        "total_prompt_tokens": 1255841121,
        "total_native_tokens_reasoning": 549383269,
        "num_media_prompt": 205418,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 113081215,
        "total_tool_calls": 12555,
        "requests_with_tool_call_errors": 564
      },
      "mistralai/mistral-small-3.1-24b-instruct-2503": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
        "count": 1219343,
        "total_completion_tokens": 103500299,
        "total_prompt_tokens": 1011975906,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 16316,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 157824173,
        "total_tool_calls": 147,
        "requests_with_tool_call_errors": 1
      },
      "nvidia/llama-3.3-nemotron-super-49b-v1.5": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
        "variant": "standard",
        "variant_permaslug": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
        "count": 85082,
        "total_completion_tokens": 218068020,
        "total_prompt_tokens": 478252300,
        "total_native_tokens_reasoning": 205998499,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 1436,
        "requests_with_tool_call_errors": 30
      },
      "openai/text-embedding-3-large": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/text-embedding-3-large",
        "variant": "standard",
        "variant_permaslug": "openai/text-embedding-3-large",
        "count": 4660346,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 3656998210,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-4": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4",
        "count": 69883,
        "total_completion_tokens": 12744482,
        "total_prompt_tokens": 66571980,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2962048,
        "total_tool_calls": 7232,
        "requests_with_tool_call_errors": 378
      },
      "undi95/remm-slerp-l2-13b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "undi95/remm-slerp-l2-13b",
        "variant": "standard",
        "variant_permaslug": "undi95/remm-slerp-l2-13b",
        "count": 195646,
        "total_completion_tokens": 19688306,
        "total_prompt_tokens": 297019591,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "meta-llama/llama-3.2-3b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3.2-3b-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-3.2-3b-instruct",
        "count": 9079493,
        "total_completion_tokens": 1939518063,
        "total_prompt_tokens": 5958086927,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 339,
        "requests_with_tool_call_errors": 70
      },
      "meta-llama/llama-3.2-3b-instruct:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3.2-3b-instruct",
        "variant": "free",
        "variant_permaslug": "meta-llama/llama-3.2-3b-instruct:free",
        "count": 85710,
        "total_completion_tokens": 18870413,
        "total_prompt_tokens": 132382655,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "stepfun-ai/step3": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "stepfun-ai/step3",
        "variant": "standard",
        "variant_permaslug": "stepfun-ai/step3",
        "count": 3334,
        "total_completion_tokens": 10174897,
        "total_prompt_tokens": 6892078,
        "total_native_tokens_reasoning": 6175374,
        "num_media_prompt": 2509,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 18,
        "requests_with_tool_call_errors": 11
      },
      "qwen/qwen3-next-80b-a3b-instruct-2509:free": {
        "date": "2026-01-15 00:00:00",
        "model_permaslug": "qwen/qwen3-next-80b-a3b-instruct-2509",
        "variant": "free",
        "variant_permaslug": "qwen/qwen3-next-80b-a3b-instruct-2509:free",
        "count": 3569,
        "total_completion_tokens": 2102119,
        "total_prompt_tokens": 38336293,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 466,
        "requests_with_tool_call_errors": 54
      },
      "cohere/command-r-plus-08-2024": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "cohere/command-r-plus-08-2024",
        "variant": "standard",
        "variant_permaslug": "cohere/command-r-plus-08-2024",
        "count": 7195,
        "total_completion_tokens": 1322418,
        "total_prompt_tokens": 18140141,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 1482,
        "requests_with_tool_call_errors": 73
      },
      "mancer/weaver": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mancer/weaver",
        "variant": "standard",
        "variant_permaslug": "mancer/weaver",
        "count": 4768,
        "total_completion_tokens": 1303579,
        "total_prompt_tokens": 3030379,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "z-ai/glm-4.7-20251222": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "z-ai/glm-4.7-20251222",
        "variant": "standard",
        "variant_permaslug": "z-ai/glm-4.7-20251222",
        "count": 12868586,
        "total_completion_tokens": 10115328456,
        "total_prompt_tokens": 157574344326,
        "total_native_tokens_reasoning": 4043292156,
        "num_media_prompt": 1771,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 70311576027,
        "total_tool_calls": 6077455,
        "requests_with_tool_call_errors": 172029
      },
      "liquid/lfm-2.2-6b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "liquid/lfm-2.2-6b",
        "variant": "standard",
        "variant_permaslug": "liquid/lfm-2.2-6b",
        "count": 49755,
        "total_completion_tokens": 9365063,
        "total_prompt_tokens": 10307768,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "black-forest-labs/flux.2-pro": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "black-forest-labs/flux.2-pro",
        "variant": "standard",
        "variant_permaslug": "black-forest-labs/flux.2-pro",
        "count": 51215,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 25303251,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 7320,
        "num_media_completion": 51215,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "mistralai/ministral-8b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/ministral-8b",
        "variant": "standard",
        "variant_permaslug": "mistralai/ministral-8b",
        "count": 886278,
        "total_completion_tokens": 255020125,
        "total_prompt_tokens": 292484264,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 1679,
        "requests_with_tool_call_errors": 108
      },
      "qwen/qwen3-32b-04-28": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-32b-04-28",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-32b-04-28",
        "count": 12936535,
        "total_completion_tokens": 1853969312,
        "total_prompt_tokens": 11053488696,
        "total_native_tokens_reasoning": 1391811263,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1320329938,
        "total_tool_calls": 268765,
        "requests_with_tool_call_errors": 2612
      },
      "openai/o3-2025-04-16": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/o3-2025-04-16",
        "variant": "standard",
        "variant_permaslug": "openai/o3-2025-04-16",
        "count": 185759,
        "total_completion_tokens": 128283899,
        "total_prompt_tokens": 566805656,
        "total_native_tokens_reasoning": 85703486,
        "num_media_prompt": 117760,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 193083648,
        "total_tool_calls": 11378,
        "requests_with_tool_call_errors": 9
      },
      "mistralai/mixtral-8x7b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mixtral-8x7b-instruct",
        "variant": "standard",
        "variant_permaslug": "mistralai/mixtral-8x7b-instruct",
        "count": 8723858,
        "total_completion_tokens": 2245401572,
        "total_prompt_tokens": 1962294709,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 39,
        "requests_with_tool_call_errors": 6
      },
      "meta-llama/llama-guard-3-8b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-guard-3-8b",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-guard-3-8b",
        "count": 204199,
        "total_completion_tokens": 21705322,
        "total_prompt_tokens": 163263051,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "morph/morph-v3-fast": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "morph/morph-v3-fast",
        "variant": "standard",
        "variant_permaslug": "morph/morph-v3-fast",
        "count": 7532,
        "total_completion_tokens": 32924102,
        "total_prompt_tokens": 33857513,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "neversleep/noromaid-20b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "neversleep/noromaid-20b",
        "variant": "standard",
        "variant_permaslug": "neversleep/noromaid-20b",
        "count": 15885,
        "total_completion_tokens": 2007434,
        "total_prompt_tokens": 24401546,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-4-turbo": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4-turbo",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4-turbo",
        "count": 236657,
        "total_completion_tokens": 22006219,
        "total_prompt_tokens": 653819761,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 9180,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 3511,
        "requests_with_tool_call_errors": 79
      },
      "z-ai/glm-4.5": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "z-ai/glm-4.5",
        "variant": "standard",
        "variant_permaslug": "z-ai/glm-4.5",
        "count": 335552,
        "total_completion_tokens": 193462395,
        "total_prompt_tokens": 2743545897,
        "total_native_tokens_reasoning": 122884708,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1422282466,
        "total_tool_calls": 44498,
        "requests_with_tool_call_errors": 3615
      },
      "qwen/qwen-2.5-coder-32b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-2.5-coder-32b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen-2.5-coder-32b-instruct",
        "count": 717999,
        "total_completion_tokens": 213821246,
        "total_prompt_tokens": 794625163,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 137768890,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen2.5-coder-7b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen2.5-coder-7b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen2.5-coder-7b-instruct",
        "count": 55372,
        "total_completion_tokens": 44655038,
        "total_prompt_tokens": 44094792,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "arcee-ai/trinity-mini-20251201": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "arcee-ai/trinity-mini-20251201",
        "variant": "standard",
        "variant_permaslug": "arcee-ai/trinity-mini-20251201",
        "count": 50516,
        "total_completion_tokens": 40416155,
        "total_prompt_tokens": 60383545,
        "total_native_tokens_reasoning": 32191468,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 224,
        "requests_with_tool_call_errors": 35
      },
      "nvidia/nemotron-nano-12b-v2-vl": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nvidia/nemotron-nano-12b-v2-vl",
        "variant": "standard",
        "variant_permaslug": "nvidia/nemotron-nano-12b-v2-vl",
        "count": 12158,
        "total_completion_tokens": 14146998,
        "total_prompt_tokens": 31369301,
        "total_native_tokens_reasoning": 9103926,
        "num_media_prompt": 11083,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "xiaomi/mimo-v2-flash-20251210:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "xiaomi/mimo-v2-flash-20251210",
        "variant": "free",
        "variant_permaslug": "xiaomi/mimo-v2-flash-20251210:free",
        "count": 54933554,
        "total_completion_tokens": 57435342206,
        "total_prompt_tokens": 516660536759,
        "total_native_tokens_reasoning": 20414762729,
        "num_media_prompt": 776,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 48651590126,
        "total_tool_calls": 4480897,
        "requests_with_tool_call_errors": 77617
      },
      "mistralai/mistral-large-2411": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-large-2411",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-large-2411",
        "count": 83681,
        "total_completion_tokens": 29155963,
        "total_prompt_tokens": 308218080,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 5517,
        "requests_with_tool_call_errors": 54
      },
      "sao10k/l3.1-70b-hanami-x1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sao10k/l3.1-70b-hanami-x1",
        "variant": "standard",
        "variant_permaslug": "sao10k/l3.1-70b-hanami-x1",
        "count": 2128,
        "total_completion_tokens": 295284,
        "total_prompt_tokens": 3520028,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "google/gemma-3n-e4b-it": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemma-3n-e4b-it",
        "variant": "standard",
        "variant_permaslug": "google/gemma-3n-e4b-it",
        "count": 2099048,
        "total_completion_tokens": 235773073,
        "total_prompt_tokens": 854984897,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 2,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-5.2-20251211": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5.2-20251211",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5.2-20251211",
        "count": 6376130,
        "total_completion_tokens": 5972124049,
        "total_prompt_tokens": 94784624822,
        "total_native_tokens_reasoning": 3445268823,
        "num_media_prompt": 4785838,
        "num_media_completion": 6,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 52639851136,
        "total_tool_calls": 1484039,
        "requests_with_tool_call_errors": 14187
      },
      "openai/gpt-oss-safeguard-20b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-oss-safeguard-20b",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-oss-safeguard-20b",
        "count": 2549103,
        "total_completion_tokens": 1474458849,
        "total_prompt_tokens": 6321779404,
        "total_native_tokens_reasoning": 1155262410,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 4679261184,
        "total_tool_calls": 39981,
        "requests_with_tool_call_errors": 288
      },
      "mistralai/mistral-large-2407": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-large-2407",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-large-2407",
        "count": 8036,
        "total_completion_tokens": 3188868,
        "total_prompt_tokens": 82172899,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 6,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 167,
        "requests_with_tool_call_errors": 17
      },
      "mistralai/ministral-3b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/ministral-3b",
        "variant": "standard",
        "variant_permaslug": "mistralai/ministral-3b",
        "count": 5136248,
        "total_completion_tokens": 226983952,
        "total_prompt_tokens": 3466024500,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 26,
        "requests_with_tool_call_errors": 2
      },
      "intfloat/e5-large-v2-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "intfloat/e5-large-v2-20251117",
        "variant": "standard",
        "variant_permaslug": "intfloat/e5-large-v2-20251117",
        "count": 38061,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 21747117,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "x-ai/grok-4.1-fast": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "x-ai/grok-4.1-fast",
        "variant": "standard",
        "variant_permaslug": "x-ai/grok-4.1-fast",
        "count": 50857363,
        "total_completion_tokens": 55107966719,
        "total_prompt_tokens": 249009150095,
        "total_native_tokens_reasoning": 41586333503,
        "num_media_prompt": 10069607,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 57165158874,
        "total_tool_calls": 1871131,
        "requests_with_tool_call_errors": 12943
      },
      "mistralai/mistral-embed-2312": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-embed-2312",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-embed-2312",
        "count": 189114,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 560401304,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "google/gemma-3-27b-it:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemma-3-27b-it",
        "variant": "free",
        "variant_permaslug": "google/gemma-3-27b-it:free",
        "count": 726684,
        "total_completion_tokens": 623901900,
        "total_prompt_tokens": 3157613427,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 21371,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 2588,
        "requests_with_tool_call_errors": 305
      },
      "qwen/qwen-2.5-7b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-2.5-7b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen-2.5-7b-instruct",
        "count": 6274091,
        "total_completion_tokens": 713913835,
        "total_prompt_tokens": 4202537703,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 594096,
        "requests_with_tool_call_errors": 7039
      },
      "openai/gpt-5-2025-08-07": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5-2025-08-07",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5-2025-08-07",
        "count": 3931203,
        "total_completion_tokens": 4983977455,
        "total_prompt_tokens": 54374278669,
        "total_native_tokens_reasoning": 3967044379,
        "num_media_prompt": 8803795,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 36424814976,
        "total_tool_calls": 1501242,
        "requests_with_tool_call_errors": 4415
      },
      "perplexity/sonar": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "perplexity/sonar",
        "variant": "standard",
        "variant_permaslug": "perplexity/sonar",
        "count": 838898,
        "total_completion_tokens": 425524636,
        "total_prompt_tokens": 874511602,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 7375,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "amazon/nova-pro-v1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "amazon/nova-pro-v1",
        "variant": "standard",
        "variant_permaslug": "amazon/nova-pro-v1",
        "count": 17795,
        "total_completion_tokens": 1753058,
        "total_prompt_tokens": 20699926,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 1395,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 147,
        "requests_with_tool_call_errors": 8
      },
      "meta-llama/llama-3.3-70b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3.3-70b-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-3.3-70b-instruct",
        "count": 20154920,
        "total_completion_tokens": 1909245883,
        "total_prompt_tokens": 21908713249,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 4494126937,
        "total_tool_calls": 607092,
        "requests_with_tool_call_errors": 178149
      },
      "tngtech/deepseek-r1t-chimera:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "tngtech/deepseek-r1t-chimera",
        "variant": "free",
        "variant_permaslug": "tngtech/deepseek-r1t-chimera:free",
        "count": 2332726,
        "total_completion_tokens": 1229777385,
        "total_prompt_tokens": 24523093129,
        "total_native_tokens_reasoning": 23626428,
        "num_media_prompt": 5,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 6260629729,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "mistralai/mistral-nemo": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-nemo",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-nemo",
        "count": 29360247,
        "total_completion_tokens": 3771643201,
        "total_prompt_tokens": 84729170922,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 1227,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1190394599,
        "total_tool_calls": 3917,
        "requests_with_tool_call_errors": 126
      },
      "arcee-ai/trinity-mini-20251201:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "arcee-ai/trinity-mini-20251201",
        "variant": "free",
        "variant_permaslug": "arcee-ai/trinity-mini-20251201:free",
        "count": 73174,
        "total_completion_tokens": 141552049,
        "total_prompt_tokens": 317401866,
        "total_native_tokens_reasoning": 116373481,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 3572,
        "requests_with_tool_call_errors": 1252
      },
      "meta-llama/llama-guard-2-8b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-guard-2-8b",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-guard-2-8b",
        "count": 39300,
        "total_completion_tokens": 53475,
        "total_prompt_tokens": 465391,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-4.1-mini-2025-04-14": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4.1-mini-2025-04-14",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4.1-mini-2025-04-14",
        "count": 20280192,
        "total_completion_tokens": 3008613295,
        "total_prompt_tokens": 41888764778,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 3055411,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 10101863552,
        "total_tool_calls": 1984384,
        "requests_with_tool_call_errors": 13335
      },
      "inflection/inflection-3-pi": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "inflection/inflection-3-pi",
        "variant": "standard",
        "variant_permaslug": "inflection/inflection-3-pi",
        "count": 34488,
        "total_completion_tokens": 320812,
        "total_prompt_tokens": 2904971,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "perplexity/sonar-pro-search": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "perplexity/sonar-pro-search",
        "variant": "standard",
        "variant_permaslug": "perplexity/sonar-pro-search",
        "count": 90339,
        "total_completion_tokens": 50093255,
        "total_prompt_tokens": 252302741,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 2161,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 837,
        "requests_with_tool_call_errors": 0
      },
      "openai/o4-mini-high-2025-04-16": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/o4-mini-high-2025-04-16",
        "variant": "standard",
        "variant_permaslug": "openai/o4-mini-high-2025-04-16",
        "count": 230262,
        "total_completion_tokens": 180581368,
        "total_prompt_tokens": 576705658,
        "total_native_tokens_reasoning": 153278905,
        "num_media_prompt": 8846,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 139393024,
        "total_tool_calls": 4034,
        "requests_with_tool_call_errors": 2
      },
      "nvidia/nemotron-3-nano-30b-a3b:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nvidia/nemotron-3-nano-30b-a3b",
        "variant": "free",
        "variant_permaslug": "nvidia/nemotron-3-nano-30b-a3b:free",
        "count": 434264,
        "total_completion_tokens": 875503480,
        "total_prompt_tokens": 2913863349,
        "total_native_tokens_reasoning": 667885569,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 49244,
        "requests_with_tool_call_errors": 12261
      },
      "openai/o4-mini-2025-04-16": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/o4-mini-2025-04-16",
        "variant": "standard",
        "variant_permaslug": "openai/o4-mini-2025-04-16",
        "count": 301332,
        "total_completion_tokens": 206860466,
        "total_prompt_tokens": 964740564,
        "total_native_tokens_reasoning": 161861759,
        "num_media_prompt": 53737,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 316912896,
        "total_tool_calls": 20929,
        "requests_with_tool_call_errors": 19
      },
      "opengvlab/internvl3-78b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "opengvlab/internvl3-78b",
        "variant": "standard",
        "variant_permaslug": "opengvlab/internvl3-78b",
        "count": 615532,
        "total_completion_tokens": 11913970,
        "total_prompt_tokens": 287188624,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 41129,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 132846848,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "amazon/nova-micro-v1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "amazon/nova-micro-v1",
        "variant": "standard",
        "variant_permaslug": "amazon/nova-micro-v1",
        "count": 1326865,
        "total_completion_tokens": 305364815,
        "total_prompt_tokens": 1740410238,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 13740,
        "requests_with_tool_call_errors": 489
      },
      "qwen/qwen-2-vl-7b-instruct:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-2-vl-7b-instruct",
        "variant": "free",
        "variant_permaslug": "qwen/qwen-2-vl-7b-instruct:free",
        "count": 70417,
        "total_completion_tokens": 19482832,
        "total_prompt_tokens": 217928473,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 79757,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "z-ai/glm-4.6:exacto": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "z-ai/glm-4.6",
        "variant": "exacto",
        "variant_permaslug": "z-ai/glm-4.6:exacto",
        "count": 101584,
        "total_completion_tokens": 31466311,
        "total_prompt_tokens": 555171874,
        "total_native_tokens_reasoning": 23321056,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 215974932,
        "total_tool_calls": 16599,
        "requests_with_tool_call_errors": 4838
      },
      "amazon/nova-2-lite-v1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "amazon/nova-2-lite-v1",
        "variant": "standard",
        "variant_permaslug": "amazon/nova-2-lite-v1",
        "count": 28679,
        "total_completion_tokens": 13348288,
        "total_prompt_tokens": 127323299,
        "total_native_tokens_reasoning": 4713,
        "num_media_prompt": 11651,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 2164,
        "requests_with_tool_call_errors": 24
      },
      "black-forest-labs/flux.2-flex": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "black-forest-labs/flux.2-flex",
        "variant": "standard",
        "variant_permaslug": "black-forest-labs/flux.2-flex",
        "count": 1934,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 1747622,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 587,
        "num_media_completion": 1934,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "tencent/hunyuan-a13b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "tencent/hunyuan-a13b-instruct",
        "variant": "standard",
        "variant_permaslug": "tencent/hunyuan-a13b-instruct",
        "count": 20123,
        "total_completion_tokens": 10135143,
        "total_prompt_tokens": 28715970,
        "total_native_tokens_reasoning": 18248,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen-max-2025-01-25": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-max-2025-01-25",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen-max-2025-01-25",
        "count": 28486,
        "total_completion_tokens": 7644108,
        "total_prompt_tokens": 85378181,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 36624896,
        "total_tool_calls": 3042,
        "requests_with_tool_call_errors": 410
      },
      "google/gemini-embedding-001": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-embedding-001",
        "variant": "standard",
        "variant_permaslug": "google/gemini-embedding-001",
        "count": 4507220,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 2921396963,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-oss-120b:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-oss-120b",
        "variant": "free",
        "variant_permaslug": "openai/gpt-oss-120b:free",
        "count": 243204,
        "total_completion_tokens": 206851042,
        "total_prompt_tokens": 1896113680,
        "total_native_tokens_reasoning": 119501762,
        "num_media_prompt": 19,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 26916,
        "requests_with_tool_call_errors": 2721
      },
      "minimax/minimax-m1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "minimax/minimax-m1",
        "variant": "standard",
        "variant_permaslug": "minimax/minimax-m1",
        "count": 6236,
        "total_completion_tokens": 5440528,
        "total_prompt_tokens": 110008259,
        "total_native_tokens_reasoning": 3462672,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 1893,
        "requests_with_tool_call_errors": 844
      },
      "bytedance-seed/seed-1.6-20250625": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "bytedance-seed/seed-1.6-20250625",
        "variant": "standard",
        "variant_permaslug": "bytedance-seed/seed-1.6-20250625",
        "count": 1398166,
        "total_completion_tokens": 569425678,
        "total_prompt_tokens": 6569903726,
        "total_native_tokens_reasoning": 404879909,
        "num_media_prompt": 1314340,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 5726,
        "requests_with_tool_call_errors": 213
      },
      "google/gemma-3n-e2b-it:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemma-3n-e2b-it",
        "variant": "free",
        "variant_permaslug": "google/gemma-3n-e2b-it:free",
        "count": 102006,
        "total_completion_tokens": 33686660,
        "total_prompt_tokens": 14956111,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 2,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-5-image-mini": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5-image-mini",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5-image-mini",
        "count": 67673,
        "total_completion_tokens": 107576636,
        "total_prompt_tokens": 156361163,
        "total_native_tokens_reasoning": 54054963,
        "num_media_prompt": 44418,
        "num_media_completion": 25500,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 6397056,
        "total_tool_calls": 132,
        "requests_with_tool_call_errors": 0
      },
      "google/gemini-3-pro-image-preview-20251120": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-3-pro-image-preview-20251120",
        "variant": "standard",
        "variant_permaslug": "google/gemini-3-pro-image-preview-20251120",
        "count": 1350226,
        "total_completion_tokens": 1893649374,
        "total_prompt_tokens": 1964766841,
        "total_native_tokens_reasoning": 452748923,
        "num_media_prompt": 1717939,
        "num_media_completion": 1457961,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 30601760,
        "total_tool_calls": 105,
        "requests_with_tool_call_errors": 105
      },
      "x-ai/grok-4-fast": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "x-ai/grok-4-fast",
        "variant": "standard",
        "variant_permaslug": "x-ai/grok-4-fast",
        "count": 23848317,
        "total_completion_tokens": 19729668412,
        "total_prompt_tokens": 117228184384,
        "total_native_tokens_reasoning": 10936880059,
        "num_media_prompt": 3558407,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 25634832319,
        "total_tool_calls": 758374,
        "requests_with_tool_call_errors": 907
      },
      "qwen/qwen-vl-plus": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-vl-plus",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen-vl-plus",
        "count": 14086,
        "total_completion_tokens": 3414556,
        "total_prompt_tokens": 30855179,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 10312,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "inflection/inflection-3-productivity": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "inflection/inflection-3-productivity",
        "variant": "standard",
        "variant_permaslug": "inflection/inflection-3-productivity",
        "count": 2136,
        "total_completion_tokens": 311466,
        "total_prompt_tokens": 2388381,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-5.2-codex-20260114": {
        "date": "2026-01-14 00:00:00",
        "model_permaslug": "openai/gpt-5.2-codex-20260114",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5.2-codex-20260114",
        "count": 203361,
        "total_completion_tokens": 371249557,
        "total_prompt_tokens": 9455238726,
        "total_native_tokens_reasoning": 328507157,
        "num_media_prompt": 64002,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 7741534848,
        "total_tool_calls": 139507,
        "requests_with_tool_call_errors": 4174
      },
      "intfloat/multilingual-e5-large-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "intfloat/multilingual-e5-large-20251117",
        "variant": "standard",
        "variant_permaslug": "intfloat/multilingual-e5-large-20251117",
        "count": 1139262,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 314173453,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "meta-llama/llama-3-8b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3-8b-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-3-8b-instruct",
        "count": 3397650,
        "total_completion_tokens": 294683001,
        "total_prompt_tokens": 1714310855,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 2,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 341,
        "requests_with_tool_call_errors": 112
      },
      "mistralai/devstral-medium-2507": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/devstral-medium-2507",
        "variant": "standard",
        "variant_permaslug": "mistralai/devstral-medium-2507",
        "count": 62799,
        "total_completion_tokens": 3705775,
        "total_prompt_tokens": 217638238,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 868,
        "requests_with_tool_call_errors": 67
      },
      "qwen/qwen3-30b-a3b-04-28": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-30b-a3b-04-28",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-30b-a3b-04-28",
        "count": 1644697,
        "total_completion_tokens": 1387724216,
        "total_prompt_tokens": 4578585487,
        "total_native_tokens_reasoning": 1391385394,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 265765165,
        "total_tool_calls": 20841,
        "requests_with_tool_call_errors": 7142
      },
      "mistralai/mistral-medium-3.1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-medium-3.1",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-medium-3.1",
        "count": 429298,
        "total_completion_tokens": 197737094,
        "total_prompt_tokens": 4070858126,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 13078,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 27620,
        "requests_with_tool_call_errors": 1396
      },
      "mistralai/mistral-large": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-large",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-large",
        "count": 126980,
        "total_completion_tokens": 16876704,
        "total_prompt_tokens": 353424270,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 2737,
        "requests_with_tool_call_errors": 31
      },
      "google/gemini-3-pro-preview-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-3-pro-preview-20251117",
        "variant": "standard",
        "variant_permaslug": "google/gemini-3-pro-preview-20251117",
        "count": 11003353,
        "total_completion_tokens": 19928291159,
        "total_prompt_tokens": 217083575056,
        "total_native_tokens_reasoning": 13410687498,
        "num_media_prompt": 3826865,
        "num_media_completion": 0,
        "num_audio_prompt": 1005572,
        "total_native_tokens_cached": 125622095199,
        "total_tool_calls": 2586188,
        "requests_with_tool_call_errors": 95948
      },
      "venice/uncensored:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "venice/uncensored",
        "variant": "free",
        "variant_permaslug": "venice/uncensored:free",
        "count": 276713,
        "total_completion_tokens": 110621982,
        "total_prompt_tokens": 1151945020,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepseek/deepseek-r1-distill-qwen-32b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-r1-distill-qwen-32b",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-r1-distill-qwen-32b",
        "count": 298181,
        "total_completion_tokens": 123405519,
        "total_prompt_tokens": 229114204,
        "total_native_tokens_reasoning": 122313120,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-vl-235b-a22b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-vl-235b-a22b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-vl-235b-a22b-instruct",
        "count": 3490458,
        "total_completion_tokens": 932255672,
        "total_prompt_tokens": 26934997991,
        "total_native_tokens_reasoning": 17055,
        "num_media_prompt": 16953427,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1596162634,
        "total_tool_calls": 73268,
        "requests_with_tool_call_errors": 20053
      },
      "openai/gpt-4.1-nano-2025-04-14": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4.1-nano-2025-04-14",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4.1-nano-2025-04-14",
        "count": 6769764,
        "total_completion_tokens": 795836777,
        "total_prompt_tokens": 14343680355,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 246371,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 5040403456,
        "total_tool_calls": 591593,
        "requests_with_tool_call_errors": 246
      },
      "anthropic/claude-4.5-haiku-20251001": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthropic/claude-4.5-haiku-20251001",
        "variant": "standard",
        "variant_permaslug": "anthropic/claude-4.5-haiku-20251001",
        "count": 13093012,
        "total_completion_tokens": 4320202125,
        "total_prompt_tokens": 134188706163,
        "total_native_tokens_reasoning": 275483753,
        "num_media_prompt": 790619,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 77342534814,
        "total_tool_calls": 3938868,
        "requests_with_tool_call_errors": 82090
      },
      "mistralai/mistral-7b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-7b-instruct",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-7b-instruct",
        "count": 456075,
        "total_completion_tokens": 75747509,
        "total_prompt_tokens": 685328741,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "google/gemini-2.0-flash-001": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-2.0-flash-001",
        "variant": "standard",
        "variant_permaslug": "google/gemini-2.0-flash-001",
        "count": 131513430,
        "total_completion_tokens": 20256395500,
        "total_prompt_tokens": 158450692795,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 11927614,
        "num_media_completion": 0,
        "num_audio_prompt": 25565,
        "total_native_tokens_cached": 616646574,
        "total_tool_calls": 1733692,
        "requests_with_tool_call_errors": 10116
      },
      "nousresearch/hermes-2-pro-llama-3-8b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nousresearch/hermes-2-pro-llama-3-8b",
        "variant": "standard",
        "variant_permaslug": "nousresearch/hermes-2-pro-llama-3-8b",
        "count": 181387,
        "total_completion_tokens": 11482376,
        "total_prompt_tokens": 119939746,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 1,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "google/gemma-3-4b-it": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemma-3-4b-it",
        "variant": "standard",
        "variant_permaslug": "google/gemma-3-4b-it",
        "count": 23785738,
        "total_completion_tokens": 648881389,
        "total_prompt_tokens": 1678325464,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 99418,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 279944608,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-3.5-turbo": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-3.5-turbo",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-3.5-turbo",
        "count": 1028162,
        "total_completion_tokens": 97502569,
        "total_prompt_tokens": 1038733115,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 68446,
        "requests_with_tool_call_errors": 1978
      },
      "nousresearch/hermes-3-llama-3.1-405b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nousresearch/hermes-3-llama-3.1-405b",
        "variant": "standard",
        "variant_permaslug": "nousresearch/hermes-3-llama-3.1-405b",
        "count": 385829,
        "total_completion_tokens": 64980996,
        "total_prompt_tokens": 886336075,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/text-embedding-ada-002": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/text-embedding-ada-002",
        "variant": "standard",
        "variant_permaslug": "openai/text-embedding-ada-002",
        "count": 3637651,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 1638659695,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "mistralai/ministral-3b-2512": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/ministral-3b-2512",
        "variant": "standard",
        "variant_permaslug": "mistralai/ministral-3b-2512",
        "count": 3850822,
        "total_completion_tokens": 556502662,
        "total_prompt_tokens": 1404632607,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 33224,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 2759,
        "requests_with_tool_call_errors": 246
      },
      "anthropic/claude-4.5-opus-20251124": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthropic/claude-4.5-opus-20251124",
        "variant": "standard",
        "variant_permaslug": "anthropic/claude-4.5-opus-20251124",
        "count": 17782036,
        "total_completion_tokens": 10392260206,
        "total_prompt_tokens": 655128211670,
        "total_native_tokens_reasoning": 1609750765,
        "num_media_prompt": 7056765,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 252443207925,
        "total_tool_calls": 7162383,
        "requests_with_tool_call_errors": 125775
      },
      "allenai/molmo-2-8b-20260109:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "allenai/molmo-2-8b-20260109",
        "variant": "free",
        "variant_permaslug": "allenai/molmo-2-8b-20260109:free",
        "count": 115833,
        "total_completion_tokens": 34193820,
        "total_prompt_tokens": 294655769,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 58479,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/codex-mini": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/codex-mini",
        "variant": "standard",
        "variant_permaslug": "openai/codex-mini",
        "count": 4277,
        "total_completion_tokens": 3553831,
        "total_prompt_tokens": 50129459,
        "total_native_tokens_reasoning": 2900569,
        "num_media_prompt": 165,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 32225024,
        "total_tool_calls": 649,
        "requests_with_tool_call_errors": 5
      },
      "google/gemini-2.0-flash-lite-001": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-2.0-flash-lite-001",
        "variant": "standard",
        "variant_permaslug": "google/gemini-2.0-flash-lite-001",
        "count": 20959786,
        "total_completion_tokens": 3790804904,
        "total_prompt_tokens": 28005222111,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 3822061,
        "num_media_completion": 0,
        "num_audio_prompt": 11490,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 98749,
        "requests_with_tool_call_errors": 20974
      },
      "mistralai/codestral-embed-2505": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/codestral-embed-2505",
        "variant": "standard",
        "variant_permaslug": "mistralai/codestral-embed-2505",
        "count": 128741,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 375054650,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "mistralai/mistral-small-creative-20251216": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-small-creative-20251216",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-small-creative-20251216",
        "count": 816844,
        "total_completion_tokens": 403344696,
        "total_prompt_tokens": 3605263403,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 7163,
        "requests_with_tool_call_errors": 305
      },
      "openai/gpt-4.1-2025-04-14": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4.1-2025-04-14",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4.1-2025-04-14",
        "count": 7513251,
        "total_completion_tokens": 1621594184,
        "total_prompt_tokens": 37574839780,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 794009,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 14026157696,
        "total_tool_calls": 757043,
        "requests_with_tool_call_errors": 4344
      },
      "qwen/qwen3-coder-480b-a35b-07-25:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-coder-480b-a35b-07-25",
        "variant": "free",
        "variant_permaslug": "qwen/qwen3-coder-480b-a35b-07-25:free",
        "count": 263028,
        "total_completion_tokens": 207821676,
        "total_prompt_tokens": 7845739688,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 58673,
        "requests_with_tool_call_errors": 2037
      },
      "openai/chatgpt-4o-latest": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/chatgpt-4o-latest",
        "variant": "standard",
        "variant_permaslug": "openai/chatgpt-4o-latest",
        "count": 445683,
        "total_completion_tokens": 102298268,
        "total_prompt_tokens": 1360299285,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 131274,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "aion-labs/aion-1.0-mini": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "aion-labs/aion-1.0-mini",
        "variant": "standard",
        "variant_permaslug": "aion-labs/aion-1.0-mini",
        "count": 1221,
        "total_completion_tokens": 449548,
        "total_prompt_tokens": 3550827,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-4o-2024-08-06": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4o-2024-08-06",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4o-2024-08-06",
        "count": 1488709,
        "total_completion_tokens": 268741580,
        "total_prompt_tokens": 1746484842,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 15257,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 793718784,
        "total_tool_calls": 31165,
        "requests_with_tool_call_errors": 17980
      },
      "mistralai/codestral-2508": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/codestral-2508",
        "variant": "standard",
        "variant_permaslug": "mistralai/codestral-2508",
        "count": 2455588,
        "total_completion_tokens": 362425365,
        "total_prompt_tokens": 4972067876,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 2385,
        "requests_with_tool_call_errors": 58
      },
      "mistralai/devstral-small-2507": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/devstral-small-2507",
        "variant": "standard",
        "variant_permaslug": "mistralai/devstral-small-2507",
        "count": 490851,
        "total_completion_tokens": 55142344,
        "total_prompt_tokens": 608374346,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 7595,
        "requests_with_tool_call_errors": 869
      },
      "mistralai/mixtral-8x22b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mixtral-8x22b-instruct",
        "variant": "standard",
        "variant_permaslug": "mistralai/mixtral-8x22b-instruct",
        "count": 54903,
        "total_completion_tokens": 16663701,
        "total_prompt_tokens": 69114076,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 8,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 168,
        "requests_with_tool_call_errors": 7
      },
      "deepcogito/cogito-v2-preview-llama-109b-moe": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepcogito/cogito-v2-preview-llama-109b-moe",
        "variant": "standard",
        "variant_permaslug": "deepcogito/cogito-v2-preview-llama-109b-moe",
        "count": 7663,
        "total_completion_tokens": 884907,
        "total_prompt_tokens": 32436871,
        "total_native_tokens_reasoning": 40765,
        "num_media_prompt": 12275,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 25,
        "requests_with_tool_call_errors": 7
      },
      "openai/gpt-4o-mini-search-preview-2025-03-11": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4o-mini-search-preview-2025-03-11",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4o-mini-search-preview-2025-03-11",
        "count": 71699,
        "total_completion_tokens": 63597972,
        "total_prompt_tokens": 49297124,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "nvidia/nemotron-nano-9b-v2:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nvidia/nemotron-nano-9b-v2",
        "variant": "free",
        "variant_permaslug": "nvidia/nemotron-nano-9b-v2:free",
        "count": 63817,
        "total_completion_tokens": 70473270,
        "total_prompt_tokens": 262880346,
        "total_native_tokens_reasoning": 47130739,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 2244,
        "requests_with_tool_call_errors": 312
      },
      "moonshotai/kimi-k2-0905:exacto": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "moonshotai/kimi-k2-0905",
        "variant": "exacto",
        "variant_permaslug": "moonshotai/kimi-k2-0905:exacto",
        "count": 403908,
        "total_completion_tokens": 242130891,
        "total_prompt_tokens": 1830111896,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1102396868,
        "total_tool_calls": 25854,
        "requests_with_tool_call_errors": 604
      },
      "anthropic/claude-4-opus-20250522": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthropic/claude-4-opus-20250522",
        "variant": "standard",
        "variant_permaslug": "anthropic/claude-4-opus-20250522",
        "count": 148528,
        "total_completion_tokens": 65145365,
        "total_prompt_tokens": 1202928017,
        "total_native_tokens_reasoning": 1521752,
        "num_media_prompt": 7184,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 450773439,
        "total_tool_calls": 16808,
        "requests_with_tool_call_errors": 582
      },
      "openai/gpt-5.2-pro-20251211": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5.2-pro-20251211",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5.2-pro-20251211",
        "count": 110153,
        "total_completion_tokens": 195831443,
        "total_prompt_tokens": 3107399447,
        "total_native_tokens_reasoning": 120059058,
        "num_media_prompt": 17892,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 30917,
        "requests_with_tool_call_errors": 341
      },
      "openai/gpt-4o-2024-05-13": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4o-2024-05-13",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4o-2024-05-13",
        "count": 49581,
        "total_completion_tokens": 4166405,
        "total_prompt_tokens": 91111309,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 8173,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 3361536,
        "total_tool_calls": 17271,
        "requests_with_tool_call_errors": 384
      },
      "allenai/olmo-3-7b-think-20251121": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "allenai/olmo-3-7b-think-20251121",
        "variant": "standard",
        "variant_permaslug": "allenai/olmo-3-7b-think-20251121",
        "count": 37208,
        "total_completion_tokens": 96723728,
        "total_prompt_tokens": 41172867,
        "total_native_tokens_reasoning": 90038402,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 13039744,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-coder-30b-a3b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-coder-30b-a3b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-coder-30b-a3b-instruct",
        "count": 572928,
        "total_completion_tokens": 462425396,
        "total_prompt_tokens": 2792314104,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 45318,
        "requests_with_tool_call_errors": 7453
      },
      "openai/gpt-4o-mini-2024-07-18": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4o-mini-2024-07-18",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4o-mini-2024-07-18",
        "count": 3709517,
        "total_completion_tokens": 515294179,
        "total_prompt_tokens": 7988993961,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 33828,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2864932608,
        "total_tool_calls": 174720,
        "requests_with_tool_call_errors": 344
      },
      "anthropic/claude-3-5-haiku": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthropic/claude-3-5-haiku",
        "variant": "standard",
        "variant_permaslug": "anthropic/claude-3-5-haiku",
        "count": 3651328,
        "total_completion_tokens": 593938325,
        "total_prompt_tokens": 10140262754,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 34287,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1092143880,
        "total_tool_calls": 137897,
        "requests_with_tool_call_errors": 4156
      },
      "z-ai/glm-4.6": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "z-ai/glm-4.6",
        "variant": "standard",
        "variant_permaslug": "z-ai/glm-4.6",
        "count": 1929818,
        "total_completion_tokens": 1219330927,
        "total_prompt_tokens": 21296371260,
        "total_native_tokens_reasoning": 518404143,
        "num_media_prompt": 375,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 8330736318,
        "total_tool_calls": 337882,
        "requests_with_tool_call_errors": 42373
      },
      "nvidia/llama-3.1-nemotron-70b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nvidia/llama-3.1-nemotron-70b-instruct",
        "variant": "standard",
        "variant_permaslug": "nvidia/llama-3.1-nemotron-70b-instruct",
        "count": 20136,
        "total_completion_tokens": 6141517,
        "total_prompt_tokens": 49952533,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 44,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 278,
        "requests_with_tool_call_errors": 19
      },
      "google/gemma-3-27b-it": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemma-3-27b-it",
        "variant": "standard",
        "variant_permaslug": "google/gemma-3-27b-it",
        "count": 11301172,
        "total_completion_tokens": 2728020138,
        "total_prompt_tokens": 20798133028,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 2699839,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2054672413,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "sentence-transformers/all-minilm-l12-v2-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sentence-transformers/all-minilm-l12-v2-20251117",
        "variant": "standard",
        "variant_permaslug": "sentence-transformers/all-minilm-l12-v2-20251117",
        "count": 1091719,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 198143927,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-5-mini-2025-08-07": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5-mini-2025-08-07",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5-mini-2025-08-07",
        "count": 23529755,
        "total_completion_tokens": 14014511556,
        "total_prompt_tokens": 109076829671,
        "total_native_tokens_reasoning": 9871653490,
        "num_media_prompt": 8215937,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 51851916928,
        "total_tool_calls": 2464192,
        "requests_with_tool_call_errors": 6910
      },
      "deepseek/deepseek-r1-0528:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-r1-0528",
        "variant": "free",
        "variant_permaslug": "deepseek/deepseek-r1-0528:free",
        "count": 2118400,
        "total_completion_tokens": 1667640693,
        "total_prompt_tokens": 12614728754,
        "total_native_tokens_reasoning": 1041315714,
        "num_media_prompt": 38,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 15730049,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/o1-2024-12-17": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/o1-2024-12-17",
        "variant": "standard",
        "variant_permaslug": "openai/o1-2024-12-17",
        "count": 12019,
        "total_completion_tokens": 12608833,
        "total_prompt_tokens": 45684281,
        "total_native_tokens_reasoning": 8546368,
        "num_media_prompt": 611,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 16402688,
        "total_tool_calls": 250,
        "requests_with_tool_call_errors": 3
      },
      "nousresearch/hermes-4-70b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nousresearch/hermes-4-70b",
        "variant": "standard",
        "variant_permaslug": "nousresearch/hermes-4-70b",
        "count": 318400,
        "total_completion_tokens": 54960443,
        "total_prompt_tokens": 1271812358,
        "total_native_tokens_reasoning": 339413,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 72877552,
        "total_tool_calls": 1610,
        "requests_with_tool_call_errors": 43
      },
      "qwen/qwen-plus-2025-07-28:thinking": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-plus-2025-07-28",
        "variant": "thinking",
        "variant_permaslug": "qwen/qwen-plus-2025-07-28:thinking",
        "count": 4289,
        "total_completion_tokens": 8667239,
        "total_prompt_tokens": 26008172,
        "total_native_tokens_reasoning": 4465922,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 161,
        "requests_with_tool_call_errors": 9
      },
      "mistralai/mistral-small-3.2-24b-instruct-2506": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-small-3.2-24b-instruct-2506",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-small-3.2-24b-instruct-2506",
        "count": 8654735,
        "total_completion_tokens": 2662273578,
        "total_prompt_tokens": 20153075096,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 994296,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2674464081,
        "total_tool_calls": 66913,
        "requests_with_tool_call_errors": 7942
      },
      "qwen/qwen3-vl-235b-a22b-thinking": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-vl-235b-a22b-thinking",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-vl-235b-a22b-thinking",
        "count": 679662,
        "total_completion_tokens": 899689763,
        "total_prompt_tokens": 3217030864,
        "total_native_tokens_reasoning": 697728111,
        "num_media_prompt": 2194081,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 37,
        "requests_with_tool_call_errors": 2
      },
      "deepseek/deepseek-chat-v3": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-chat-v3",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-chat-v3",
        "count": 7048401,
        "total_completion_tokens": 1425062542,
        "total_prompt_tokens": 11852866512,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 669100473,
        "total_tool_calls": 183753,
        "requests_with_tool_call_errors": 1616
      },
      "sao10k/l3.3-euryale-70b-v2.3": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sao10k/l3.3-euryale-70b-v2.3",
        "variant": "standard",
        "variant_permaslug": "sao10k/l3.3-euryale-70b-v2.3",
        "count": 207635,
        "total_completion_tokens": 22318868,
        "total_prompt_tokens": 404941517,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "perplexity/sonar-pro": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "perplexity/sonar-pro",
        "variant": "standard",
        "variant_permaslug": "perplexity/sonar-pro",
        "count": 290885,
        "total_completion_tokens": 162733996,
        "total_prompt_tokens": 748141241,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 2260,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "ai21/jamba-large-1.7": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "ai21/jamba-large-1.7",
        "variant": "standard",
        "variant_permaslug": "ai21/jamba-large-1.7",
        "count": 7485,
        "total_completion_tokens": 2548463,
        "total_prompt_tokens": 34014718,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 74,
        "requests_with_tool_call_errors": 25
      },
      "openai/gpt-5.2-chat-20251211": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5.2-chat-20251211",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5.2-chat-20251211",
        "count": 1255587,
        "total_completion_tokens": 478829550,
        "total_prompt_tokens": 6928144028,
        "total_native_tokens_reasoning": 78073344,
        "num_media_prompt": 349201,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 3372653312,
        "total_tool_calls": 59287,
        "requests_with_tool_call_errors": 709
      },
      "thenlper/gte-base-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "thenlper/gte-base-20251117",
        "variant": "standard",
        "variant_permaslug": "thenlper/gte-base-20251117",
        "count": 385507,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 735583345,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-embedding-4b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-embedding-4b",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-embedding-4b",
        "count": 1458799,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 2912509344,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-oss-120b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-oss-120b",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-oss-120b",
        "count": 52487593,
        "total_completion_tokens": 32563681129,
        "total_prompt_tokens": 169611226234,
        "total_native_tokens_reasoning": 17419491687,
        "num_media_prompt": 2078,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 38002825009,
        "total_tool_calls": 1137002,
        "requests_with_tool_call_errors": 82907
      },
      "openai/gpt-3.5-turbo-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-3.5-turbo-instruct",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-3.5-turbo-instruct",
        "count": 15219,
        "total_completion_tokens": 3318018,
        "total_prompt_tokens": 3596124,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "microsoft/phi-4": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "microsoft/phi-4",
        "variant": "standard",
        "variant_permaslug": "microsoft/phi-4",
        "count": 1961628,
        "total_completion_tokens": 30018291,
        "total_prompt_tokens": 567295313,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "mistralai/ministral-14b-2512": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/ministral-14b-2512",
        "variant": "standard",
        "variant_permaslug": "mistralai/ministral-14b-2512",
        "count": 1464826,
        "total_completion_tokens": 238611303,
        "total_prompt_tokens": 2663018676,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 278990,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 25001,
        "requests_with_tool_call_errors": 3033
      },
      "anthropic/claude-3-haiku": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthropic/claude-3-haiku",
        "variant": "standard",
        "variant_permaslug": "anthropic/claude-3-haiku",
        "count": 1498337,
        "total_completion_tokens": 329153881,
        "total_prompt_tokens": 2235688259,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 26730,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 46227752,
        "total_tool_calls": 122087,
        "requests_with_tool_call_errors": 4536
      },
      "allenai/olmo-3-7b-instruct-20251121": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "allenai/olmo-3-7b-instruct-20251121",
        "variant": "standard",
        "variant_permaslug": "allenai/olmo-3-7b-instruct-20251121",
        "count": 40347,
        "total_completion_tokens": 40095205,
        "total_prompt_tokens": 33253595,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 11869264,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-30b-a3b-instruct-2507": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-30b-a3b-instruct-2507",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-30b-a3b-instruct-2507",
        "count": 1903068,
        "total_completion_tokens": 995453829,
        "total_prompt_tokens": 5079248829,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 6,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 549118054,
        "total_tool_calls": 27445,
        "requests_with_tool_call_errors": 11979
      },
      "anthropic/claude-4.5-sonnet-20250929": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthropic/claude-4.5-sonnet-20250929",
        "variant": "standard",
        "variant_permaslug": "anthropic/claude-4.5-sonnet-20250929",
        "count": 21526202,
        "total_completion_tokens": 12257998930,
        "total_prompt_tokens": 679777128361,
        "total_native_tokens_reasoning": 537204198,
        "num_media_prompt": 5157898,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 386443213943,
        "total_tool_calls": 7151823,
        "requests_with_tool_call_errors": 178608
      },
      "openai/gpt-5-pro-2025-10-06": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5-pro-2025-10-06",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5-pro-2025-10-06",
        "count": 9837,
        "total_completion_tokens": 23327301,
        "total_prompt_tokens": 50148656,
        "total_native_tokens_reasoning": 20169951,
        "num_media_prompt": 3227,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 210,
        "requests_with_tool_call_errors": 0
      },
      "z-ai/glm-4-32b-0414": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "z-ai/glm-4-32b-0414",
        "variant": "standard",
        "variant_permaslug": "z-ai/glm-4-32b-0414",
        "count": 18788814,
        "total_completion_tokens": 102291291,
        "total_prompt_tokens": 6167628908,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 186,
        "requests_with_tool_call_errors": 17
      },
      "qwen/qwen3-next-80b-a3b-instruct-2509": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-next-80b-a3b-instruct-2509",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-next-80b-a3b-instruct-2509",
        "count": 4987240,
        "total_completion_tokens": 780626467,
        "total_prompt_tokens": 19943234416,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 2,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 510067185,
        "total_tool_calls": 195908,
        "requests_with_tool_call_errors": 20530
      },
      "mistralai/mistral-7b-instruct-v0.2": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-7b-instruct-v0.2",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-7b-instruct-v0.2",
        "count": 228936,
        "total_completion_tokens": 6693687,
        "total_prompt_tokens": 64038187,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepseek/deepseek-v3.1-terminus:exacto": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-v3.1-terminus",
        "variant": "exacto",
        "variant_permaslug": "deepseek/deepseek-v3.1-terminus:exacto",
        "count": 163515,
        "total_completion_tokens": 77611874,
        "total_prompt_tokens": 1766449576,
        "total_native_tokens_reasoning": 40229063,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 15407131,
        "total_tool_calls": 26046,
        "requests_with_tool_call_errors": 432
      },
      "mistralai/mistral-small-3.1-24b-instruct-2503:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
        "variant": "free",
        "variant_permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503:free",
        "count": 81105,
        "total_completion_tokens": 48907234,
        "total_prompt_tokens": 442717123,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 11,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 634,
        "requests_with_tool_call_errors": 620
      },
      "x-ai/grok-code-fast-1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "x-ai/grok-code-fast-1",
        "variant": "standard",
        "variant_permaslug": "x-ai/grok-code-fast-1",
        "count": 15770336,
        "total_completion_tokens": 13428463953,
        "total_prompt_tokens": 479587967485,
        "total_native_tokens_reasoning": 10209858089,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 322901692736,
        "total_tool_calls": 5650018,
        "requests_with_tool_call_errors": 10335
      },
      "openai/gpt-5-chat-2025-08-07": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5-chat-2025-08-07",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5-chat-2025-08-07",
        "count": 2749755,
        "total_completion_tokens": 610618971,
        "total_prompt_tokens": 11266838635,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 281718,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 5661346944,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-4o:extended": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4o",
        "variant": "extended",
        "variant_permaslug": "openai/gpt-4o:extended",
        "count": 2507,
        "total_completion_tokens": 587966,
        "total_prompt_tokens": 7701647,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 435,
        "requests_with_tool_call_errors": 174
      },
      "nvidia/nemotron-nano-12b-v2-vl:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nvidia/nemotron-nano-12b-v2-vl",
        "variant": "free",
        "variant_permaslug": "nvidia/nemotron-nano-12b-v2-vl:free",
        "count": 152648,
        "total_completion_tokens": 175596902,
        "total_prompt_tokens": 536315632,
        "total_native_tokens_reasoning": 129562138,
        "num_media_prompt": 145395,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 1313,
        "requests_with_tool_call_errors": 478
      },
      "google/gemini-2.5-pro": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-2.5-pro",
        "variant": "standard",
        "variant_permaslug": "google/gemini-2.5-pro",
        "count": 11036997,
        "total_completion_tokens": 19398826455,
        "total_prompt_tokens": 130899024378,
        "total_native_tokens_reasoning": 11271228318,
        "num_media_prompt": 995267,
        "num_media_completion": 0,
        "num_audio_prompt": 23461,
        "total_native_tokens_cached": 38832797874,
        "total_tool_calls": 708882,
        "requests_with_tool_call_errors": 23855
      },
      "z-ai/glm-4.5-air:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "z-ai/glm-4.5-air",
        "variant": "free",
        "variant_permaslug": "z-ai/glm-4.5-air:free",
        "count": 1883352,
        "total_completion_tokens": 1572104210,
        "total_prompt_tokens": 23059727329,
        "total_native_tokens_reasoning": 750558984,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 13524742307,
        "total_tool_calls": 226469,
        "requests_with_tool_call_errors": 14082
      },
      "qwen/qwen3-coder-flash": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-coder-flash",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-coder-flash",
        "count": 82076,
        "total_completion_tokens": 17932307,
        "total_prompt_tokens": 474737920,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 318727200,
        "total_tool_calls": 15165,
        "requests_with_tool_call_errors": 5406
      },
      "intfloat/e5-base-v2-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "intfloat/e5-base-v2-20251117",
        "variant": "standard",
        "variant_permaslug": "intfloat/e5-base-v2-20251117",
        "count": 3491,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 24451639,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "meta-llama/llama-3.3-70b-instruct:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3.3-70b-instruct",
        "variant": "free",
        "variant_permaslug": "meta-llama/llama-3.3-70b-instruct:free",
        "count": 933639,
        "total_completion_tokens": 378685950,
        "total_prompt_tokens": 3424145798,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 5,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 22903,
        "requests_with_tool_call_errors": 13105
      },
      "nvidia/nemotron-3-nano-30b-a3b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nvidia/nemotron-3-nano-30b-a3b",
        "variant": "standard",
        "variant_permaslug": "nvidia/nemotron-3-nano-30b-a3b",
        "count": 625502,
        "total_completion_tokens": 1627269728,
        "total_prompt_tokens": 6871990660,
        "total_native_tokens_reasoning": 1487322381,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 162959,
        "requests_with_tool_call_errors": 12496
      },
      "black-forest-labs/flux.2-klein-4b": {
        "date": "2026-01-15 00:00:00",
        "model_permaslug": "black-forest-labs/flux.2-klein-4b",
        "variant": "standard",
        "variant_permaslug": "black-forest-labs/flux.2-klein-4b",
        "count": 4088,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 7099215,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 2474,
        "num_media_completion": 4088,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "sao10k/l3-euryale-70b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sao10k/l3-euryale-70b",
        "variant": "standard",
        "variant_permaslug": "sao10k/l3-euryale-70b",
        "count": 32532,
        "total_completion_tokens": 9339076,
        "total_prompt_tokens": 47298682,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "thedrummer/rocinante-12b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "thedrummer/rocinante-12b",
        "variant": "standard",
        "variant_permaslug": "thedrummer/rocinante-12b",
        "count": 527358,
        "total_completion_tokens": 151029077,
        "total_prompt_tokens": 916757162,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "meta-llama/llama-guard-4-12b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-guard-4-12b",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-guard-4-12b",
        "count": 2846621,
        "total_completion_tokens": 11146122,
        "total_prompt_tokens": 1026936037,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 230,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "moonshotai/kimi-dev-72b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "moonshotai/kimi-dev-72b",
        "variant": "standard",
        "variant_permaslug": "moonshotai/kimi-dev-72b",
        "count": 4623,
        "total_completion_tokens": 12689482,
        "total_prompt_tokens": 7029732,
        "total_native_tokens_reasoning": 10461571,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-5.1-20251113": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5.1-20251113",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5.1-20251113",
        "count": 3221927,
        "total_completion_tokens": 2789273487,
        "total_prompt_tokens": 21876864265,
        "total_native_tokens_reasoning": 1600320700,
        "num_media_prompt": 1663239,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 8275092608,
        "total_tool_calls": 264082,
        "requests_with_tool_call_errors": 765
      },
      "openai/gpt-oss-120b:exacto": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-oss-120b",
        "variant": "exacto",
        "variant_permaslug": "openai/gpt-oss-120b:exacto",
        "count": 1393282,
        "total_completion_tokens": 714625767,
        "total_prompt_tokens": 3774620373,
        "total_native_tokens_reasoning": 495157689,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 112595712,
        "total_tool_calls": 264501,
        "requests_with_tool_call_errors": 9756
      },
      "eleutherai/llemma_7b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "eleutherai/llemma_7b",
        "variant": "standard",
        "variant_permaslug": "eleutherai/llemma_7b",
        "count": 391,
        "total_completion_tokens": 138036,
        "total_prompt_tokens": 139036,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-vl-30b-a3b-thinking": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-vl-30b-a3b-thinking",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-vl-30b-a3b-thinking",
        "count": 79354,
        "total_completion_tokens": 119792855,
        "total_prompt_tokens": 316153205,
        "total_native_tokens_reasoning": 89201928,
        "num_media_prompt": 183386,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 4152,
        "requests_with_tool_call_errors": 1264
      },
      "anthracite-org/magnum-v4-72b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthracite-org/magnum-v4-72b",
        "variant": "standard",
        "variant_permaslug": "anthracite-org/magnum-v4-72b",
        "count": 52592,
        "total_completion_tokens": 5816700,
        "total_prompt_tokens": 83309504,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "meta-llama/llama-3.1-8b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3.1-8b-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-3.1-8b-instruct",
        "count": 28031373,
        "total_completion_tokens": 2156648866,
        "total_prompt_tokens": 24998129931,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 41,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 3068832896,
        "total_tool_calls": 1072487,
        "requests_with_tool_call_errors": 27994
      },
      "anthropic/claude-4-sonnet-20250522": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthropic/claude-4-sonnet-20250522",
        "variant": "standard",
        "variant_permaslug": "anthropic/claude-4-sonnet-20250522",
        "count": 5842124,
        "total_completion_tokens": 3136775131,
        "total_prompt_tokens": 54636825167,
        "total_native_tokens_reasoning": 65241869,
        "num_media_prompt": 547232,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 22891654203,
        "total_tool_calls": 813918,
        "requests_with_tool_call_errors": 19741
      },
      "google/gemma-3-12b-it": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemma-3-12b-it",
        "variant": "standard",
        "variant_permaslug": "google/gemma-3-12b-it",
        "count": 15940728,
        "total_completion_tokens": 1330919740,
        "total_prompt_tokens": 8836437090,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 1348775,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 988725322,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "tngtech/deepseek-r1t2-chimera:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "tngtech/deepseek-r1t2-chimera",
        "variant": "free",
        "variant_permaslug": "tngtech/deepseek-r1t2-chimera:free",
        "count": 9752938,
        "total_completion_tokens": 8663583896,
        "total_prompt_tokens": 93273653793,
        "total_native_tokens_reasoning": 4982356894,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 11660063424,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "alpindale/goliath-120b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "alpindale/goliath-120b",
        "variant": "standard",
        "variant_permaslug": "alpindale/goliath-120b",
        "count": 2399,
        "total_completion_tokens": 749065,
        "total_prompt_tokens": 3226227,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 60,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "mistralai/pixtral-12b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/pixtral-12b",
        "variant": "standard",
        "variant_permaslug": "mistralai/pixtral-12b",
        "count": 180534,
        "total_completion_tokens": 22746977,
        "total_prompt_tokens": 150999203,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 128239,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 258,
        "requests_with_tool_call_errors": 26
      },
      "qwen/qwen3-vl-8b-thinking": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-vl-8b-thinking",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-vl-8b-thinking",
        "count": 51137,
        "total_completion_tokens": 248147617,
        "total_prompt_tokens": 190739289,
        "total_native_tokens_reasoning": 236610266,
        "num_media_prompt": 26280,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 44009,
        "requests_with_tool_call_errors": 33388
      },
      "moonshotai/kimi-k2-thinking-20251106": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "moonshotai/kimi-k2-thinking-20251106",
        "variant": "standard",
        "variant_permaslug": "moonshotai/kimi-k2-thinking-20251106",
        "count": 1569081,
        "total_completion_tokens": 2524831113,
        "total_prompt_tokens": 21131647240,
        "total_native_tokens_reasoning": 1883859913,
        "num_media_prompt": 1054,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 12625811169,
        "total_tool_calls": 443729,
        "requests_with_tool_call_errors": 5393
      },
      "inception/mercury-coder-small-beta": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "inception/mercury-coder-small-beta",
        "variant": "standard",
        "variant_permaslug": "inception/mercury-coder-small-beta",
        "count": 21587,
        "total_completion_tokens": 23419340,
        "total_prompt_tokens": 77567804,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 479,
        "requests_with_tool_call_errors": 62
      },
      "openai/gpt-4-turbo-preview": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4-turbo-preview",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4-turbo-preview",
        "count": 30285,
        "total_completion_tokens": 2835023,
        "total_prompt_tokens": 26456199,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 304,
        "requests_with_tool_call_errors": 10
      },
      "google/gemma-2-27b-it": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemma-2-27b-it",
        "variant": "standard",
        "variant_permaslug": "google/gemma-2-27b-it",
        "count": 35419,
        "total_completion_tokens": 4767502,
        "total_prompt_tokens": 35996928,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-4o": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4o",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4o",
        "count": 6385504,
        "total_completion_tokens": 833163628,
        "total_prompt_tokens": 11015538834,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 976489,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2989436288,
        "total_tool_calls": 766114,
        "requests_with_tool_call_errors": 17875
      },
      "minimax/minimax-m2": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "minimax/minimax-m2",
        "variant": "standard",
        "variant_permaslug": "minimax/minimax-m2",
        "count": 753066,
        "total_completion_tokens": 441461946,
        "total_prompt_tokens": 18497711490,
        "total_native_tokens_reasoning": 323482415,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 7984543797,
        "total_tool_calls": 440402,
        "requests_with_tool_call_errors": 27792
      },
      "x-ai/grok-3-mini": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "x-ai/grok-3-mini",
        "variant": "standard",
        "variant_permaslug": "x-ai/grok-3-mini",
        "count": 4037475,
        "total_completion_tokens": 3133824173,
        "total_prompt_tokens": 8085747123,
        "total_native_tokens_reasoning": 2558190712,
        "num_media_prompt": 736,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2594285991,
        "total_tool_calls": 50215,
        "requests_with_tool_call_errors": 13157
      },
      "sourceful/riverflow-v2-max-preview": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sourceful/riverflow-v2-max-preview",
        "variant": "standard",
        "variant_permaslug": "sourceful/riverflow-v2-max-preview",
        "count": 2396,
        "total_completion_tokens": 10003300,
        "total_prompt_tokens": 10490989,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 4360,
        "num_media_completion": 2396,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "cohere/command-a-03-2025": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "cohere/command-a-03-2025",
        "variant": "standard",
        "variant_permaslug": "cohere/command-a-03-2025",
        "count": 22327,
        "total_completion_tokens": 3375457,
        "total_prompt_tokens": 18825592,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-3.5-turbo-0613": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-3.5-turbo-0613",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-3.5-turbo-0613",
        "count": 212295,
        "total_completion_tokens": 39062570,
        "total_prompt_tokens": 63632924,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1210496,
        "total_tool_calls": 84,
        "requests_with_tool_call_errors": 6
      },
      "inception/mercury": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "inception/mercury",
        "variant": "standard",
        "variant_permaslug": "inception/mercury",
        "count": 13813,
        "total_completion_tokens": 3658018,
        "total_prompt_tokens": 60795157,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 192,
        "requests_with_tool_call_errors": 13
      },
      "qwen/qwen3-8b-04-28": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-8b-04-28",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-8b-04-28",
        "count": 895447,
        "total_completion_tokens": 912698885,
        "total_prompt_tokens": 1966749290,
        "total_native_tokens_reasoning": 837784327,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 207784613,
        "total_tool_calls": 25624,
        "requests_with_tool_call_errors": 67
      },
      "tngtech/tng-r1t-chimera:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "tngtech/tng-r1t-chimera",
        "variant": "free",
        "variant_permaslug": "tngtech/tng-r1t-chimera:free",
        "count": 603185,
        "total_completion_tokens": 480404972,
        "total_prompt_tokens": 6452614045,
        "total_native_tokens_reasoning": 297749299,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1894903744,
        "total_tool_calls": 6260,
        "requests_with_tool_call_errors": 181
      },
      "google/gemini-2.5-flash-image": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-2.5-flash-image",
        "variant": "standard",
        "variant_permaslug": "google/gemini-2.5-flash-image",
        "count": 1281387,
        "total_completion_tokens": 1319948141,
        "total_prompt_tokens": 1447345626,
        "total_native_tokens_reasoning": 26171,
        "num_media_prompt": 1229892,
        "num_media_completion": 984419,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "anthropic/claude-3-7-sonnet-20250219": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthropic/claude-3-7-sonnet-20250219",
        "variant": "standard",
        "variant_permaslug": "anthropic/claude-3-7-sonnet-20250219",
        "count": 2965440,
        "total_completion_tokens": 1500364156,
        "total_prompt_tokens": 28644547179,
        "total_native_tokens_reasoning": 11915941,
        "num_media_prompt": 242524,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 8037442286,
        "total_tool_calls": 170020,
        "requests_with_tool_call_errors": 19508
      },
      "qwen/qwen-plus-2025-01-25": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-plus-2025-01-25",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen-plus-2025-01-25",
        "count": 40516,
        "total_completion_tokens": 12200326,
        "total_prompt_tokens": 539958085,
        "total_native_tokens_reasoning": 467727,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 437146799,
        "total_tool_calls": 13978,
        "requests_with_tool_call_errors": 6174
      },
      "anthropic/claude-3.5-sonnet": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthropic/claude-3.5-sonnet",
        "variant": "standard",
        "variant_permaslug": "anthropic/claude-3.5-sonnet",
        "count": 1549563,
        "total_completion_tokens": 388972829,
        "total_prompt_tokens": 5051486220,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 166978,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 822083420,
        "total_tool_calls": 194971,
        "requests_with_tool_call_errors": 1721
      },
      "bytedance/ui-tars-1.5-7b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "bytedance/ui-tars-1.5-7b",
        "variant": "standard",
        "variant_permaslug": "bytedance/ui-tars-1.5-7b",
        "count": 78451,
        "total_completion_tokens": 2598516,
        "total_prompt_tokens": 179588083,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 72741,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 54910768,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepcogito/cogito-v2-preview-llama-405b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepcogito/cogito-v2-preview-llama-405b",
        "variant": "standard",
        "variant_permaslug": "deepcogito/cogito-v2-preview-llama-405b",
        "count": 2874,
        "total_completion_tokens": 555125,
        "total_prompt_tokens": 9687390,
        "total_native_tokens_reasoning": 2213,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 120,
        "requests_with_tool_call_errors": 5
      },
      "moonshotai/kimi-k2-0905": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "moonshotai/kimi-k2-0905",
        "variant": "standard",
        "variant_permaslug": "moonshotai/kimi-k2-0905",
        "count": 12754224,
        "total_completion_tokens": 1743055060,
        "total_prompt_tokens": 29590012264,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 167,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 6405490663,
        "total_tool_calls": 105400,
        "requests_with_tool_call_errors": 1302
      },
      "nex-agi/deepseek-v3.1-nex-n1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nex-agi/deepseek-v3.1-nex-n1",
        "variant": "standard",
        "variant_permaslug": "nex-agi/deepseek-v3.1-nex-n1",
        "count": 276098,
        "total_completion_tokens": 276085626,
        "total_prompt_tokens": 3402253606,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 9,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 3225,
        "requests_with_tool_call_errors": 284
      },
      "baidu/ernie-4.5-21b-a3b-thinking": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "baidu/ernie-4.5-21b-a3b-thinking",
        "variant": "standard",
        "variant_permaslug": "baidu/ernie-4.5-21b-a3b-thinking",
        "count": 5991,
        "total_completion_tokens": 15440646,
        "total_prompt_tokens": 30734473,
        "total_native_tokens_reasoning": 13609135,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "meta-llama/llama-3.1-405b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3.1-405b",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-3.1-405b",
        "count": 59106,
        "total_completion_tokens": 4068529,
        "total_prompt_tokens": 1994139,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "prime-intellect/intellect-3-20251126": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "prime-intellect/intellect-3-20251126",
        "variant": "standard",
        "variant_permaslug": "prime-intellect/intellect-3-20251126",
        "count": 72387,
        "total_completion_tokens": 66877042,
        "total_prompt_tokens": 111131548,
        "total_native_tokens_reasoning": 51381024,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 33354352,
        "total_tool_calls": 6283,
        "requests_with_tool_call_errors": 1907
      },
      "qwen/qwen-vl-max-2025-01-25": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-vl-max-2025-01-25",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen-vl-max-2025-01-25",
        "count": 42976,
        "total_completion_tokens": 12042814,
        "total_prompt_tokens": 115041006,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 48610,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 34,
        "requests_with_tool_call_errors": 6
      },
      "anthropic/claude-3-7-sonnet-20250219:thinking": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthropic/claude-3-7-sonnet-20250219",
        "variant": "thinking",
        "variant_permaslug": "anthropic/claude-3-7-sonnet-20250219:thinking",
        "count": 127431,
        "total_completion_tokens": 160873710,
        "total_prompt_tokens": 2926677812,
        "total_native_tokens_reasoning": 77643482,
        "num_media_prompt": 18304,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1538527876,
        "total_tool_calls": 27429,
        "requests_with_tool_call_errors": 817
      },
      "sentence-transformers/paraphrase-minilm-l6-v2-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sentence-transformers/paraphrase-minilm-l6-v2-20251117",
        "variant": "standard",
        "variant_permaslug": "sentence-transformers/paraphrase-minilm-l6-v2-20251117",
        "count": 1656,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 4501326,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "sao10k/l3.1-euryale-70b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "sao10k/l3.1-euryale-70b",
        "variant": "standard",
        "variant_permaslug": "sao10k/l3.1-euryale-70b",
        "count": 144926,
        "total_completion_tokens": 18921260,
        "total_prompt_tokens": 510573560,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-4-0314": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4-0314",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4-0314",
        "count": 827,
        "total_completion_tokens": 70563,
        "total_prompt_tokens": 570293,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 9,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "thenlper/gte-large-20251117": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "thenlper/gte-large-20251117",
        "variant": "standard",
        "variant_permaslug": "thenlper/gte-large-20251117",
        "count": 19419,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 50564085,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-coder-480b-a35b-07-25:exacto": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-coder-480b-a35b-07-25",
        "variant": "exacto",
        "variant_permaslug": "qwen/qwen3-coder-480b-a35b-07-25:exacto",
        "count": 48839,
        "total_completion_tokens": 15154418,
        "total_prompt_tokens": 1566341113,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 82925484,
        "total_tool_calls": 21690,
        "requests_with_tool_call_errors": 276
      },
      "mistralai/mistral-saba-2502": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-saba-2502",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-saba-2502",
        "count": 3379,
        "total_completion_tokens": 714354,
        "total_prompt_tokens": 9256894,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 36,
        "requests_with_tool_call_errors": 1
      },
      "google/gemma-2-9b-it": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemma-2-9b-it",
        "variant": "standard",
        "variant_permaslug": "google/gemma-2-9b-it",
        "count": 1399867,
        "total_completion_tokens": 425486485,
        "total_prompt_tokens": 1089070433,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepseek/deepseek-v3.2-20251201": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-v3.2-20251201",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-v3.2-20251201",
        "count": 54533192,
        "total_completion_tokens": 26906339937,
        "total_prompt_tokens": 378090086472,
        "total_native_tokens_reasoning": 4172806809,
        "num_media_prompt": 5211,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 161400502080,
        "total_tool_calls": 3330758,
        "requests_with_tool_call_errors": 131654
      },
      "baidu/ernie-4.5-vl-424b-a47b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "baidu/ernie-4.5-vl-424b-a47b",
        "variant": "standard",
        "variant_permaslug": "baidu/ernie-4.5-vl-424b-a47b",
        "count": 2704,
        "total_completion_tokens": 1116515,
        "total_prompt_tokens": 10026910,
        "total_native_tokens_reasoning": 286684,
        "num_media_prompt": 677,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/o3-deep-research-2025-06-26": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/o3-deep-research-2025-06-26",
        "variant": "standard",
        "variant_permaslug": "openai/o3-deep-research-2025-06-26",
        "count": 1565,
        "total_completion_tokens": 10367962,
        "total_prompt_tokens": 23425755,
        "total_native_tokens_reasoning": 9053935,
        "num_media_prompt": 565,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1748864,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/text-embedding-3-small": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/text-embedding-3-small",
        "variant": "standard",
        "variant_permaslug": "openai/text-embedding-3-small",
        "count": 13785797,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 20673504327,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepseek/deepseek-chat-v3.1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-chat-v3.1",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-chat-v3.1",
        "count": 25351991,
        "total_completion_tokens": 4380434236,
        "total_prompt_tokens": 100929919613,
        "total_native_tokens_reasoning": 711875701,
        "num_media_prompt": 642,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 12961343160,
        "total_tool_calls": 220660,
        "requests_with_tool_call_errors": 3462
      },
      "meta-llama/llama-4-maverick-17b-128e-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-4-maverick-17b-128e-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-4-maverick-17b-128e-instruct",
        "count": 10137487,
        "total_completion_tokens": 1046580269,
        "total_prompt_tokens": 21546287728,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 1535828,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 406125824,
        "total_tool_calls": 425485,
        "requests_with_tool_call_errors": 23680
      },
      "relace/relace-search-20251208": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "relace/relace-search-20251208",
        "variant": "standard",
        "variant_permaslug": "relace/relace-search-20251208",
        "count": 30269,
        "total_completion_tokens": 385418,
        "total_prompt_tokens": 12884095,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 397,
        "requests_with_tool_call_errors": 14
      },
      "qwen/qwen3-4b-04-28:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-4b-04-28",
        "variant": "free",
        "variant_permaslug": "qwen/qwen3-4b-04-28:free",
        "count": 36476,
        "total_completion_tokens": 34730932,
        "total_prompt_tokens": 109716569,
        "total_native_tokens_reasoning": 25011110,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 3910,
        "requests_with_tool_call_errors": 3058
      },
      "deepseek/deepseek-v3.1-terminus": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-v3.1-terminus",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-v3.1-terminus",
        "count": 3467950,
        "total_completion_tokens": 1047842966,
        "total_prompt_tokens": 14837845201,
        "total_native_tokens_reasoning": 237865308,
        "num_media_prompt": 135,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 736107292,
        "total_tool_calls": 114523,
        "requests_with_tool_call_errors": 2230
      },
      "openai/o1-pro": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/o1-pro",
        "variant": "standard",
        "variant_permaslug": "openai/o1-pro",
        "count": 734,
        "total_completion_tokens": 512803,
        "total_prompt_tokens": 995742,
        "total_native_tokens_reasoning": 354560,
        "num_media_prompt": 6,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "tngtech/deepseek-r1t2-chimera": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "tngtech/deepseek-r1t2-chimera",
        "variant": "standard",
        "variant_permaslug": "tngtech/deepseek-r1t2-chimera",
        "count": 991479,
        "total_completion_tokens": 472852270,
        "total_prompt_tokens": 4991079820,
        "total_native_tokens_reasoning": 694547105,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 568199488,
        "total_tool_calls": 84,
        "requests_with_tool_call_errors": 3
      },
      "essentialai/rnj-1-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "essentialai/rnj-1-instruct",
        "variant": "standard",
        "variant_permaslug": "essentialai/rnj-1-instruct",
        "count": 197953,
        "total_completion_tokens": 20886502,
        "total_prompt_tokens": 126295265,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen2.5-vl-72b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen2.5-vl-72b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen2.5-vl-72b-instruct",
        "count": 821056,
        "total_completion_tokens": 89221789,
        "total_prompt_tokens": 1818326117,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 954012,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 64154928,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-oss-20b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-oss-20b",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-oss-20b",
        "count": 19957157,
        "total_completion_tokens": 16057769848,
        "total_prompt_tokens": 48091424311,
        "total_native_tokens_reasoning": 12713007567,
        "num_media_prompt": 806,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 10735635400,
        "total_tool_calls": 491976,
        "requests_with_tool_call_errors": 33551
      },
      "openai/gpt-4o-mini": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4o-mini",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4o-mini",
        "count": 58040181,
        "total_completion_tokens": 6449199798,
        "total_prompt_tokens": 138806594025,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 1339885,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 26741058816,
        "total_tool_calls": 4031519,
        "requests_with_tool_call_errors": 72275
      },
      "qwen/qwen-2.5-72b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen-2.5-72b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen-2.5-72b-instruct",
        "count": 4876353,
        "total_completion_tokens": 309604932,
        "total_prompt_tokens": 3317257363,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 19897492,
        "total_tool_calls": 707453,
        "requests_with_tool_call_errors": 1257
      },
      "alibaba/tongyi-deepresearch-30b-a3b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "alibaba/tongyi-deepresearch-30b-a3b",
        "variant": "standard",
        "variant_permaslug": "alibaba/tongyi-deepresearch-30b-a3b",
        "count": 148599,
        "total_completion_tokens": 105021228,
        "total_prompt_tokens": 1912455433,
        "total_native_tokens_reasoning": 81325815,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 4368,
        "requests_with_tool_call_errors": 1493
      },
      "switchpoint/router": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "switchpoint/router",
        "variant": "standard",
        "variant_permaslug": "switchpoint/router",
        "count": 1647,
        "total_completion_tokens": 864215,
        "total_prompt_tokens": 5663808,
        "total_native_tokens_reasoning": 19420,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "ibm-granite/granite-4.0-h-micro": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "ibm-granite/granite-4.0-h-micro",
        "variant": "standard",
        "variant_permaslug": "ibm-granite/granite-4.0-h-micro",
        "count": 536871,
        "total_completion_tokens": 54061211,
        "total_prompt_tokens": 808836034,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen2.5-vl-32b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen2.5-vl-32b-instruct",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen2.5-vl-32b-instruct",
        "count": 615864,
        "total_completion_tokens": 70573086,
        "total_prompt_tokens": 1664134422,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 517292,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 102591094,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/o4-mini-deep-research-2025-06-26": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/o4-mini-deep-research-2025-06-26",
        "variant": "standard",
        "variant_permaslug": "openai/o4-mini-deep-research-2025-06-26",
        "count": 2380,
        "total_completion_tokens": 30253425,
        "total_prompt_tokens": 66187608,
        "total_native_tokens_reasoning": 26872698,
        "num_media_prompt": 404,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2166656,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "baidu/ernie-4.5-vl-28b-a3b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "baidu/ernie-4.5-vl-28b-a3b",
        "variant": "standard",
        "variant_permaslug": "baidu/ernie-4.5-vl-28b-a3b",
        "count": 3568,
        "total_completion_tokens": 1823015,
        "total_prompt_tokens": 8012554,
        "total_native_tokens_reasoning": 57552,
        "num_media_prompt": 2097,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "xiaomi/mimo-v2-flash-20251210": {
        "date": "2026-01-15 00:00:00",
        "model_permaslug": "xiaomi/mimo-v2-flash-20251210",
        "variant": "standard",
        "variant_permaslug": "xiaomi/mimo-v2-flash-20251210",
        "count": 131548,
        "total_completion_tokens": 63519890,
        "total_prompt_tokens": 695651900,
        "total_native_tokens_reasoning": 14882286,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 493386467,
        "total_tool_calls": 4754,
        "requests_with_tool_call_errors": 417
      },
      "cohere/command-r7b-12-2024": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "cohere/command-r7b-12-2024",
        "variant": "standard",
        "variant_permaslug": "cohere/command-r7b-12-2024",
        "count": 805936,
        "total_completion_tokens": 80230535,
        "total_prompt_tokens": 3282937653,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/o3-mini-2025-01-31": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/o3-mini-2025-01-31",
        "variant": "standard",
        "variant_permaslug": "openai/o3-mini-2025-01-31",
        "count": 269668,
        "total_completion_tokens": 407616825,
        "total_prompt_tokens": 662927271,
        "total_native_tokens_reasoning": 266392896,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 116639232,
        "total_tool_calls": 1882,
        "requests_with_tool_call_errors": 45
      },
      "openai/o3-mini-high-2025-01-31": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/o3-mini-high-2025-01-31",
        "variant": "standard",
        "variant_permaslug": "openai/o3-mini-high-2025-01-31",
        "count": 10779,
        "total_completion_tokens": 15659237,
        "total_prompt_tokens": 89113091,
        "total_native_tokens_reasoning": 10962112,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 42684544,
        "total_tool_calls": 339,
        "requests_with_tool_call_errors": 4
      },
      "openai/o3-pro-2025-06-10": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/o3-pro-2025-06-10",
        "variant": "standard",
        "variant_permaslug": "openai/o3-pro-2025-06-10",
        "count": 387,
        "total_completion_tokens": 389344,
        "total_prompt_tokens": 3117058,
        "total_native_tokens_reasoning": 188502,
        "num_media_prompt": 92,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 19,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-4o-search-preview-2025-03-11": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-4o-search-preview-2025-03-11",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-4o-search-preview-2025-03-11",
        "count": 31531,
        "total_completion_tokens": 13592254,
        "total_prompt_tokens": 43611001,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "openai/gpt-5.1-codex-20251113": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "openai/gpt-5.1-codex-20251113",
        "variant": "standard",
        "variant_permaslug": "openai/gpt-5.1-codex-20251113",
        "count": 138414,
        "total_completion_tokens": 75339569,
        "total_prompt_tokens": 5758969755,
        "total_native_tokens_reasoning": 47687469,
        "num_media_prompt": 41707,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 4653945856,
        "total_tool_calls": 82132,
        "requests_with_tool_call_errors": 1134
      },
      "baidu/ernie-4.5-300b-a47b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "baidu/ernie-4.5-300b-a47b",
        "variant": "standard",
        "variant_permaslug": "baidu/ernie-4.5-300b-a47b",
        "count": 37213,
        "total_completion_tokens": 15710257,
        "total_prompt_tokens": 152110122,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 5381824,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "black-forest-labs/flux.2-max": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "black-forest-labs/flux.2-max",
        "variant": "standard",
        "variant_permaslug": "black-forest-labs/flux.2-max",
        "count": 3925,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 12114574,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 4527,
        "num_media_completion": 3925,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "nousresearch/deephermes-3-mistral-24b-preview": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nousresearch/deephermes-3-mistral-24b-preview",
        "variant": "standard",
        "variant_permaslug": "nousresearch/deephermes-3-mistral-24b-preview",
        "count": 3690,
        "total_completion_tokens": 1482684,
        "total_prompt_tokens": 9029116,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 3811607,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "meituan/longcat-flash-chat": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meituan/longcat-flash-chat",
        "variant": "standard",
        "variant_permaslug": "meituan/longcat-flash-chat",
        "count": 312914,
        "total_completion_tokens": 89673817,
        "total_prompt_tokens": 1481188292,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 1292920960,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "qwen/qwen3-embedding-8b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "qwen/qwen3-embedding-8b",
        "variant": "standard",
        "variant_permaslug": "qwen/qwen3-embedding-8b",
        "count": 8636230,
        "total_completion_tokens": 0,
        "total_prompt_tokens": 12498427124,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "mistralai/devstral-2512": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/devstral-2512",
        "variant": "standard",
        "variant_permaslug": "mistralai/devstral-2512",
        "count": 531104,
        "total_completion_tokens": 140679189,
        "total_prompt_tokens": 5414374957,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 4288361024,
        "total_tool_calls": 44974,
        "requests_with_tool_call_errors": 4313
      },
      "amazon/nova-lite-v1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "amazon/nova-lite-v1",
        "variant": "standard",
        "variant_permaslug": "amazon/nova-lite-v1",
        "count": 451693,
        "total_completion_tokens": 167795117,
        "total_prompt_tokens": 840941261,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 224838,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 145278,
        "requests_with_tool_call_errors": 6398
      },
      "ai21/jamba-mini-1.7": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "ai21/jamba-mini-1.7",
        "variant": "standard",
        "variant_permaslug": "ai21/jamba-mini-1.7",
        "count": 3824,
        "total_completion_tokens": 1394641,
        "total_prompt_tokens": 13521579,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 248,
        "requests_with_tool_call_errors": 120
      },
      "neversleep/llama-3.1-lumimaid-8b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "neversleep/llama-3.1-lumimaid-8b",
        "variant": "standard",
        "variant_permaslug": "neversleep/llama-3.1-lumimaid-8b",
        "count": 90125,
        "total_completion_tokens": 7809119,
        "total_prompt_tokens": 147416571,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "aion-labs/aion-rp-llama-3.1-8b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "aion-labs/aion-rp-llama-3.1-8b",
        "variant": "standard",
        "variant_permaslug": "aion-labs/aion-rp-llama-3.1-8b",
        "count": 12121,
        "total_completion_tokens": 2873505,
        "total_prompt_tokens": 59872460,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "meta-llama/llama-3.1-405b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3.1-405b-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-3.1-405b-instruct",
        "count": 993189,
        "total_completion_tokens": 69614406,
        "total_prompt_tokens": 726643148,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 379,
        "requests_with_tool_call_errors": 39
      },
      "mistralai/voxtral-small-24b-2507": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/voxtral-small-24b-2507",
        "variant": "standard",
        "variant_permaslug": "mistralai/voxtral-small-24b-2507",
        "count": 40210,
        "total_completion_tokens": 5495552,
        "total_prompt_tokens": 47880278,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 12038,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 4820,
        "requests_with_tool_call_errors": 4
      },
      "anthropic/claude-4.1-opus-20250805": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "anthropic/claude-4.1-opus-20250805",
        "variant": "standard",
        "variant_permaslug": "anthropic/claude-4.1-opus-20250805",
        "count": 187700,
        "total_completion_tokens": 66711317,
        "total_prompt_tokens": 1249892613,
        "total_native_tokens_reasoning": 5771024,
        "num_media_prompt": 10545,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 453077683,
        "total_tool_calls": 14823,
        "requests_with_tool_call_errors": 692
      },
      "google/gemini-2.5-flash-lite-preview-09-2025": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-2.5-flash-lite-preview-09-2025",
        "variant": "standard",
        "variant_permaslug": "google/gemini-2.5-flash-lite-preview-09-2025",
        "count": 18426550,
        "total_completion_tokens": 8523885589,
        "total_prompt_tokens": 50026816178,
        "total_native_tokens_reasoning": 1783093842,
        "num_media_prompt": 2470390,
        "num_media_completion": 0,
        "num_audio_prompt": 6905,
        "total_native_tokens_cached": 10029466549,
        "total_tool_calls": 338283,
        "requests_with_tool_call_errors": 1394
      },
      "deepcogito/cogito-v2-preview-llama-70b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepcogito/cogito-v2-preview-llama-70b",
        "variant": "standard",
        "variant_permaslug": "deepcogito/cogito-v2-preview-llama-70b",
        "count": 17925,
        "total_completion_tokens": 850684,
        "total_prompt_tokens": 9169662,
        "total_native_tokens_reasoning": 504,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 47,
        "requests_with_tool_call_errors": 3
      },
      "mistralai/mistral-7b-instruct-v0.1": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-7b-instruct-v0.1",
        "variant": "standard",
        "variant_permaslug": "mistralai/mistral-7b-instruct-v0.1",
        "count": 58539,
        "total_completion_tokens": 5649019,
        "total_prompt_tokens": 12582245,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "moonshotai/kimi-k2": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "moonshotai/kimi-k2",
        "variant": "standard",
        "variant_permaslug": "moonshotai/kimi-k2",
        "count": 1211952,
        "total_completion_tokens": 236893030,
        "total_prompt_tokens": 4708581810,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 2100843613,
        "total_tool_calls": 82967,
        "requests_with_tool_call_errors": 1446
      },
      "liquid/lfm2-8b-a1b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "liquid/lfm2-8b-a1b",
        "variant": "standard",
        "variant_permaslug": "liquid/lfm2-8b-a1b",
        "count": 63628,
        "total_completion_tokens": 3070187,
        "total_prompt_tokens": 24760492,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "tngtech/tng-r1t-chimera": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "tngtech/tng-r1t-chimera",
        "variant": "standard",
        "variant_permaslug": "tngtech/tng-r1t-chimera",
        "count": 17820,
        "total_completion_tokens": 10875635,
        "total_prompt_tokens": 72233419,
        "total_native_tokens_reasoning": 8952126,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 15904576,
        "total_tool_calls": 43,
        "requests_with_tool_call_errors": 2
      },
      "meta-llama/llama-3.2-1b-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3.2-1b-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-3.2-1b-instruct",
        "count": 53151,
        "total_completion_tokens": 15602331,
        "total_prompt_tokens": 303914467,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 1,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "mistralai/devstral-small-2505": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/devstral-small-2505",
        "variant": "standard",
        "variant_permaslug": "mistralai/devstral-small-2505",
        "count": 67550,
        "total_completion_tokens": 3791824,
        "total_prompt_tokens": 80166164,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "google/gemini-2.5-flash-image-preview": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "google/gemini-2.5-flash-image-preview",
        "variant": "standard",
        "variant_permaslug": "google/gemini-2.5-flash-image-preview",
        "count": 322855,
        "total_completion_tokens": 243460238,
        "total_prompt_tokens": 307668402,
        "total_native_tokens_reasoning": 1459,
        "num_media_prompt": 332166,
        "num_media_completion": 179120,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "allenai/olmo-3-32b-think-20251121": {
        "date": "2026-01-12 00:00:00",
        "model_permaslug": "allenai/olmo-3-32b-think-20251121",
        "variant": "standard",
        "variant_permaslug": "allenai/olmo-3-32b-think-20251121",
        "count": 4,
        "total_completion_tokens": 4944,
        "total_prompt_tokens": 210,
        "total_native_tokens_reasoning": 5390,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 160,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "microsoft/phi-4-reasoning-plus-04-30": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "microsoft/phi-4-reasoning-plus-04-30",
        "variant": "standard",
        "variant_permaslug": "microsoft/phi-4-reasoning-plus-04-30",
        "count": 52168,
        "total_completion_tokens": 75059856,
        "total_prompt_tokens": 98312956,
        "total_native_tokens_reasoning": 4247,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepseek/deepseek-prover-v2": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-prover-v2",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-prover-v2",
        "count": 232189,
        "total_completion_tokens": 128432190,
        "total_prompt_tokens": 420166598,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "mistralai/mistral-7b-instruct:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "mistralai/mistral-7b-instruct",
        "variant": "free",
        "variant_permaslug": "mistralai/mistral-7b-instruct:free",
        "count": 217397,
        "total_completion_tokens": 51573398,
        "total_prompt_tokens": 611678765,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 81,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "meta-llama/llama-3.2-90b-vision-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "meta-llama/llama-3.2-90b-vision-instruct",
        "variant": "standard",
        "variant_permaslug": "meta-llama/llama-3.2-90b-vision-instruct",
        "count": 163458,
        "total_completion_tokens": 15900196,
        "total_prompt_tokens": 410332584,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 190004,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "microsoft/phi-4-multimodal-instruct": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "microsoft/phi-4-multimodal-instruct",
        "variant": "standard",
        "variant_permaslug": "microsoft/phi-4-multimodal-instruct",
        "count": 93616,
        "total_completion_tokens": 11676844,
        "total_prompt_tokens": 33323378,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 33682,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepseek/deepseek-r1-distill-qwen-14b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-r1-distill-qwen-14b",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-r1-distill-qwen-14b",
        "count": 20400,
        "total_completion_tokens": 21719127,
        "total_prompt_tokens": 33243409,
        "total_native_tokens_reasoning": 13548130,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "deepseek/deepseek-r1-0528-qwen3-8b": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "deepseek/deepseek-r1-0528-qwen3-8b",
        "variant": "standard",
        "variant_permaslug": "deepseek/deepseek-r1-0528-qwen3-8b",
        "count": 292972,
        "total_completion_tokens": 216365241,
        "total_prompt_tokens": 282284755,
        "total_native_tokens_reasoning": 144964597,
        "num_media_prompt": 363,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "thudm/glm-4.1v-9b-thinking": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "thudm/glm-4.1v-9b-thinking",
        "variant": "standard",
        "variant_permaslug": "thudm/glm-4.1v-9b-thinking",
        "count": 41047,
        "total_completion_tokens": 9261241,
        "total_prompt_tokens": 18930444,
        "total_native_tokens_reasoning": 8977156,
        "num_media_prompt": 9633,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "kwaipilot/kat-coder-pro-v1:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "kwaipilot/kat-coder-pro-v1",
        "variant": "free",
        "variant_permaslug": "kwaipilot/kat-coder-pro-v1:free",
        "count": 938540,
        "total_completion_tokens": 399700899,
        "total_prompt_tokens": 18069604329,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 15124050059,
        "total_tool_calls": 187810,
        "requests_with_tool_call_errors": 11107
      },
      "anthropic/claude-3-5-haiku-20241022": {
        "date": "2026-01-11 00:00:00",
        "model_permaslug": "anthropic/claude-3-5-haiku-20241022",
        "variant": "standard",
        "variant_permaslug": "anthropic/claude-3-5-haiku-20241022",
        "count": 7,
        "total_completion_tokens": 1537,
        "total_prompt_tokens": 141286,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 6,
        "requests_with_tool_call_errors": 0
      },
      "allenai/molmo-2-8b-20260109": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "allenai/molmo-2-8b-20260109",
        "variant": "standard",
        "variant_permaslug": "allenai/molmo-2-8b-20260109",
        "count": 502,
        "total_completion_tokens": 133057,
        "total_prompt_tokens": 330625,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 76,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 0,
        "requests_with_tool_call_errors": 0
      },
      "nex-agi/deepseek-v3.1-nex-n1:free": {
        "date": "2026-01-09 00:00:00",
        "model_permaslug": "nex-agi/deepseek-v3.1-nex-n1",
        "variant": "free",
        "variant_permaslug": "nex-agi/deepseek-v3.1-nex-n1:free",
        "count": 520677,
        "total_completion_tokens": 299252421,
        "total_prompt_tokens": 7435086011,
        "total_native_tokens_reasoning": 0,
        "num_media_prompt": 0,
        "num_media_completion": 0,
        "num_audio_prompt": 0,
        "total_native_tokens_cached": 0,
        "total_tool_calls": 9263,
        "requests_with_tool_call_errors": 1458
      }
    },
    "categories": {
      "x-ai/grok-code-fast-1": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "x-ai/grok-code-fast-1",
          "category": "programming",
          "count": 10304,
          "total_prompt_tokens": 679149514,
          "total_completion_tokens": 5903115,
          "volume": 2.640890759,
          "rank": 1
        }
      ],
      "openai/gpt-oss-120b": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-oss-120b",
          "category": "legal",
          "count": 4216,
          "total_prompt_tokens": 18550267,
          "total_completion_tokens": 1275548,
          "volume": 4.5676140722,
          "rank": 1
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-oss-120b",
          "category": "finance",
          "count": 2514,
          "total_prompt_tokens": 17609333,
          "total_completion_tokens": 1426115,
          "volume": 2.59372804707,
          "rank": 3
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-oss-120b",
          "category": "translation",
          "count": 9363,
          "total_prompt_tokens": 12010114,
          "total_completion_tokens": 4553962,
          "volume": 0.48735877106,
          "rank": 3
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-oss-120b",
          "category": "trivia",
          "count": 558,
          "total_prompt_tokens": 857987,
          "total_completion_tokens": 327464,
          "volume": 0.0506540128,
          "rank": 4
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-oss-120b",
          "category": "academia",
          "count": 3462,
          "total_prompt_tokens": 2562126,
          "total_completion_tokens": 3346466,
          "volume": 2.37230243572,
          "rank": 6
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-oss-120b",
          "category": "science",
          "count": 5996,
          "total_prompt_tokens": 20065622,
          "total_completion_tokens": 8650251,
          "volume": 8.11594460448,
          "rank": 6
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-oss-120b",
          "category": "technology",
          "count": 5957,
          "total_prompt_tokens": 32128347,
          "total_completion_tokens": 4149885,
          "volume": 5.87225887009,
          "rank": 8
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-oss-120b",
          "category": "marketing",
          "count": 605,
          "total_prompt_tokens": 2318134,
          "total_completion_tokens": 583452,
          "volume": 0.20360426243,
          "rank": 9
        }
      ],
      "google/gemini-2.0-flash-001": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.0-flash-001",
          "category": "translation",
          "count": 35749,
          "total_prompt_tokens": 29069760,
          "total_completion_tokens": 8291946,
          "volume": 1.1482708445,
          "rank": 1
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.0-flash-001",
          "category": "trivia",
          "count": 598,
          "total_prompt_tokens": 878533,
          "total_completion_tokens": 62408,
          "volume": 0.1617823586,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.0-flash-001",
          "category": "academia",
          "count": 2102,
          "total_prompt_tokens": 4271021,
          "total_completion_tokens": 1404342,
          "volume": 1.0353577409,
          "rank": 7
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.0-flash-001",
          "category": "marketing",
          "count": 512,
          "total_prompt_tokens": 2210760,
          "total_completion_tokens": 266751,
          "volume": 0.4834420775,
          "rank": 10
        }
      ],
      "anthropic/claude-4.5-sonnet-20250929": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-sonnet-20250929",
          "category": "health",
          "count": 504,
          "total_prompt_tokens": 12462821,
          "total_completion_tokens": 363817,
          "volume": 65.608356748,
          "rank": 1
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-sonnet-20250929",
          "category": "technology",
          "count": 5834,
          "total_prompt_tokens": 333723155,
          "total_completion_tokens": 2306336,
          "volume": 193.642564532,
          "rank": 1
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-sonnet-20250929",
          "category": "science",
          "count": 1765,
          "total_prompt_tokens": 35240365,
          "total_completion_tokens": 1032364,
          "volume": 127.118924409,
          "rank": 3
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-sonnet-20250929",
          "category": "programming",
          "count": 4490,
          "total_prompt_tokens": 202532714,
          "total_completion_tokens": 2623683,
          "volume": 314.226995738,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-sonnet-20250929",
          "category": "academia",
          "count": 878,
          "total_prompt_tokens": 6145823,
          "total_completion_tokens": 384992,
          "volume": 23.7592705975,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-sonnet-20250929",
          "category": "marketing",
          "count": 161,
          "total_prompt_tokens": 3622304,
          "total_completion_tokens": 83095,
          "volume": 17.5921333935,
          "rank": 6
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-sonnet-20250929",
          "category": "legal",
          "count": 299,
          "total_prompt_tokens": 3906046,
          "total_completion_tokens": 135429,
          "volume": 11.9959430575,
          "rank": 8
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-sonnet-20250929",
          "category": "roleplay",
          "count": 4449,
          "total_prompt_tokens": 42335520,
          "total_completion_tokens": 1702961,
          "volume": 154.903585975,
          "rank": 10
        }
      ],
      "xiaomi/mimo-v2-flash-20251210:free": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "xiaomi/mimo-v2-flash-20251210",
          "category": "trivia",
          "count": 235,
          "total_prompt_tokens": 426468,
          "total_completion_tokens": 3648914,
          "volume": 0.00033884,
          "rank": 1
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "xiaomi/mimo-v2-flash-20251210",
          "category": "academia",
          "count": 2723,
          "total_prompt_tokens": 8278393,
          "total_completion_tokens": 9797302,
          "volume": 0,
          "rank": 1
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "xiaomi/mimo-v2-flash-20251210",
          "category": "finance",
          "count": 3766,
          "total_prompt_tokens": 30750071,
          "total_completion_tokens": 7314973,
          "volume": 0.02,
          "rank": 1
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "xiaomi/mimo-v2-flash-20251210",
          "category": "science",
          "count": 7857,
          "total_prompt_tokens": 35802220,
          "total_completion_tokens": 19540849,
          "volume": 0.02242352,
          "rank": 1
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "xiaomi/mimo-v2-flash-20251210",
          "category": "roleplay",
          "count": 15192,
          "total_prompt_tokens": 189868681,
          "total_completion_tokens": 7924318,
          "volume": 0.1007914142,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "xiaomi/mimo-v2-flash-20251210",
          "category": "translation",
          "count": 1652,
          "total_prompt_tokens": 12394380,
          "total_completion_tokens": 8902261,
          "volume": 0,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "xiaomi/mimo-v2-flash-20251210",
          "category": "marketing",
          "count": 1702,
          "total_prompt_tokens": 9469496,
          "total_completion_tokens": 553302,
          "volume": 0,
          "rank": 3
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "xiaomi/mimo-v2-flash-20251210",
          "category": "technology",
          "count": 7193,
          "total_prompt_tokens": 73064401,
          "total_completion_tokens": 3470596,
          "volume": 0.06054738,
          "rank": 4
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "xiaomi/mimo-v2-flash-20251210",
          "category": "programming",
          "count": 5985,
          "total_prompt_tokens": 116247725,
          "total_completion_tokens": 7295511,
          "volume": 0.0411322,
          "rank": 7
        }
      ],
      "google/gemini-2.5-flash-lite": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash-lite",
          "category": "marketing",
          "count": 4203,
          "total_prompt_tokens": 16498813,
          "total_completion_tokens": 1162935,
          "volume": 1.448098173,
          "rank": 1
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash-lite",
          "category": "technology",
          "count": 14047,
          "total_prompt_tokens": 97806325,
          "total_completion_tokens": 8481702,
          "volume": 6.2740733513,
          "rank": 3
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash-lite",
          "category": "translation",
          "count": 10586,
          "total_prompt_tokens": 9075088,
          "total_completion_tokens": 2146361,
          "volume": 1.531087132552,
          "rank": 4
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash-lite",
          "category": "legal",
          "count": 1366,
          "total_prompt_tokens": 5497375,
          "total_completion_tokens": 352956,
          "volume": 0.758090655,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash-lite",
          "category": "health",
          "count": 6237,
          "total_prompt_tokens": 3761231,
          "total_completion_tokens": 1159083,
          "volume": 0.7959590053,
          "rank": 6
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash-lite",
          "category": "academia",
          "count": 2656,
          "total_prompt_tokens": 4576257,
          "total_completion_tokens": 773560,
          "volume": 1.32543829255,
          "rank": 8
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash-lite",
          "category": "marketing/seo",
          "count": 541,
          "total_prompt_tokens": 773511,
          "total_completion_tokens": 250072,
          "volume": 0.193402285,
          "rank": 9
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash-lite",
          "category": "roleplay",
          "count": 18524,
          "total_prompt_tokens": 45376083,
          "total_completion_tokens": 1150251,
          "volume": 3.8638590431,
          "rank": 9
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash-lite",
          "category": "finance",
          "count": 5197,
          "total_prompt_tokens": 7408620,
          "total_completion_tokens": 641052,
          "volume": 1.2612740393,
          "rank": 10
        }
      ],
      "deepseek/deepseek-v3.2-20251201": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "deepseek/deepseek-v3.2-20251201",
          "category": "roleplay",
          "count": 26903,
          "total_prompt_tokens": 245462522,
          "total_completion_tokens": 15359065,
          "volume": 25.742490119790002,
          "rank": 1
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "deepseek/deepseek-v3.2-20251201",
          "category": "academia",
          "count": 962,
          "total_prompt_tokens": 5615451,
          "total_completion_tokens": 1514776,
          "volume": 2.13099734818,
          "rank": 4
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "deepseek/deepseek-v3.2-20251201",
          "category": "science",
          "count": 4761,
          "total_prompt_tokens": 28242074,
          "total_completion_tokens": 4525085,
          "volume": 10.85523656995,
          "rank": 4
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "deepseek/deepseek-v3.2-20251201",
          "category": "finance",
          "count": 1868,
          "total_prompt_tokens": 11896381,
          "total_completion_tokens": 668810,
          "volume": 5.39878881835,
          "rank": 8
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "deepseek/deepseek-v3.2-20251201",
          "category": "translation",
          "count": 1365,
          "total_prompt_tokens": 2332567,
          "total_completion_tokens": 639403,
          "volume": 0.86552245886,
          "rank": 9
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "deepseek/deepseek-v3.2-20251201",
          "category": "technology",
          "count": 4167,
          "total_prompt_tokens": 32765249,
          "total_completion_tokens": 1931937,
          "volume": 7.25573689619,
          "rank": 10
        }
      ],
      "x-ai/grok-4-fast": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "x-ai/grok-4-fast",
          "category": "marketing/seo",
          "count": 1529,
          "total_prompt_tokens": 6403550,
          "total_completion_tokens": 2149700,
          "volume": 2.8851342975,
          "rank": 1
        }
      ],
      "anthropic/claude-4.5-opus-20251124": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-opus-20251124",
          "category": "technology",
          "count": 7332,
          "total_prompt_tokens": 215846991,
          "total_completion_tokens": 2972856,
          "volume": 1174.2742164875,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-opus-20251124",
          "category": "programming",
          "count": 17942,
          "total_prompt_tokens": 620537128,
          "total_completion_tokens": 6420530,
          "volume": 3003.0972704,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-opus-20251124",
          "category": "marketing/seo",
          "count": 55,
          "total_prompt_tokens": 1261934,
          "total_completion_tokens": 48274,
          "volume": 9.1181767,
          "rank": 4
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-opus-20251124",
          "category": "science",
          "count": 1192,
          "total_prompt_tokens": 28099408,
          "total_completion_tokens": 488918,
          "volume": 93.8484774075,
          "rank": 7
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-opus-20251124",
          "category": "academia",
          "count": 246,
          "total_prompt_tokens": 5121748,
          "total_completion_tokens": 136205,
          "volume": 31.552414000000002,
          "rank": 9
        }
      ],
      "openai/gpt-4o-mini": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-4o-mini",
          "category": "trivia",
          "count": 1846,
          "total_prompt_tokens": 1871817,
          "total_completion_tokens": 19903,
          "volume": 0.24616377,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-4o-mini",
          "category": "finance",
          "count": 3085,
          "total_prompt_tokens": 18649870,
          "total_completion_tokens": 222348,
          "volume": 3.0048863404999997,
          "rank": 4
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-4o-mini",
          "category": "marketing",
          "count": 3722,
          "total_prompt_tokens": 3352168,
          "total_completion_tokens": 169811,
          "volume": 0.599295609,
          "rank": 7
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-4o-mini",
          "category": "marketing/seo",
          "count": 1424,
          "total_prompt_tokens": 784035,
          "total_completion_tokens": 248337,
          "volume": 0.308601277,
          "rank": 8
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-4o-mini",
          "category": "science",
          "count": 5523,
          "total_prompt_tokens": 21756036,
          "total_completion_tokens": 869294,
          "volume": 3.697017309,
          "rank": 9
        }
      ],
      "google/gemini-3-flash-preview-20251217": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "finance",
          "count": 2811,
          "total_prompt_tokens": 23360134,
          "total_completion_tokens": 902007,
          "volume": 12.5116493685,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "health",
          "count": 2259,
          "total_prompt_tokens": 10314565,
          "total_completion_tokens": 679784,
          "volume": 6.723002682,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "science",
          "count": 6097,
          "total_prompt_tokens": 39577578,
          "total_completion_tokens": 1982524,
          "volume": 19.2213283355,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "programming",
          "count": 9223,
          "total_prompt_tokens": 241678887,
          "total_completion_tokens": 3191804,
          "volume": 28.2535491455,
          "rank": 3
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "academia",
          "count": 3626,
          "total_prompt_tokens": 12513023,
          "total_completion_tokens": 1500922,
          "volume": 8.2787556765,
          "rank": 3
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "marketing/seo",
          "count": 203,
          "total_prompt_tokens": 1757201,
          "total_completion_tokens": 65982,
          "volume": 0.999279869,
          "rank": 3
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "legal",
          "count": 1282,
          "total_prompt_tokens": 6856467,
          "total_completion_tokens": 681229,
          "volume": 4.9577896015,
          "rank": 3
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "marketing",
          "count": 722,
          "total_prompt_tokens": 3982790,
          "total_completion_tokens": 213689,
          "volume": 2.571737667,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "technology",
          "count": 7796,
          "total_prompt_tokens": 69687667,
          "total_completion_tokens": 2873744,
          "volume": 31.559859791,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "translation",
          "count": 5951,
          "total_prompt_tokens": 6748812,
          "total_completion_tokens": 1739236,
          "volume": 7.101130131500001,
          "rank": 6
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "trivia",
          "count": 430,
          "total_prompt_tokens": 723143,
          "total_completion_tokens": 112961,
          "volume": 0.91928088,
          "rank": 6
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-flash-preview-20251217",
          "category": "roleplay",
          "count": 6924,
          "total_prompt_tokens": 52231184,
          "total_completion_tokens": 3234593,
          "volume": 26.617844777,
          "rank": 8
        }
      ],
      "google/gemini-2.5-flash": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash",
          "category": "legal",
          "count": 2774,
          "total_prompt_tokens": 14028254,
          "total_completion_tokens": 570720,
          "volume": 3.6477247815,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash",
          "category": "marketing",
          "count": 2350,
          "total_prompt_tokens": 9069149,
          "total_completion_tokens": 999095,
          "volume": 3.9447405111,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash",
          "category": "academia",
          "count": 5880,
          "total_prompt_tokens": 13996525,
          "total_completion_tokens": 2002473,
          "volume": 7.009833549879,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash",
          "category": "marketing/seo",
          "count": 1952,
          "total_prompt_tokens": 2259239,
          "total_completion_tokens": 508171,
          "volume": 1.209903453,
          "rank": 2
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash",
          "category": "health",
          "count": 2476,
          "total_prompt_tokens": 7176065,
          "total_completion_tokens": 1181584,
          "volume": 3.1186738885,
          "rank": 3
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash",
          "category": "science",
          "count": 6637,
          "total_prompt_tokens": 29226681,
          "total_completion_tokens": 1905760,
          "volume": 11.933320269100001,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash",
          "category": "roleplay",
          "count": 11760,
          "total_prompt_tokens": 66267274,
          "total_completion_tokens": 3921227,
          "volume": 23.3842842292,
          "rank": 6
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash",
          "category": "finance",
          "count": 7410,
          "total_prompt_tokens": 11878349,
          "total_completion_tokens": 1355691,
          "volume": 4.2796908983,
          "rank": 6
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash",
          "category": "technology",
          "count": 12636,
          "total_prompt_tokens": 55259118,
          "total_completion_tokens": 4935338,
          "volume": 21.149648935379,
          "rank": 6
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash",
          "category": "translation",
          "count": 6060,
          "total_prompt_tokens": 5064547,
          "total_completion_tokens": 1008430,
          "volume": 3.3313450409,
          "rank": 7
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash",
          "category": "trivia",
          "count": 932,
          "total_prompt_tokens": 659549,
          "total_completion_tokens": 139930,
          "volume": 0.4510255534,
          "rank": 7
        }
      ],
      "x-ai/grok-4.1-fast": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "x-ai/grok-4.1-fast",
          "category": "trivia",
          "count": 435,
          "total_prompt_tokens": 1123722,
          "total_completion_tokens": 128234,
          "volume": 0.368653884,
          "rank": 3
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "x-ai/grok-4.1-fast",
          "category": "marketing",
          "count": 1441,
          "total_prompt_tokens": 8408844,
          "total_completion_tokens": 1164463,
          "volume": 2.5689471575,
          "rank": 4
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "x-ai/grok-4.1-fast",
          "category": "roleplay",
          "count": 10978,
          "total_prompt_tokens": 95095830,
          "total_completion_tokens": 5296442,
          "volume": 12.7046526545,
          "rank": 4
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "x-ai/grok-4.1-fast",
          "category": "legal",
          "count": 417,
          "total_prompt_tokens": 4973894,
          "total_completion_tokens": 234504,
          "volume": 1.3660008479999999,
          "rank": 6
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "x-ai/grok-4.1-fast",
          "category": "science",
          "count": 2979,
          "total_prompt_tokens": 24812675,
          "total_completion_tokens": 1975942,
          "volume": 5.599915707,
          "rank": 8
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "x-ai/grok-4.1-fast",
          "category": "finance",
          "count": 2928,
          "total_prompt_tokens": 11334666,
          "total_completion_tokens": 811943,
          "volume": 3.947345568,
          "rank": 9
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "x-ai/grok-4.1-fast",
          "category": "marketing/seo",
          "count": 257,
          "total_prompt_tokens": 599866,
          "total_completion_tokens": 309164,
          "volume": 0.4532778465,
          "rank": 10
        }
      ],
      "tngtech/deepseek-r1t2-chimera:free": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "tngtech/deepseek-r1t2-chimera",
          "category": "roleplay",
          "count": 9453,
          "total_prompt_tokens": 96875447,
          "total_completion_tokens": 7943367,
          "volume": 0.4592855385,
          "rank": 3
        }
      ],
      "anthropic/claude-4-sonnet-20250522": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4-sonnet-20250522",
          "category": "health",
          "count": 1131,
          "total_prompt_tokens": 4850622,
          "total_completion_tokens": 1352344,
          "volume": 39.49455927,
          "rank": 4
        }
      ],
      "openai/gpt-5-mini-2025-08-07": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-5-mini-2025-08-07",
          "category": "legal",
          "count": 1494,
          "total_prompt_tokens": 7139211,
          "total_completion_tokens": 189610,
          "volume": 1.8528693075,
          "rank": 4
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-5-mini-2025-08-07",
          "category": "finance",
          "count": 2389,
          "total_prompt_tokens": 14507815,
          "total_completion_tokens": 974255,
          "volume": 6.0123198350000004,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-5-mini-2025-08-07",
          "category": "health",
          "count": 913,
          "total_prompt_tokens": 4920457,
          "total_completion_tokens": 659881,
          "volume": 3.33226796,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-5-mini-2025-08-07",
          "category": "marketing/seo",
          "count": 459,
          "total_prompt_tokens": 974267,
          "total_completion_tokens": 266445,
          "volume": 1.33881092,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-5-mini-2025-08-07",
          "category": "technology",
          "count": 2745,
          "total_prompt_tokens": 33449512,
          "total_completion_tokens": 1386103,
          "volume": 9.1275819115,
          "rank": 9
        }
      ],
      "mistralai/devstral-2512:free": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "mistralai/devstral-2512",
          "category": "programming",
          "count": 2773,
          "total_prompt_tokens": 205200503,
          "total_completion_tokens": 881400,
          "volume": 0.2296268977,
          "rank": 4
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "mistralai/devstral-2512",
          "category": "marketing/seo",
          "count": 127,
          "total_prompt_tokens": 1009823,
          "total_completion_tokens": 95895,
          "volume": 0,
          "rank": 7
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "mistralai/devstral-2512",
          "category": "legal",
          "count": 1233,
          "total_prompt_tokens": 3786750,
          "total_completion_tokens": 1172050,
          "volume": 0,
          "rank": 7
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "mistralai/devstral-2512",
          "category": "academia",
          "count": 1292,
          "total_prompt_tokens": 3566733,
          "total_completion_tokens": 1690744,
          "volume": 0.0025803558,
          "rank": 10
        }
      ],
      "meta-llama/llama-3.1-8b-instruct": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "meta-llama/llama-3.1-8b-instruct",
          "category": "translation",
          "count": 8228,
          "total_prompt_tokens": 9067001,
          "total_completion_tokens": 448573,
          "volume": 0.24086777559999997,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "meta-llama/llama-3.1-8b-instruct",
          "category": "trivia",
          "count": 1576,
          "total_prompt_tokens": 661000,
          "total_completion_tokens": 12600,
          "volume": 0.025604850000000002,
          "rank": 9
        }
      ],
      "deepseek/deepseek-chat-v3-0324": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "deepseek/deepseek-chat-v3-0324",
          "category": "roleplay",
          "count": 15654,
          "total_prompt_tokens": 89479818,
          "total_completion_tokens": 3474322,
          "volume": 29.40984031294,
          "rank": 5
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "deepseek/deepseek-chat-v3-0324",
          "category": "health",
          "count": 182,
          "total_prompt_tokens": 2765245,
          "total_completion_tokens": 109754,
          "volume": 0.89047372848,
          "rank": 9
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "deepseek/deepseek-chat-v3-0324",
          "category": "trivia",
          "count": 281,
          "total_prompt_tokens": 401056,
          "total_completion_tokens": 27312,
          "volume": 0.1307579738,
          "rank": 10
        }
      ],
      "google/gemini-2.5-flash-preview-09-2025": [
        {
          "id": 0,
          "date": "2026-01-14",
          "model": "google/gemini-2.5-flash-preview-09-2025",
          "category": "marketing/seo",
          "count": 39,
          "total_prompt_tokens": 1207098,
          "total_completion_tokens": 13329,
          "volume": 0.387463415,
          "rank": 6
        }
      ],
      "google/gemini-3-pro-preview-20251117": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-pro-preview-20251117",
          "category": "programming",
          "count": 4140,
          "total_prompt_tokens": 132411625,
          "total_completion_tokens": 2715971,
          "volume": 186.308172255,
          "rank": 6
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-pro-preview-20251117",
          "category": "technology",
          "count": 2234,
          "total_prompt_tokens": 49860062,
          "total_completion_tokens": 2282001,
          "volume": 92.503462042,
          "rank": 7
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-pro-preview-20251117",
          "category": "health",
          "count": 209,
          "total_prompt_tokens": 2731245,
          "total_completion_tokens": 317223,
          "volume": 15.04045237,
          "rank": 7
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-pro-preview-20251117",
          "category": "science",
          "count": 1383,
          "total_prompt_tokens": 18034533,
          "total_completion_tokens": 1801794,
          "volume": 69.867422936,
          "rank": 10
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-3-pro-preview-20251117",
          "category": "legal",
          "count": 201,
          "total_prompt_tokens": 2312831,
          "total_completion_tokens": 204253,
          "volume": 9.78040816,
          "rank": 10
        }
      ],
      "deepseek/deepseek-chat-v3.1": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "deepseek/deepseek-chat-v3.1",
          "category": "roleplay",
          "count": 13858,
          "total_prompt_tokens": 64977619,
          "total_completion_tokens": 1748905,
          "volume": 20.0609503859,
          "rank": 7
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "deepseek/deepseek-chat-v3.1",
          "category": "finance",
          "count": 742,
          "total_prompt_tokens": 11902046,
          "total_completion_tokens": 1173622,
          "volume": 4.742806102199999,
          "rank": 7
        }
      ],
      "google/gemini-2.5-pro": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-pro",
          "category": "health",
          "count": 280,
          "total_prompt_tokens": 2677250,
          "total_completion_tokens": 312801,
          "volume": 8.58600745375,
          "rank": 8
        }
      ],
      "anthropic/claude-4.5-haiku-20251001": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "anthropic/claude-4.5-haiku-20251001",
          "category": "trivia",
          "count": 202,
          "total_prompt_tokens": 773700,
          "total_completion_tokens": 7850,
          "volume": 1.003834,
          "rank": 8
        }
      ],
      "minimax/minimax-m2.1": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "minimax/minimax-m2.1",
          "category": "programming",
          "count": 2053,
          "total_prompt_tokens": 100218975,
          "total_completion_tokens": 1401523,
          "volume": 4.6440296596,
          "rank": 8
        }
      ],
      "z-ai/glm-4.7-20251222": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "z-ai/glm-4.7-20251222",
          "category": "translation",
          "count": 568,
          "total_prompt_tokens": 1933668,
          "total_completion_tokens": 1857616,
          "volume": 0.3038238179,
          "rank": 8
        },
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "z-ai/glm-4.7-20251222",
          "category": "programming",
          "count": 3633,
          "total_prompt_tokens": 92927218,
          "total_completion_tokens": 4420481,
          "volume": 27.865996856530003,
          "rank": 9
        }
      ],
      "qwen/qwen3-30b-a3b-04-28": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "qwen/qwen3-30b-a3b-04-28",
          "category": "marketing",
          "count": 1037,
          "total_prompt_tokens": 2243550,
          "total_completion_tokens": 724400,
          "volume": 0.48066809,
          "rank": 8
        }
      ],
      "google/gemini-2.5-flash-lite-preview-09-2025": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "google/gemini-2.5-flash-lite-preview-09-2025",
          "category": "legal",
          "count": 788,
          "total_prompt_tokens": 3078465,
          "total_completion_tokens": 343526,
          "volume": 0.34180918,
          "rank": 9
        }
      ],
      "openai/gpt-5.2-20251211": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-5.2-20251211",
          "category": "programming",
          "count": 2103,
          "total_prompt_tokens": 73642478,
          "total_completion_tokens": 1632981,
          "volume": 46.363018183,
          "rank": 10
        }
      ],
      "openai/gpt-4.1-mini-2025-04-14": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-4.1-mini-2025-04-14",
          "category": "translation",
          "count": 4625,
          "total_prompt_tokens": 2411208,
          "total_completion_tokens": 348853,
          "volume": 1.30104752,
          "rank": 10
        }
      ],
      "openai/gpt-oss-20b": [
        {
          "id": 0,
          "date": "2026-01-15",
          "model": "openai/gpt-oss-20b",
          "category": "health",
          "count": 1147,
          "total_prompt_tokens": 2678722,
          "total_completion_tokens": 154158,
          "volume": 0.1962293575,
          "rank": 10
        }
      ]
    }
  }
}